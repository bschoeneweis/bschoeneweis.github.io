{"pageProps":{"tag":"networkx","taggedPosts":[{"id":"visualizing-your-linkedin-connections","contentHtml":"<h2>tl;dr</h2>\n<h3>Goal</h3>\n<p><em>To understand and visualize the companies within my directly connected network on LinkedIn</em></p>\n<h3>Process overview</h3>\n<ol>\n<li><strong>LinkedIn data sources</strong> - retrieving LinkedIn Network data from a \"Get a copy of your data\" CSV export</li>\n<li><strong>Diving into the data</strong> - exploring, cleaning, and aggregating the data with <a href=\"https://pandas.pydata.org/\"><code>Pandas</code></a></li>\n<li><strong>Creating the network</strong> - creating a network graph using <a href=\"https://networkx.org/\"><code>NetworkX</code></a></li>\n<li><strong>Visualization</strong> - visualizing the network with <a href=\"https://pyvis.readthedocs.io/en/latest/\"><code>pyvis</code></a></li>\n<li><strong>Improving the output</strong> - cleaning up the network graph with additional filtering</li>\n</ol>\n<h3>Results</h3>\n<p><em>Hover over the nodes for more details</em></p>\n<ul>\n<li><a href=\"/network/first-nx-graph.html\">The first network graph</a></li>\n<li><a href=\"/network/second-nx-graph.html\">The second (more specific) network graph</a></li>\n</ul>\n<h3>Python dependencies</h3>\n<pre><code># Python standard library\nfrom difflib import get_close_matches\n\n# 3rd party\nimport networkx as nx\nimport pandas as pd\nfrom pyvis.network import Network\n</code></pre>\n<hr>\n<p>Recently, I was exploring <a href=\"https://www.linkedin.com/in/bradley-schoeneweis/\">my LinkedIn</a> network to see what some of my colleagues from high school and undergrad are currently up to.</p>\n<p>As I was scrolling through the connections page, I noticed LinkedIn gives you options to filter and searching with ease, but it doesn't really provide tools to learn about your network as a whole.</p>\n<p>So I decided to see if there was an easy way to export my network data to see what I could do with a few hours of exploring the data.</p>\n<h2>LinkedIn data sources</h2>\n<p>My first thought was to checkout out the <a href=\"https://www.linkedin.com/developers/\">LinkedIn's Developer API</a>.</p>\n<p>Something I do fairly frequently at my current job is integrating various 3rd-party REST APIs into our platform, so I wanted to see all the functionality and possibilities that this API would provide.</p>\n<p>After reading through some documentation, I decided this wasn't a direction I wanted to pursue. Most of their developer products require approval, so I decided to look into other options.</p>\n<p>Another thought I had was to write a quick scraping script to pull down the HTML of my connections page and parse out names and companies, but I assumed there had to be a more simple way to get this data.</p>\n<p>Finally, after a bit of research, I found that there are various \"Get a copy of your data\" reports that you can run within LinkedIn.  In order to get to these reports, you can do the following:</p>\n<ol>\n<li>On the homepage toolbar, click the <strong>Me</strong> dropdown</li>\n<li>Under the <em>Account</em> section, click <strong>Settings &#x26; Privacy</strong></li>\n<li>Click on <strong>Get a copy of your data</strong>, and you can view the various reports</li>\n<li>Select the reports you're interested in, for this, I just checked <strong>Connections</strong></li>\n</ol>\n<p>After requesting the report, it should only take a few minutes before you get an email saying your report is ready for export.</p>\n<h2>Diving into the data</h2>\n<p>To reiterate our goal, we want to get a broad understanding of the companies within the first layer of our network (direct connections). Now, let's load up Python and learn more about this data in this CSV.</p>\n<h3>Reading in the data</h3>\n<p>Once the CSV is downloaded, we can open it up with Pandas and take a look (<em>output will be commented below</em>).</p>\n<pre><code>import pandas as pd\n\n# We want to skip the first three rows because of Notes at the top\ndf = pd.read_csv('Connections.csv', skiprows=3)\n\ndf.columns\n# ['First Name', 'Last Name', 'Email Address', 'Company', 'Position', 'Connected On',]\n\ndf.info()\n\"\"\"\n&#x3C;class 'pandas.core.frame.DataFrame'>\nRangeIndex: 376 entries, 0 to 375\nData columns (total 6 columns):\n #   Column         Non-Null Count  Dtype \n---  ------         --------------  ----- \n 0   First Name     375 non-null    object\n 1   Last Name      375 non-null    object\n 2   Email Address  1 non-null      object\n 3   Company        371 non-null    object\n 4   Position       371 non-null    object\n 5   Connected On   376 non-null    object\ndtypes: object(6)\nmemory usage: 17.8+ KB\n\"\"\"\n</code></pre>\n<p>I won't post the name's of any individuals or full rows to respect the privacy of my connections, but when I searched through the my Connections CSV, I noticed a few initial patterns that would help clean up the data.</p>\n<h3>Cleaning up the data</h3>\n<p>At first glance, the first thing I notice is connections who don't list a current company, so let's get rid of those.</p>\n<pre><code>df = df[df['Company'].notna()].sort_values(by='Company')\n</code></pre>\n<p>After sorting, another thing I noticed was that some of these company names belong to the same company, but the individuals wrote them differently.</p>\n<p>An example of this is <code>'IBM Global Solution Center'</code> and <code>'IBM'</code>; for our purposes, these should both be classified as <code>IBM</code>.</p>\n<p>Let's run through a fuzzy match run using <a href=\"https://docs.python.org/3/library/difflib.html#difflib.get_close_matches\">difflib's <code>get_close_matches</code></a> to try and bucket some of these similar company names.</p>\n<pre><code>from difflib import get_close_matches\n\ncompanies = df['Company'].drop_duplicates()\n\n# cutoff=0.7 is a similarity ranking, and n=10 just takes the top 10 values\nsimilar_companies = {x: get_close_matches(x, companies, n=10, cutoff=0.7)\n                     for x in companies}\n\n# We are only interested in the entries that had another match\nsimilar_companies = {x: [name for name in y if name != x]\n                     for x, y in similar_companies.items() if len(y) > 1}\n</code></pre>\n<p>Now, this solution is not perfect, but it will help draw out some similar companies. You should still run a manual inspection of the data (the IBM example I gave above is one that doesn't show up in the fuzzy match results).</p>\n<p>Based upon the results, let's group together some of the companies that had matches.</p>\n<pre><code>df['Company'] = df['Company'].replace({\n    'KPMG US': similar_companies['KPMG US'],\n    'Self-employed': similar_companies['Self-employed'],\n    'IBM Global Solution Center': 'IBM',\n})\n</code></pre>\n<p>The next thing you may have noticed is that in our <code>similar_companies</code> dictionary, we cleaned up a <code>Self-employed</code> entry.</p>\n<p>To stay aligned with our goal, let's drop these entries, as well as your current company.</p>\n<pre><code>companies_to_drop = ['self employed', 'your current company']\ndf = df[~df['Company'].str.lower().isin(companies_to_drop)]\n</code></pre>\n<h3>Aggregating the data</h3>\n<p>Now that our data is cleaned up a bit, let's aggregate and sum the number of connections for each of the companies.</p>\n<pre><code>df_company_counts = df['Company'].value_counts().reset_index()\ndf_company_counts.columns = ['Company', 'Count']  # For ease of understanding\ndf_company_counts = df_company_counts.sort_values(by='Count', ascending=False)\n</code></pre>\n<h2>Creating the network</h2>\n<p>We have the numbers we want for each company, now let's jump into using <code>NetworkX</code> to recreate a network.</p>\n<p>The first step will be to initialize our graph, and add yourself as the central node, as it is your network.</p>\n<pre><code>import networkx as nx\n\nG = nx.Graph()\nG.add_node('Me')\n</code></pre>\n<p>Then, we'll loop through our <code>df_company_counts</code> DataFrame and add each company as a node.</p>\n<p><em>You'll notice some HTML tags in the title below, this is just to make it more readable for later</em></p>\n<pre><code>for _, row in df_company_counts.iterrows():\n\t# The title will be for more information later on\n    title = '&#x3C;b>{0}&#x3C;/b> ({1})&#x3C;br>&#x3C;hr>Positions:&#x3C;br>'.format(row['Company'],\n    \t\t\t\t\t\t\t\t\t\t\t\t\t\trow['Count'])\n\n    # In addition to the full company name, let's add each position in a\n    # list to see the roles our connections have at these companies\n    position_list = ''.join('&#x3C;li>{}&#x3C;/li>'.format(x)\n    \t\t\t\t\t\tfor x in df[df['Company'] == row['Company']]['Position'])\n    title += '&#x3C;ul>{0}&#x3C;/ul>'.format(position_list)\n\n    # For ease of viewing, limit company names to 15 letters\n    node_name = row['Company']\n    if len(node_name) > 15:\n        node_name = node_name[:15] + '...'\n\n    # Add the node and an edge connection ourself to the new node\n    G.add_node(node_name, weight=row['Count'], size=row['Count'] * 2, title=title)\n    G.add_edge('Me', node_name)\n</code></pre>\n<p>And just like that, we've created our network of connections.</p>\n<h2>Visualization</h2>\n<p>Our network graph is created, so let's get into visualizing the network.</p>\n<p>There are a few options for visualizing networks including <code>matplotlib.pyplot</code>, but I found that <code>pyvis</code> was the easiest to use for several reasons:</p>\n<ul>\n<li><code>pyvis</code> generates an HTML file</li>\n<li>Customization is made very easy</li>\n<li>The graph is interactive by default</li>\n</ul>\n<p>Let's look into generating this HTML file.</p>\n<pre><code>from pyvis.network import Network\n\nnt = Network('100%', '100%', bgcolor='#222222', font_color='white')\nnt.from_nx(G)\nnt.repulsion()  # Spaces out the nodes\nnt.show('nx.html')\n</code></pre>\n<p>And it's that simple! We specify a width and height, optional styling attributes, and then we can generate the network graph visual straight from what we created with NetworkX.</p>\n<p>Now we can see <a href=\"/network/first-nx-graph.html\">the network we generated</a>.</p>\n<p>You can hover over each node to see the total number of connections that work at the respective company, and below is a list of the positions held by your connections.</p>\n<p>As you can see, this is a bit hard to read into since there are a lot of nodes. Try and imagine reading this with +1,000 connections.</p>\n<h2>Improving the output</h2>\n<p>There are a few ways that our network could be narrowed down.</p>\n<p>Being a <em>Software Developer</em>, the thought that first occurred to me was to try and dial in on tech-related companies through known positions titles.</p>\n<p>To do this, I thought of a list of buzzwords/common job titles that I've seen across LinkedIn, and filtered down the initial DataFrame.</p>\n<p>Then, we go through the same process we did in previous sections of generating and displaying the graph.</p>\n<p><em>Again, this is not perfect, but it's a good starting point.</em></p>\n<pre><code># Filter down from a list of popular tech positions\npositions = [\n    'developer', 'engineer', 'ai', 'analytics', 'software', 'cloud', 'cto',\n    'sde', 'sre', 'saas', 'product', 'engineering', 'scientist', 'data',\n]\ndf = df[df['Position'].str.contains('|'.join(positions), case=False)]\ndf_company_counts = df['Company'].value_counts().reset_index()\ndf_company_counts.columns = ['Company', 'Count']\ndf_company_counts = df_company_counts.sort_values(by='Count', ascending=False)\n\n# Re-initialize the graph and add the nodes/edges again\nG = nx.Graph()\nG.add_node('Me')\n\nfor _, row in df_company_counts.iterrows():\n    title = '&#x3C;b>{0}&#x3C;/b> ({1})&#x3C;br>&#x3C;hr>Positions:&#x3C;br>'.format(row['Company'], row['Count'])\n    position_list = ''.join('&#x3C;li>{}&#x3C;/li>'.format(x)\n    \t\t\t\t\t\tfor x in df[df['Company'] == row['Company']]['Position'])\n    title += '&#x3C;ul>{0}&#x3C;/ul>'.format(position_list)\n    node_name = row['Company']\n    if len(node_name) > 15:\n        node_name = node_name[:15] + '...'\n\n    # Since there are less nodes, let's increase the sizes\n    G.add_node(node_name, weight=row['Count'], size=row['Count'] * 5, title=title)\n    G.add_edge('Me', node_name)\n\n# Generate the visualization\nnt = Network('100%', '100%', bgcolor='#222222', font_color='white')\nnt.from_nx(G)\nnt.repulsion()\nnt.show('nx.html')\n</code></pre>\n<p>Now, let's look at the <a href=\"/network/second-nx-graph.html\">updated results</a>.</p>\n<p>Much better! This is more readable and easier to interact with.</p>\n<p>And just like that, we achieved our goal of gaining a broader understanding of the companies in our LinkedIn network.</p>\n<hr>\n<p><strong><em>Possible improvements for those interested</em></strong></p>\n<ul>\n<li>Scraping the profile location of each of your connections to segment by location</li>\n<li>Compiling a list of companies you'd like to work for/are interested in and creating a filtering system</li>\n<li>Researching salary data for positions and gathering average pay by company</li>\n</ul>\n<hr>\n","markdown":"\n## tl;dr\n\n### Goal\n_To understand and visualize the companies within my directly connected network on LinkedIn_\n\n### Process overview\n1. **LinkedIn data sources** - retrieving LinkedIn Network data from a \"Get a copy of your data\" CSV export\n2. **Diving into the data** - exploring, cleaning, and aggregating the data with [`Pandas`](https://pandas.pydata.org/)\n3. **Creating the network** - creating a network graph using [`NetworkX`](https://networkx.org/)\n4. **Visualization** - visualizing the network with [`pyvis`](https://pyvis.readthedocs.io/en/latest/)\n5. **Improving the output** - cleaning up the network graph with additional filtering\n\n### Results\n_Hover over the nodes for more details_\n- [The first network graph](/network/first-nx-graph.html)\n- [The second (more specific) network graph](/network/second-nx-graph.html)\n\n### Python dependencies\n```python\n# Python standard library\nfrom difflib import get_close_matches\n\n# 3rd party\nimport networkx as nx\nimport pandas as pd\nfrom pyvis.network import Network\n```\n\n---\n\nRecently, I was exploring [my LinkedIn](https://www.linkedin.com/in/bradley-schoeneweis/) network to see what some of my colleagues from high school and undergrad are currently up to.\n\nAs I was scrolling through the connections page, I noticed LinkedIn gives you options to filter and searching with ease, but it doesn't really provide tools to learn about your network as a whole.\n\nSo I decided to see if there was an easy way to export my network data to see what I could do with a few hours of exploring the data.\n\n\n## LinkedIn data sources\n\nMy first thought was to checkout out the [LinkedIn's Developer API](https://www.linkedin.com/developers/).\n\nSomething I do fairly frequently at my current job is integrating various 3rd-party REST APIs into our platform, so I wanted to see all the functionality and possibilities that this API would provide.\n\nAfter reading through some documentation, I decided this wasn't a direction I wanted to pursue. Most of their developer products require approval, so I decided to look into other options.\n\nAnother thought I had was to write a quick scraping script to pull down the HTML of my connections page and parse out names and companies, but I assumed there had to be a more simple way to get this data.\n\nFinally, after a bit of research, I found that there are various \"Get a copy of your data\" reports that you can run within LinkedIn.  In order to get to these reports, you can do the following:\n1. On the homepage toolbar, click the **Me** dropdown\n2. Under the _Account_ section, click **Settings & Privacy**\n3. Click on **Get a copy of your data**, and you can view the various reports\n4. Select the reports you're interested in, for this, I just checked **Connections**\n\nAfter requesting the report, it should only take a few minutes before you get an email saying your report is ready for export.\n\n\n## Diving into the data\n\nTo reiterate our goal, we want to get a broad understanding of the companies within the first layer of our network (direct connections). Now, let's load up Python and learn more about this data in this CSV.\n\n### Reading in the data\nOnce the CSV is downloaded, we can open it up with Pandas and take a look (_output will be commented below_).\n\n```python\nimport pandas as pd\n\n# We want to skip the first three rows because of Notes at the top\ndf = pd.read_csv('Connections.csv', skiprows=3)\n\ndf.columns\n# ['First Name', 'Last Name', 'Email Address', 'Company', 'Position', 'Connected On',]\n\ndf.info()\n\"\"\"\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 376 entries, 0 to 375\nData columns (total 6 columns):\n #   Column         Non-Null Count  Dtype \n---  ------         --------------  ----- \n 0   First Name     375 non-null    object\n 1   Last Name      375 non-null    object\n 2   Email Address  1 non-null      object\n 3   Company        371 non-null    object\n 4   Position       371 non-null    object\n 5   Connected On   376 non-null    object\ndtypes: object(6)\nmemory usage: 17.8+ KB\n\"\"\"\n```\n\nI won't post the name's of any individuals or full rows to respect the privacy of my connections, but when I searched through the my Connections CSV, I noticed a few initial patterns that would help clean up the data.\n\n### Cleaning up the data\n\nAt first glance, the first thing I notice is connections who don't list a current company, so let's get rid of those.\n\n```python\ndf = df[df['Company'].notna()].sort_values(by='Company')\n```\n\nAfter sorting, another thing I noticed was that some of these company names belong to the same company, but the individuals wrote them differently.\n\nAn example of this is `'IBM Global Solution Center'` and `'IBM'`; for our purposes, these should both be classified as `IBM`.\n\nLet's run through a fuzzy match run using [difflib's `get_close_matches`](https://docs.python.org/3/library/difflib.html#difflib.get_close_matches) to try and bucket some of these similar company names.\n```python\nfrom difflib import get_close_matches\n\ncompanies = df['Company'].drop_duplicates()\n\n# cutoff=0.7 is a similarity ranking, and n=10 just takes the top 10 values\nsimilar_companies = {x: get_close_matches(x, companies, n=10, cutoff=0.7)\n                     for x in companies}\n\n# We are only interested in the entries that had another match\nsimilar_companies = {x: [name for name in y if name != x]\n                     for x, y in similar_companies.items() if len(y) > 1}\n```\n\nNow, this solution is not perfect, but it will help draw out some similar companies. You should still run a manual inspection of the data (the IBM example I gave above is one that doesn't show up in the fuzzy match results).\n\nBased upon the results, let's group together some of the companies that had matches.\n```python\ndf['Company'] = df['Company'].replace({\n    'KPMG US': similar_companies['KPMG US'],\n    'Self-employed': similar_companies['Self-employed'],\n    'IBM Global Solution Center': 'IBM',\n})\n```\n\nThe next thing you may have noticed is that in our `similar_companies` dictionary, we cleaned up a `Self-employed` entry.\n\nTo stay aligned with our goal, let's drop these entries, as well as your current company.\n```python\ncompanies_to_drop = ['self employed', 'your current company']\ndf = df[~df['Company'].str.lower().isin(companies_to_drop)]\n```\n\n### Aggregating the data\nNow that our data is cleaned up a bit, let's aggregate and sum the number of connections for each of the companies.\n\n```python\ndf_company_counts = df['Company'].value_counts().reset_index()\ndf_company_counts.columns = ['Company', 'Count']  # For ease of understanding\ndf_company_counts = df_company_counts.sort_values(by='Count', ascending=False)\n```\n\n## Creating the network\n\nWe have the numbers we want for each company, now let's jump into using `NetworkX` to recreate a network.\n\nThe first step will be to initialize our graph, and add yourself as the central node, as it is your network.\n\n```python\nimport networkx as nx\n\nG = nx.Graph()\nG.add_node('Me')\n```\n\nThen, we'll loop through our `df_company_counts` DataFrame and add each company as a node.\n\n_You'll notice some HTML tags in the title below, this is just to make it more readable for later_\n```python\nfor _, row in df_company_counts.iterrows():\n\t# The title will be for more information later on\n    title = '<b>{0}</b> ({1})<br><hr>Positions:<br>'.format(row['Company'],\n    \t\t\t\t\t\t\t\t\t\t\t\t\t\trow['Count'])\n\n    # In addition to the full company name, let's add each position in a\n    # list to see the roles our connections have at these companies\n    position_list = ''.join('<li>{}</li>'.format(x)\n    \t\t\t\t\t\tfor x in df[df['Company'] == row['Company']]['Position'])\n    title += '<ul>{0}</ul>'.format(position_list)\n\n    # For ease of viewing, limit company names to 15 letters\n    node_name = row['Company']\n    if len(node_name) > 15:\n        node_name = node_name[:15] + '...'\n\n    # Add the node and an edge connection ourself to the new node\n    G.add_node(node_name, weight=row['Count'], size=row['Count'] * 2, title=title)\n    G.add_edge('Me', node_name)\n```\n\nAnd just like that, we've created our network of connections.\n\n\n## Visualization\n\nOur network graph is created, so let's get into visualizing the network.\n\nThere are a few options for visualizing networks including `matplotlib.pyplot`, but I found that `pyvis` was the easiest to use for several reasons:\n- `pyvis` generates an HTML file\n- Customization is made very easy\n- The graph is interactive by default\n\nLet's look into generating this HTML file.\n```python\nfrom pyvis.network import Network\n\nnt = Network('100%', '100%', bgcolor='#222222', font_color='white')\nnt.from_nx(G)\nnt.repulsion()  # Spaces out the nodes\nnt.show('nx.html')\n```\n\nAnd it's that simple! We specify a width and height, optional styling attributes, and then we can generate the network graph visual straight from what we created with NetworkX.\n\nNow we can see [the network we generated](/network/first-nx-graph.html).\n\nYou can hover over each node to see the total number of connections that work at the respective company, and below is a list of the positions held by your connections.\n\nAs you can see, this is a bit hard to read into since there are a lot of nodes. Try and imagine reading this with +1,000 connections.\n\n## Improving the output\n\nThere are a few ways that our network could be narrowed down.\n\nBeing a _Software Developer_, the thought that first occurred to me was to try and dial in on tech-related companies through known positions titles.\n\nTo do this, I thought of a list of buzzwords/common job titles that I've seen across LinkedIn, and filtered down the initial DataFrame.\n\nThen, we go through the same process we did in previous sections of generating and displaying the graph.\n\n_Again, this is not perfect, but it's a good starting point._\n```python\n# Filter down from a list of popular tech positions\npositions = [\n    'developer', 'engineer', 'ai', 'analytics', 'software', 'cloud', 'cto',\n    'sde', 'sre', 'saas', 'product', 'engineering', 'scientist', 'data',\n]\ndf = df[df['Position'].str.contains('|'.join(positions), case=False)]\ndf_company_counts = df['Company'].value_counts().reset_index()\ndf_company_counts.columns = ['Company', 'Count']\ndf_company_counts = df_company_counts.sort_values(by='Count', ascending=False)\n\n# Re-initialize the graph and add the nodes/edges again\nG = nx.Graph()\nG.add_node('Me')\n\nfor _, row in df_company_counts.iterrows():\n    title = '<b>{0}</b> ({1})<br><hr>Positions:<br>'.format(row['Company'], row['Count'])\n    position_list = ''.join('<li>{}</li>'.format(x)\n    \t\t\t\t\t\tfor x in df[df['Company'] == row['Company']]['Position'])\n    title += '<ul>{0}</ul>'.format(position_list)\n    node_name = row['Company']\n    if len(node_name) > 15:\n        node_name = node_name[:15] + '...'\n\n    # Since there are less nodes, let's increase the sizes\n    G.add_node(node_name, weight=row['Count'], size=row['Count'] * 5, title=title)\n    G.add_edge('Me', node_name)\n\n# Generate the visualization\nnt = Network('100%', '100%', bgcolor='#222222', font_color='white')\nnt.from_nx(G)\nnt.repulsion()\nnt.show('nx.html')\n```\n\nNow, let's look at the [updated results](/network/second-nx-graph.html).\n\nMuch better! This is more readable and easier to interact with.\n\nAnd just like that, we achieved our goal of gaining a broader understanding of the companies in our LinkedIn network.\n\n---\n\n**_Possible improvements for those interested_**\n- Scraping the profile location of each of your connections to segment by location\n- Compiling a list of companies you'd like to work for/are interested in and creating a filtering system\n- Researching salary data for positions and gathering average pay by company\n\n---\n","title":"Visualizing your LinkedIn Connections using Python","date":"2021-04-08","tags":["python","pandas","networkx","data-analysis"],"description":"Using Python's Pandas, NetworkX, and pyvis to understand and visualize companies within a directly connected LinkedIn network."}]},"__N_SSG":true}