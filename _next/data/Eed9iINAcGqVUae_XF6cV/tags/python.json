{"pageProps":{"tag":"python","taggedPosts":[{"id":"converting-html-to-pdf","contentHtml":"<h2>tl;dr</h2>\n<h3>Goal</h3>\n<p><em>To set up an easy to call HTML to PDF converter as an AWS Lambda function.</em></p>\n<h3>Process Overview</h3>\n<ol>\n<li><strong>Downloading the <code>wkhtmltopdf</code> binary</strong></li>\n<li><strong>Creating the AWS Lambda layer(s) and configuring our function</strong></li>\n<li><strong>Writing the AWS Lambda function</strong>\n<ul>\n<li>We will use Python's <a href=\"https://docs.python.org/3/library/subprocess.html\"><code>subprocess</code> module</a> to call the <code>wkhtmltopdf</code> command</li>\n<li>For more in-depth Python focused usage, also check out <a href=\"https://pypi.org/project/pdfkit/\">pdfkit</a></li>\n</ul>\n</li>\n</ol>\n<h3>Prerequisites</h3>\n<p>This article assumes access to an AWS account (free-tier is acceptable) and basic knowledge of AWS Lambda/S3 and Python.</p>\n<h3>Functional Requirements</h3>\n<ol>\n<li>Allow passing either an S3 file key or an HTML string</li>\n<li>Return a file key for the generated PDF</li>\n<li>Accept a small set of options for the <code>wkhtmltopdf</code> command\n<ul>\n<li>A full man page can be found <a href=\"https://wkhtmltopdf.org/usage/wkhtmltopdf.txt\">here</a></li>\n<li>Most of the ones we'd want anyways are the default (i.e. <code>--images</code>, <code>--enable-external-links</code>, etc.)</li>\n</ul>\n</li>\n</ol>\n<p>Functionality for the following options</p>\n<ul>\n<li><code>--orientation &#x3C;orientation></code></li>\n<li><code>--title &#x3C;text></code></li>\n<li><code>--margin-bottom &#x3C;unitreal></code></li>\n<li><code>--margin-left &#x3C;unitreal></code></li>\n<li><code>--margin-right &#x3C;unitreal></code></li>\n<li><code>--margin-top &#x3C;unitreal></code></li>\n</ul>\n<h3>Assumptions</h3>\n<ol>\n<li>The HTML string or file will be valid and will include the necessary tags (<code>&#x3C;!DOCTYPE html></code>, <code>&#x3C;html></code>, <code>&#x3C;head></code>, <code>&#x3C;body></code>). <strong>It is very important that you check validity of this HTML prior to calling this function if you ever use something similar in production. It may be best to only accept S3 file keys instead of HTML strings, but this is simply to show our functions possibilities or be used as an internal tool.</strong></li>\n<li>The event payload will contain all valid values (S3 bucket name, file key, <code>wkhtmltopdf</code> options etc.)</li>\n</ol>\n<h3>Notes</h3>\n<p>This article will use <code>us-east-2</code> for the AWS region, changing this shouldn't effect functionality, just the links within the article.</p>\n<p>A better way to do this is through <a href=\"https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/what-is-sam.html\">AWS Serverless Application Model (SAM)</a>, but this is more tailored for those looking for the basic setup through the AWS Management Console.</p>\n<hr>\n<p>A common task I've found myself undertaking recently is programmatically converting an HTML file/string to an embedded and stylized PDF file.</p>\n<p>An example use case for this might be exporting a self-managed customer invoice or generating a daily report from an existing HTML template. For those who have used template languages before, you can probably imagine the usefulness of a function like this in combination with <a href=\"https://jinja.palletsprojects.com/en/2.11.x/\">Jinja</a> or template rendering engines commonly found in Web Frameworks (like <a href=\"https://www.djangoproject.com/\">Django</a>).</p>\n<p>After doing some research on third party libraries that could simplify our goal, I decided to use <a href=\"https://wkhtmltopdf.org/\"><code>wkhtmltopdf</code></a>.</p>\n<p><code>wkhtmltopdf</code> is an open-source command line tool that enables you to easy convert an HTML file to a PDF file. This is exactly what we're looking for. We will call the <code>wkhtmltopdf</code> command using the <a href=\"https://docs.python.org/3/library/subprocess.html\"><code>subprocess</code></a> Python library. For more in-depth Python usage, you can check out <a href=\"https://pypi.org/project/pdfkit/\">pdfkit</a>.</p>\n<p>Let's dive into it.</p>\n<hr>\n<h2>Why AWS Lambda?</h2>\n<p><a href=\"https://aws.amazon.com/lambda/\">AWS Lambda</a> provides serverless computing functions where you don't need to manage any servers or containers, you can simply call your function synchronously or asynchronously, and it will be executed and scaled automatically.</p>\n<p>Lambda has a ton of use cases and is something I have personally used many times and am a big fan of.</p>\n<p><em>For our goal, AWS Lambda is a powerful tool for the following reasons</em></p>\n<ul>\n<li>It allows us to offload processing away from the server\n<ul>\n<li>This is more of a general benefit, we won't actually be calling this function from a running server</li>\n<li>These calls will also be scaled automatically</li>\n</ul>\n</li>\n<li>Our dependencies, specifically the <code>wkhtmltopdf</code> binary, can be handled well through <a href=\"https://docs.aws.amazon.com/lambda/latest/dg/configuration-layers.html\">AWS Lambda layers</a>\n<ul>\n<li>This helps to avoid dealing with different Linux distributions or multiple installation locations</li>\n</ul>\n</li>\n</ul>\n<p><strong>Below is an explanation of why handling the dependencies through layers will avoid issues. For continued instruction, you can skip to the next section.</strong></p>\n<h3>Issues with downloading the binary</h3>\n<p>When I was first using this library, I was also using <a href=\"https://pypi.org/project/pdfkit/\"><code>pdfkit</code></a> to drive this interaction.  At the top of the installation instructions, you can see the following warning:</p>\n<p>When I first installed <code>wkhtmltopdf</code>, I didn't heed the warning and just ran the following:</p>\n<pre><code>sudo apt-get install wkhtmltopdf\n</code></pre>\n<p>On initial inspection, I wasn't experiencing the problems they mentioned (<em>at least in my local environment</em>). The issues came when I actually pushed up code using this library to a staging environment and I noticed the PDFs were no longer generating.</p>\n<p>I was able to remedy this by installing in an alternative way:</p>\n<pre><code>sudo apt-get remove --purge wkhtmltopdf\nwget https://github.com/wkhtmltopdf/packaging/releases/download/0.12.6-1/wkhtmltox_0.12.6-1.bionic_amd64.deb\nsudo dpkg -i wkhtmltox_0.12.6-1.bionic_amd64.deb\nrm wkhtmltox_0.12.6-1.bionic_amd64.deb\n</code></pre>\n<p>This isn't a big deal, but managing this dependency could get tedious if your architecture has multiple servers that need installed with different Linux distributions.</p>\n<p>Putting this binary into an AWS Lambda Layer can help solve this by having a single point of installation and management.</p>\n<h2>Downloading the <code>wkhtmltopdf</code> binary</h2>\n<p>The <code>wkhtmltopdf</code> site actually lists using this library with AWS Lambda as a <a href=\"https://wkhtmltopdf.org/downloads.html#how-do-i-use-it-in-aws-lambda\">FAQ</a> and gives the following response to this question:</p>\n<p><em>\"All files required for lambda layer are packed in one zip archive (Amazon Linux 2 / lambda zip)\"</em></p>\n<p>You can download the binary on the releases page under the <a href=\"https://wkhtmltopdf.org/downloads.html#stable\">Stable releases</a>. You'll see an entry under <code>Amazon Linux</code> with <code>lambda zip</code> as the architecture.</p>\n<p>Or, you can click <a href=\"https://github.com/wkhtmltopdf/packaging/releases/download/0.12.6-4/wkhtmltox-0.12.6-4.amazonlinux2_lambda.zip\">here</a> (I likely won't update this link, so probably best to go directly to the release page).</p>\n<p><em>Random note:</em> If you need more fonts for future usage, I've found that <a href=\"https://github.com/brandonlim-hs/fonts-aws-lambda-layer\">this is a good resource</a>. You may need to include one of these fonts as a layer in your lambda function (via ARN) if your function has issues in the beginning.</p>\n<h2>Creating the AWS Lambda layers</h2>\n<p><a href=\"https://docs.aws.amazon.com/lambda/latest/dg/configuration-layers.html\">AWS Lambda layers</a> allow us to add in \"layers\" of dependencies for our functions. An alternative to this is uploading your lambda function as a deployment package or using AWS SAM (Serverless Application Model), but that is out of the scope of this post.</p>\n<h3><code>wkhtmltopdf</code></h3>\n<p>Now that we have the zip file downloaded, let's add our file as a layer in the <a href=\"https://us-east-2.console.aws.amazon.com/console/home?region=us-east-2\">AWS Management Console</a>.</p>\n<p>Go to the <a href=\"https://us-east-2.console.aws.amazon.com/lambda/home?region=us-east-2#/layers\">Layers section</a> on the AWS Lambda page and click <code>Create layer</code>.</p>\n<p>Then, add the following Layer configuration.</p>\n<p><img src=\"/images/converting-html-to-pdf/layer-configuration.jpg\" alt=\"AWS Lambda layer configuration {priority}{680x488}\"></p>\n<p>Notice that we don't add a runtime here, this is intentional since our layer is a binary.</p>\n<p>Click Create and take note of your new layer's Version ARN as we are about to use it to add to our function.</p>\n<p>Now we're set up to create our function!</p>\n<h2>Writing the AWS Lambda function</h2>\n<p>Navigate to the <a href=\"https://us-east-2.console.aws.amazon.com/lambda/home?region=us-east-2#/functions\">Functions page</a> within the AWS Lambda service and click <code>Create function</code>.</p>\n<p>Select <code>Author from scratch</code>, and add the following configuration.</p>\n<p><img src=\"/images/converting-html-to-pdf/function-configuration.jpg\" alt=\"AWS Lambda function configuration {1004x475}\"></p>\n<p>You can ignore the <code>Advanced settings</code> for our use case.</p>\n<p>Once the function is created, we have just a few configuration additions to make.</p>\n<h3>Adding the layer to our Lambda function</h3>\n<p>Now that our function is created, the first thing we want to do is add our <code>wkhtmltopdf</code> layer.</p>\n<p>At the top of the Function Overview panel, click the <code>Layers</code> button right below your function name. This will bring you down to the layers section. Now click Add a layer.</p>\n<p>Click on <code>Specify an ARN</code> and copy your Layer Version ARN from earlier.</p>\n<p><img src=\"/images/converting-html-to-pdf/add-layer.jpg\" alt=\"AWS Lambda add layer {680x316}\"></p>\n<p>The reason why we need to specify our layer by ARN is because we didn't define a runtime above.</p>\n<h3>Add permission to access your S3 bucket</h3>\n<p>One final function configuration that we need to add is permission for our function to access Amazon S3.  To do this, navigate to the Configuration tab below your Function Overview.</p>\n<p>Under Configuration, go to the Permissions section. Here, you will see your generated Execution Role. Click this link to go to the IAM Console.</p>\n<p>From here, click Attach policies, and add the <strong>AmazonS3FullAccess</strong> policy like so</p>\n<p><img src=\"/images/converting-html-to-pdf/iam-policy.jpg\" alt=\"AWS Lambda IAM policy {1004x461}\"></p>\n<p>Now that our function is configured, we can dive into the actual requirements and code!</p>\n<h3>Requirements</h3>\n<ol>\n<li>Allow passing either an S3 file key or an HTML string</li>\n<li>Return a file key for the generated PDF</li>\n<li>Accept a small set of options for the <code>wkhtmltopdf</code> command\n<ul>\n<li>A full man page can be found <a href=\"https://wkhtmltopdf.org/usage/wkhtmltopdf.txt\">here</a></li>\n<li>Most of the ones we'd want anyways are the default (i.e. <code>--images</code>, <code>--enable-external-links</code>, etc.)</li>\n</ul>\n</li>\n</ol>\n<p>Let's allow the user to pass the following options</p>\n<ul>\n<li><code>--orientation &#x3C;orientation></code> - the common page orientation for the PDF file.\n<ul>\n<li>Valid values are <code>Landscape</code> or <code>Portrait</code></li>\n</ul>\n</li>\n<li><code>--title &#x3C;text></code> - the title of the generated file.</li>\n<li>The margins of the file\n<ul>\n<li><code>--margin-bottom &#x3C;unitreal></code></li>\n<li><code>--margin-left &#x3C;unitreal></code> (default is 10mm)</li>\n<li><code>--margin-right &#x3C;unitreal></code>  (default is 10mm)</li>\n<li><code>--margin-top &#x3C;unitreal></code></li>\n</ul>\n</li>\n</ul>\n<h3>Assumptions</h3>\n<ol>\n<li>The HTML string or file will be valid and will include the necessary tags (<code>&#x3C;!DOCTYPE html></code>, <code>&#x3C;html></code>, <code>&#x3C;head></code>, <code>&#x3C;body></code>)</li>\n<li>The event payload will contain all valid values (S3 bucket name, file key, <code>wkhtmltopdf</code> options etc.)</li>\n</ol>\n<h3>The function code</h3>\n<p>By default, you will see the following handler.</p>\n<pre><code>def lambda_handler(event, context):\n    # TODO implement\n    return {\n        'statusCode': 200,\n        'body': json.dumps('Hello from Lambda!')\n    }\n</code></pre>\n<p>This is the code that will be executed when your function is called. We'll come back to this in a bit.</p>\n<h4>The imports</h4>\n<p>First, let's go ahead and import all of the Python libraries that we'll need and set up some basic tools like the <code>S3 client</code> and our <code>logger</code>.</p>\n<pre><code>from datetime import datetime\nimport json\nimport logging\nimport os\nimport subprocess\nfrom typing import Optional\n\nimport boto3\nfrom botocore.exceptions import ClientError\n\n\n# Set up logging\nlogger = logging.getLogger()\nlogger.setLevel(logging.INFO)\n\n# Get the s3 client\ns3 = boto3.client('s3')\n</code></pre>\n<p>Now based upon our requirements, we'll need helper functions to</p>\n<ol>\n<li>Download an HTML file from S3</li>\n<li>Upload a file to S3</li>\n</ol>\n<p>Let's start with those, and then we'll return to our lambda handler.</p>\n<h4>Downloading/uploading the file</h4>\n<p><a href=\"https://boto3.amazonaws.com/v1/documentation/api/latest/index.html\"><code>boto3</code></a> makes it really easy to interact with S3.  Using <code>boto3</code>, we can add the following helper functions.</p>\n<pre><code>def download_s3_file(bucket: str, file_key: str) -> str:\n    \"\"\"Downloads a file from s3 to `/tmp/[File Key]`.\n    \n    Args:\n        bucket (str): Name of the bucket where the file lives.\n        file_key (str): The file key of the file in the bucket.\n\n    Returns:\n        The local file name as a string.\n    \"\"\"\n    local_filename = f'/tmp/{file_key}'\n    s3.download_file(Bucket=bucket, Key=file_key, Filename=local_filename)\n    logger.info('Downloaded HTML file to %s' % local_filename)\n\n    return local_filename\n    \n    \ndef upload_file_to_s3(bucket: str, filename: str) -> Optional[str]:\n    \"\"\"Uploads the generated PDF to s3.\n    \n    Args:\n        bucket (str): Name of the s3 bucket to upload the PDF to.\n        filename (str): Location of the file to upload to s3.\n        \n    Returns:\n        The file key of the file in s3 if the upload was successful.\n        If the upload failed, then `None` will be returned.\n    \"\"\"\n    file_key = None\n    try:\n        file_key = filename.replace('/tmp/', '')\n        s3.upload_file(Filename=filename, Bucket=bucket, Key=file_key)\n        logger.info('Successfully uploaded the PDF to %s as %s'\n                    % (bucket, file_key))\n    except ClientError as e:\n        logger.error('Failed to upload file to s3.')\n        logger.error(e)\n        file_key = None\n        \n    return file_key\n</code></pre>\n<h4>Parsing the event</h4>\n<p>One thing we haven't talked about yet is the data that we'll need to pass our function.</p>\n<p>Let's define our JSON event schema as the following.</p>\n<pre><code>{\n    \"bucket\": \"&#x3C;Name of the bucket where the file is stored currently and will be stored after processing> [Required]\",\n    \"file_key\": \"&#x3C;File key where the file is store in S3> [Required if `html_string` is not defined]\",\n    \"html_string\": \"&#x3C;HTML string to convert to a PDF> [Required if `file_key` is not defined]\",\n    \"wkhtmltopdf_options\": {\n        \"orientation\": \"&#x3C;`landscape` or `portrait`> [Optional: Default is `portrait`]\",\n        \"title\": \"&#x3C;Title of the PDF> [Optional]\",\n        \"margin\": \"&#x3C;Margin of the PDF (same format as css [&#x3C;top> &#x3C;right> &#x3C;bottom> &#x3C;left>] (all must be included)).> [Optional]\"\n    }\n}\n</code></pre>\n<p><code>wkhtmltopdf_options</code> is an optional object. If the included options are not valid, they will not be included.</p>\n<p>We can access all of the data passed to our function from the <code>event</code> parameter in the <code>lambda_handler</code> function.</p>\n<p>Now, let's jump back to the <code>lambda_handler</code> function and add some code to pull out the data from our event and put together the remaining pieces of actually calling the <code>wkhtmltopdf</code> executable to finish our lambda function.</p>\n<pre><code>def lambda_handler(event, context):\n    logger.info(event)\n\n    # bucket is always required\n    try:\n        bucket = event['bucket']\n    except KeyError:\n        error_message = 'Missing required \"bucket\" parameter from request payload.'\n        logger.error(error_message)\n        return {\n            'status': 400,\n            'body': json.dumps(error_message),\n        }\n\n    # html_string and file_key are conditionally required, so let's try to get both\n    try:\n        file_key = event['file_key']\n    except KeyError:\n        file_key = None\n\n    try:\n        html_string = event['html_string']\n    except KeyError:\n        html_string = None\n\n    if file_key is None and html_string is None:\n        error_message = (\n            'Missing both a \"file_key\" and \"html_string\" '\n            'from request payload. One of these must be '\n            'included.'\n        )\n        logger.error(error_message)\n        return {\n            'status': 400,\n            'body': json.dumps(error_message),\n        }\n\n    # Now we can check for the option wkhtmltopdf_options and map them to values\n    # Again, part of our assumptions are that these are valid\n    wkhtmltopdf_options = {}\n    if 'wkhtmltopdf_options' in event:\n        # Margin is &#x3C;top> &#x3C;right> &#x3C;bottom> &#x3C;left>\n        if 'margin' in event['wkhtmltopdf_options']:\n            margins = event['wkhtmltopdf_options']['margin'].split(' ')\n            if len(margins) == 4:\n                wkhtmltopdf_options['margin-top'] = margins[0]\n                wkhtmltopdf_options['margin-right'] = margins[1]\n                wkhtmltopdf_options['margin-bottom'] = margins[2]\n                wkhtmltopdf_options['margin-left'] = margins[3]\n\n        if 'orientation' in event['wkhtmltopdf_options']:\n            wkhtmltopdf_options['orientation'] = 'portrait' \\\n                if event['wkhtmltopdf_options']['orientation'].lower() not in ['portrait', 'landscape'] \\\n                else event['wkhtmltopdf_options']['orientation'].lower()\n\n        if 'title' in event['wkhtmltopdf_options']:\n            wkhtmltopdf_options['title'] = event['wkhtmltopdf_options']['title']\n\n    # If we got a file_key in the request, let's download our file\n    # If not, we'll write the HTML string to a file\n    if file_key is not None:\n        local_filename = download_s3_file(bucket, file_key)\n    else:\n        timestamp = str(datetime.now()).replace('.', '').replace(' ', '_')\n        local_filename = f'/tmp/{timestamp}-html-string.html'\n\n        # Delete any existing files with that name\n        try:\n            os.unlink(local_filename)\n        except FileNotFoundError:\n            pass\n\n        with open(local_filename, 'w') as f:\n            f.write(html_string)\n\n    # Now we can create our command string to execute and upload the result to s3\n    command = 'wkhtmltopdf  --load-error-handling ignore'  # ignore unecessary errors\n    for key, value in wkhtmltopdf_options.items():\n        if key == 'title':\n            value = f'\"{value}\"'\n        command += ' --{0} {1}'.format(key, value)\n    command += ' {0} {1}'.format(local_filename, local_filename.replace('.html', '.pdf'))\n\n    # Important! Remember, we said that we are assuming we're accepting valid HTML\n    # this should always be checked to avoid allowing any string to be executed\n    # from this command. The reason we use shell=True here is because our title\n    # can be multiple words.\n    subprocess.run(command, shell=True)\n    logger.info('Successfully generated the PDF.')\n    file_key = upload_file_to_s3(bucket, local_filename.replace('.html', '.pdf'))\n\n    if file_key is None:\n        error_message = (\n            'Failed to generate PDF from the given HTML file.'\n            ' Please check to make sure the file is valid HTML.'\n        )\n        logger.error(error_message)\n        return {\n            'status': 400,\n            'body': json.dumps(error_message),\n        }\n\n    return {\n        'status': 200,\n        'file_key': file_key,\n    }\n</code></pre>\n<p>Now you can go to the <strong>Test</strong> tab and create the following test event (change your bucket name as necessary)</p>\n<pre><code>{\n    \"bucket\": \"bucket-for-articles\",\n    \"html_string\": \"&#x3C;!DOCTYPE html>&#x3C;html>&#x3C;head>&#x3C;/head>&#x3C;body>This is an example of a simple HTML page.&#x3C;/body>&#x3C;/html>\",\n    \"wkhtmltopdf_options\": {\n        \"orientation\": \"portrait\",\n        \"title\": \"Test PDF Generation\",\n        \"margin\": \"10mm 10mm 10mm 10mm\"\n    }\n}\n</code></pre>\n<p>You should get a return event with a <code>status</code> of <code>200</code>, and a <code>file_key</code> of your converted file, thus achieving our goal! ðŸŽ‰</p>\n<hr>\n","markdown":"\n## tl;dr\n\n### Goal\n_To set up an easy to call HTML to PDF converter as an AWS Lambda function._\n\n### Process Overview\n1. **Downloading the `wkhtmltopdf` binary**\n2. **Creating the AWS Lambda layer(s) and configuring our function**\n3. **Writing the AWS Lambda function**\n    - We will use Python's [`subprocess` module](https://docs.python.org/3/library/subprocess.html) to call the `wkhtmltopdf` command\n    - For more in-depth Python focused usage, also check out [pdfkit](https://pypi.org/project/pdfkit/)\n\n### Prerequisites\nThis article assumes access to an AWS account (free-tier is acceptable) and basic knowledge of AWS Lambda/S3 and Python.\n\n### Functional Requirements\n\n1. Allow passing either an S3 file key or an HTML string\n2. Return a file key for the generated PDF\n3. Accept a small set of options for the `wkhtmltopdf` command\n    - A full man page can be found [here](https://wkhtmltopdf.org/usage/wkhtmltopdf.txt)\n    - Most of the ones we'd want anyways are the default (i.e. `--images`, `--enable-external-links`, etc.)\n\nFunctionality for the following options\n- `--orientation <orientation>`\n- `--title <text>`\n- `--margin-bottom <unitreal>`\n- `--margin-left <unitreal>`\n- `--margin-right <unitreal>`\n- `--margin-top <unitreal>`\n\n### Assumptions\n\n1. The HTML string or file will be valid and will include the necessary tags (`<!DOCTYPE html>`, `<html>`, `<head>`, `<body>`). **It is very important that you check validity of this HTML prior to calling this function if you ever use something similar in production. It may be best to only accept S3 file keys instead of HTML strings, but this is simply to show our functions possibilities or be used as an internal tool.**\n2. The event payload will contain all valid values (S3 bucket name, file key, `wkhtmltopdf` options etc.)\n\n### Notes\nThis article will use `us-east-2` for the AWS region, changing this shouldn't effect functionality, just the links within the article.\n\nA better way to do this is through [AWS Serverless Application Model (SAM)](https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/what-is-sam.html), but this is more tailored for those looking for the basic setup through the AWS Management Console.\n\n---\nA common task I've found myself undertaking recently is programmatically converting an HTML file/string to an embedded and stylized PDF file.\n\nAn example use case for this might be exporting a self-managed customer invoice or generating a daily report from an existing HTML template. For those who have used template languages before, you can probably imagine the usefulness of a function like this in combination with [Jinja](https://jinja.palletsprojects.com/en/2.11.x/) or template rendering engines commonly found in Web Frameworks (like [Django](https://www.djangoproject.com/)).\n\nAfter doing some research on third party libraries that could simplify our goal, I decided to use [`wkhtmltopdf`](https://wkhtmltopdf.org/).\n\n`wkhtmltopdf` is an open-source command line tool that enables you to easy convert an HTML file to a PDF file. This is exactly what we're looking for. We will call the `wkhtmltopdf` command using the [`subprocess`](https://docs.python.org/3/library/subprocess.html) Python library. For more in-depth Python usage, you can check out [pdfkit](https://pypi.org/project/pdfkit/).\n\nLet's dive into it.\n\n---\n\n## Why AWS Lambda?\n[AWS Lambda](https://aws.amazon.com/lambda/) provides serverless computing functions where you don't need to manage any servers or containers, you can simply call your function synchronously or asynchronously, and it will be executed and scaled automatically.\n\nLambda has a ton of use cases and is something I have personally used many times and am a big fan of.\n\n_For our goal, AWS Lambda is a powerful tool for the following reasons_\n- It allows us to offload processing away from the server\n    - This is more of a general benefit, we won't actually be calling this function from a running server\n    - These calls will also be scaled automatically\n- Our dependencies, specifically the `wkhtmltopdf` binary, can be handled well through [AWS Lambda layers](https://docs.aws.amazon.com/lambda/latest/dg/configuration-layers.html)\n    - This helps to avoid dealing with different Linux distributions or multiple installation locations\n\n**Below is an explanation of why handling the dependencies through layers will avoid issues. For continued instruction, you can skip to the next section.**\n\n### Issues with downloading the binary\nWhen I was first using this library, I was also using [`pdfkit`](https://pypi.org/project/pdfkit/) to drive this interaction.  At the top of the installation instructions, you can see the following warning:\n\n<p style=\"background-color: orange; padding: 7px 20px; text-align: center; border-radius: 6px;\">\n<i>\"<b>Warning!</b>Version in debian/ubuntu repos have reduced functionality (because it compiled without the wkhtmltopdf QT patches), such as adding outlines, headers, footers, TOC etc. To use this options you should install static binary from wkhtmltopdf site\"</i>\n</p>\n\nWhen I first installed `wkhtmltopdf`, I didn't heed the warning and just ran the following:\n```bash\nsudo apt-get install wkhtmltopdf\n```\n\nOn initial inspection, I wasn't experiencing the problems they mentioned (_at least in my local environment_). The issues came when I actually pushed up code using this library to a staging environment and I noticed the PDFs were no longer generating.\n\nI was able to remedy this by installing in an alternative way:\n```bash\nsudo apt-get remove --purge wkhtmltopdf\nwget https://github.com/wkhtmltopdf/packaging/releases/download/0.12.6-1/wkhtmltox_0.12.6-1.bionic_amd64.deb\nsudo dpkg -i wkhtmltox_0.12.6-1.bionic_amd64.deb\nrm wkhtmltox_0.12.6-1.bionic_amd64.deb\n```\n\nThis isn't a big deal, but managing this dependency could get tedious if your architecture has multiple servers that need installed with different Linux distributions.\n\nPutting this binary into an AWS Lambda Layer can help solve this by having a single point of installation and management.\n\n## Downloading the `wkhtmltopdf` binary\nThe `wkhtmltopdf` site actually lists using this library with AWS Lambda as a [FAQ](https://wkhtmltopdf.org/downloads.html#how-do-i-use-it-in-aws-lambda) and gives the following response to this question:\n\n_\"All files required for lambda layer are packed in one zip archive (Amazon Linux 2 / lambda zip)\"_\n\nYou can download the binary on the releases page under the [Stable releases](https://wkhtmltopdf.org/downloads.html#stable). You'll see an entry under `Amazon Linux` with `lambda zip` as the architecture.\n\nOr, you can click [here](https://github.com/wkhtmltopdf/packaging/releases/download/0.12.6-4/wkhtmltox-0.12.6-4.amazonlinux2_lambda.zip) (I likely won't update this link, so probably best to go directly to the release page).\n\n_Random note:_ If you need more fonts for future usage, I've found that [this is a good resource](https://github.com/brandonlim-hs/fonts-aws-lambda-layer). You may need to include one of these fonts as a layer in your lambda function (via ARN) if your function has issues in the beginning.\n\n## Creating the AWS Lambda layers\n\n[AWS Lambda layers](https://docs.aws.amazon.com/lambda/latest/dg/configuration-layers.html) allow us to add in \"layers\" of dependencies for our functions. An alternative to this is uploading your lambda function as a deployment package or using AWS SAM (Serverless Application Model), but that is out of the scope of this post.\n\n### `wkhtmltopdf`\nNow that we have the zip file downloaded, let's add our file as a layer in the [AWS Management Console](https://us-east-2.console.aws.amazon.com/console/home?region=us-east-2).\n\nGo to the [Layers section](https://us-east-2.console.aws.amazon.com/lambda/home?region=us-east-2#/layers) on the AWS Lambda page and click `Create layer`.\n\nThen, add the following Layer configuration.\n\n![AWS Lambda layer configuration {priority}{680x488}](/images/converting-html-to-pdf/layer-configuration.jpg)\n\nNotice that we don't add a runtime here, this is intentional since our layer is a binary.\n\nClick Create and take note of your new layer's Version ARN as we are about to use it to add to our function.\n\nNow we're set up to create our function!\n\n\n## Writing the AWS Lambda function\nNavigate to the [Functions page](https://us-east-2.console.aws.amazon.com/lambda/home?region=us-east-2#/functions) within the AWS Lambda service and click `Create function`.\n\nSelect `Author from scratch`, and add the following configuration.\n\n![AWS Lambda function configuration {1004x475}](/images/converting-html-to-pdf/function-configuration.jpg)\n\nYou can ignore the `Advanced settings` for our use case.\n\nOnce the function is created, we have just a few configuration additions to make.\n\n### Adding the layer to our Lambda function\n\nNow that our function is created, the first thing we want to do is add our `wkhtmltopdf` layer.\n\nAt the top of the Function Overview panel, click the `Layers` button right below your function name. This will bring you down to the layers section. Now click Add a layer.\n\nClick on `Specify an ARN` and copy your Layer Version ARN from earlier.\n\n![AWS Lambda add layer {680x316}](/images/converting-html-to-pdf/add-layer.jpg)\n\nThe reason why we need to specify our layer by ARN is because we didn't define a runtime above.\n\n<p style=\"background-color: #9bc2cf; padding: 7px 20px; text-align: center; border-radius: 6px;\">\n<b>Important!</b> If your function generates a PDF with a bunch of black squares, this is likely because there is no font configuration within Lambda. To solve this, you can go to [this link](https://github.com/brandonlim-hs/fonts-aws-lambda-layer\") that I mentioned earlier, and copy one of the AWS Linux Fonts ARNs for your region (or build from scratch), add the environment variable in the README, and repeat these steps to add a font layer.\n</p>\n\n### Add permission to access your S3 bucket\n\nOne final function configuration that we need to add is permission for our function to access Amazon S3.  To do this, navigate to the Configuration tab below your Function Overview.\n\nUnder Configuration, go to the Permissions section. Here, you will see your generated Execution Role. Click this link to go to the IAM Console.\n\nFrom here, click Attach policies, and add the **AmazonS3FullAccess** policy like so\n\n![AWS Lambda IAM policy {1004x461}](/images/converting-html-to-pdf/iam-policy.jpg)\n\nNow that our function is configured, we can dive into the actual requirements and code!\n\n### Requirements\n\n1. Allow passing either an S3 file key or an HTML string\n2. Return a file key for the generated PDF\n3. Accept a small set of options for the `wkhtmltopdf` command\n    - A full man page can be found [here](https://wkhtmltopdf.org/usage/wkhtmltopdf.txt)\n    - Most of the ones we'd want anyways are the default (i.e. `--images`, `--enable-external-links`, etc.)\n\nLet's allow the user to pass the following options\n- `--orientation <orientation>` - the common page orientation for the PDF file.\n    - Valid values are `Landscape` or `Portrait`\n- `--title <text>` - the title of the generated file.\n- The margins of the file\n    - `--margin-bottom <unitreal>`\n    - `--margin-left <unitreal>` (default is 10mm)\n    - `--margin-right <unitreal>`  (default is 10mm)\n    - `--margin-top <unitreal>`\n\n### Assumptions\n\n1. The HTML string or file will be valid and will include the necessary tags (`<!DOCTYPE html>`, `<html>`, `<head>`, `<body>`)\n2. The event payload will contain all valid values (S3 bucket name, file key, `wkhtmltopdf` options etc.)\n\n### The function code\nBy default, you will see the following handler.\n```python\ndef lambda_handler(event, context):\n    # TODO implement\n    return {\n        'statusCode': 200,\n        'body': json.dumps('Hello from Lambda!')\n    }\n```\nThis is the code that will be executed when your function is called. We'll come back to this in a bit.\n\n#### The imports\nFirst, let's go ahead and import all of the Python libraries that we'll need and set up some basic tools like the `S3 client` and our `logger`.\n```python\nfrom datetime import datetime\nimport json\nimport logging\nimport os\nimport subprocess\nfrom typing import Optional\n\nimport boto3\nfrom botocore.exceptions import ClientError\n\n\n# Set up logging\nlogger = logging.getLogger()\nlogger.setLevel(logging.INFO)\n\n# Get the s3 client\ns3 = boto3.client('s3')\n```\n\nNow based upon our requirements, we'll need helper functions to\n1. Download an HTML file from S3\n2. Upload a file to S3\n\nLet's start with those, and then we'll return to our lambda handler.\n\n#### Downloading/uploading the file\n[`boto3`](https://boto3.amazonaws.com/v1/documentation/api/latest/index.html) makes it really easy to interact with S3.  Using `boto3`, we can add the following helper functions.\n\n```python\ndef download_s3_file(bucket: str, file_key: str) -> str:\n    \"\"\"Downloads a file from s3 to `/tmp/[File Key]`.\n    \n    Args:\n        bucket (str): Name of the bucket where the file lives.\n        file_key (str): The file key of the file in the bucket.\n\n    Returns:\n        The local file name as a string.\n    \"\"\"\n    local_filename = f'/tmp/{file_key}'\n    s3.download_file(Bucket=bucket, Key=file_key, Filename=local_filename)\n    logger.info('Downloaded HTML file to %s' % local_filename)\n\n    return local_filename\n    \n    \ndef upload_file_to_s3(bucket: str, filename: str) -> Optional[str]:\n    \"\"\"Uploads the generated PDF to s3.\n    \n    Args:\n        bucket (str): Name of the s3 bucket to upload the PDF to.\n        filename (str): Location of the file to upload to s3.\n        \n    Returns:\n        The file key of the file in s3 if the upload was successful.\n        If the upload failed, then `None` will be returned.\n    \"\"\"\n    file_key = None\n    try:\n        file_key = filename.replace('/tmp/', '')\n        s3.upload_file(Filename=filename, Bucket=bucket, Key=file_key)\n        logger.info('Successfully uploaded the PDF to %s as %s'\n                    % (bucket, file_key))\n    except ClientError as e:\n        logger.error('Failed to upload file to s3.')\n        logger.error(e)\n        file_key = None\n        \n    return file_key\n```\n\n#### Parsing the event\nOne thing we haven't talked about yet is the data that we'll need to pass our function.\n\nLet's define our JSON event schema as the following.\n```json\n{\n    \"bucket\": \"<Name of the bucket where the file is stored currently and will be stored after processing> [Required]\",\n    \"file_key\": \"<File key where the file is store in S3> [Required if `html_string` is not defined]\",\n    \"html_string\": \"<HTML string to convert to a PDF> [Required if `file_key` is not defined]\",\n    \"wkhtmltopdf_options\": {\n        \"orientation\": \"<`landscape` or `portrait`> [Optional: Default is `portrait`]\",\n        \"title\": \"<Title of the PDF> [Optional]\",\n        \"margin\": \"<Margin of the PDF (same format as css [<top> <right> <bottom> <left>] (all must be included)).> [Optional]\"\n    }\n}\n```\n`wkhtmltopdf_options` is an optional object. If the included options are not valid, they will not be included.\n\nWe can access all of the data passed to our function from the `event` parameter in the `lambda_handler` function.\n\nNow, let's jump back to the `lambda_handler` function and add some code to pull out the data from our event and put together the remaining pieces of actually calling the `wkhtmltopdf` executable to finish our lambda function.\n\n```python\ndef lambda_handler(event, context):\n    logger.info(event)\n\n    # bucket is always required\n    try:\n        bucket = event['bucket']\n    except KeyError:\n        error_message = 'Missing required \"bucket\" parameter from request payload.'\n        logger.error(error_message)\n        return {\n            'status': 400,\n            'body': json.dumps(error_message),\n        }\n\n    # html_string and file_key are conditionally required, so let's try to get both\n    try:\n        file_key = event['file_key']\n    except KeyError:\n        file_key = None\n\n    try:\n        html_string = event['html_string']\n    except KeyError:\n        html_string = None\n\n    if file_key is None and html_string is None:\n        error_message = (\n            'Missing both a \"file_key\" and \"html_string\" '\n            'from request payload. One of these must be '\n            'included.'\n        )\n        logger.error(error_message)\n        return {\n            'status': 400,\n            'body': json.dumps(error_message),\n        }\n\n    # Now we can check for the option wkhtmltopdf_options and map them to values\n    # Again, part of our assumptions are that these are valid\n    wkhtmltopdf_options = {}\n    if 'wkhtmltopdf_options' in event:\n        # Margin is <top> <right> <bottom> <left>\n        if 'margin' in event['wkhtmltopdf_options']:\n            margins = event['wkhtmltopdf_options']['margin'].split(' ')\n            if len(margins) == 4:\n                wkhtmltopdf_options['margin-top'] = margins[0]\n                wkhtmltopdf_options['margin-right'] = margins[1]\n                wkhtmltopdf_options['margin-bottom'] = margins[2]\n                wkhtmltopdf_options['margin-left'] = margins[3]\n\n        if 'orientation' in event['wkhtmltopdf_options']:\n            wkhtmltopdf_options['orientation'] = 'portrait' \\\n                if event['wkhtmltopdf_options']['orientation'].lower() not in ['portrait', 'landscape'] \\\n                else event['wkhtmltopdf_options']['orientation'].lower()\n\n        if 'title' in event['wkhtmltopdf_options']:\n            wkhtmltopdf_options['title'] = event['wkhtmltopdf_options']['title']\n\n    # If we got a file_key in the request, let's download our file\n    # If not, we'll write the HTML string to a file\n    if file_key is not None:\n        local_filename = download_s3_file(bucket, file_key)\n    else:\n        timestamp = str(datetime.now()).replace('.', '').replace(' ', '_')\n        local_filename = f'/tmp/{timestamp}-html-string.html'\n\n        # Delete any existing files with that name\n        try:\n            os.unlink(local_filename)\n        except FileNotFoundError:\n            pass\n\n        with open(local_filename, 'w') as f:\n            f.write(html_string)\n\n    # Now we can create our command string to execute and upload the result to s3\n    command = 'wkhtmltopdf  --load-error-handling ignore'  # ignore unecessary errors\n    for key, value in wkhtmltopdf_options.items():\n        if key == 'title':\n            value = f'\"{value}\"'\n        command += ' --{0} {1}'.format(key, value)\n    command += ' {0} {1}'.format(local_filename, local_filename.replace('.html', '.pdf'))\n\n    # Important! Remember, we said that we are assuming we're accepting valid HTML\n    # this should always be checked to avoid allowing any string to be executed\n    # from this command. The reason we use shell=True here is because our title\n    # can be multiple words.\n    subprocess.run(command, shell=True)\n    logger.info('Successfully generated the PDF.')\n    file_key = upload_file_to_s3(bucket, local_filename.replace('.html', '.pdf'))\n\n    if file_key is None:\n        error_message = (\n            'Failed to generate PDF from the given HTML file.'\n            ' Please check to make sure the file is valid HTML.'\n        )\n        logger.error(error_message)\n        return {\n            'status': 400,\n            'body': json.dumps(error_message),\n        }\n\n    return {\n        'status': 200,\n        'file_key': file_key,\n    }\n```\n\nNow you can go to the **Test** tab and create the following test event (change your bucket name as necessary)\n```json\n{\n    \"bucket\": \"bucket-for-articles\",\n    \"html_string\": \"<!DOCTYPE html><html><head></head><body>This is an example of a simple HTML page.</body></html>\",\n    \"wkhtmltopdf_options\": {\n        \"orientation\": \"portrait\",\n        \"title\": \"Test PDF Generation\",\n        \"margin\": \"10mm 10mm 10mm 10mm\"\n    }\n}\n```\n\nYou should get a return event with a `status` of `200`, and a `file_key` of your converted file, thus achieving our goal! ðŸŽ‰\n\n---\n\n","title":"Converting HTML to a PDF using Python, AWS Lambda, and wkhtmltopdf","date":"2021-04-29","tags":["python","aws"],"description":"Building an AWS lambda function that uses Python and wkhtmltopdf to convert an HTML file to a PDF file."},{"id":"forecasting-spy-prices","contentHtml":"<h2>tl;dr</h2>\n<h3>Goal</h3>\n<p><em>To apply Facebook's Prophet forecasting procedure to historical SPY (SPDR S&#x26;P 500 ETF Trust) market data to gather future pricing predictions.</em></p>\n<h3>A few notes</h3>\n<ul>\n<li>I'm by no means a data scientist, so this is more of an exploratory analysis than an accurate one</li>\n<li>For sake of brevity, I won't be using a training/test split or measuring the error of the model, I will just train the model on the entire dataset and then make a prediction</li>\n</ul>\n<h3>Process overview</h3>\n<ol>\n<li><strong>Downloading the data</strong> - exporting the data from Yahoo Finance as a CSV</li>\n<li><strong>Exploring the data</strong> - loading and exploring the data using Pandas</li>\n<li><strong>Fitting the model</strong> - reading in the data and applying a basic fit of the Prophet model to the data</li>\n<li><strong>Visualizing the forecast</strong> - visualizing the forecasted pricing data</li>\n</ol>\n<h3>Python dependencies</h3>\n<pre><code>import pandas as pd\nfrom prophet import Prophet\n</code></pre>\n<hr>\n<p>Before we jump in, let's give a little background on SPY and on Facebook's Prophet.</p>\n<p>The <em>SPDR S&#x26;P 500 ETF Trust</em> (SPY) is an ETF (<em>Exchange Traded Fund</em>) that tracks the performance of the S&#x26;P 500 index.  SPY is also the largest ETF in the world, and is popular compared to other ETFs that track the S&#x26;P 500 because of the high volume, or the number of shares that trade on a given day (we'll be able to see the volume per day in the CSV we export from Yahoo Finance).</p>\n<p>For more information on ETFs, <a href=\"https://www.investopedia.com/terms/e/etf.asp\">Investopedia gives a good overview</a>.</p>\n<p><a href=\"https://facebook.github.io/prophet/\">Facebook Prophet</a> is an open source, automated forecasting procedure for time series data.  I'm not going to dive too much into the mathematics or implementation details of Prophet, but if you are more interested, you can read the <a href=\"https://peerj.com/preprints/3190/\">research paper</a>.  Prophet makes it easy to handle outliers, adjust to different time intervals, deal with holidays, and leaves the ability to easily tune the forecasting model.</p>\n<p>Now that we have a general idea of what we're trying to predict and the tool we'll use to forecast, let's dive into the actual data.</p>\n<hr>\n<h2>Downloading the data</h2>\n<p>Thanks to Yahoo Finance, we can download historical pricing data for free. You can click <a href=\"https://finance.yahoo.com/quote/SPY/history?p=SPY\">here</a> to view the SPY historical pricing data.</p>\n<p>Click on the <code>Historical Data</code> tab, and then we can adjust our <code>Time Period</code> to the Max as seen below (back to January 1993).</p>\n<p><img src=\"/images/forecasting-spy/export-data.jpg\" alt=\"Historical pricing data {priority}{680x243}\"></p>\n<p>Now we can click download to get our CSV and start diving into the data.</p>\n<hr>\n<h2>Exploring the data</h2>\n<p>Let's fire up Pandas and load our data into a DataFrame to see what general insights we can extract.</p>\n<pre><code>df = pd.read_csv('SPY.csv')\n\n# Columns and row count\ndf.info()\n\"\"\"\n&#x3C;class 'pandas.core.frame.DataFrame'>\nRangeIndex: 7125 entries, 0 to 7124\nData columns (total 7 columns):\n #   Column     Non-Null Count  Dtype  \n---  ------     --------------  -----  \n 0   Date       7125 non-null   object \n 1   Open       7125 non-null   float64\n 2   High       7125 non-null   float64\n 3   Low        7125 non-null   float64\n 4   Close      7125 non-null   float64\n 5   Adj Close  7125 non-null   float64\n 6   Volume     7125 non-null   int64  \ndtypes: float64(5), int64(1), object(1)\nmemory usage: 389.8+ KB\n\"\"\"\n\n# Preview of the data\ndf.head()\n\"\"\"\n         Date      Open      High       Low     Close  Adj Close   Volume\n0  1993-01-29  43.96875  43.96875  43.75000  43.93750  25.884184  1003200\n1  1993-02-01  43.96875  44.25000  43.96875  44.25000  26.068277   480500\n2  1993-02-02  44.21875  44.37500  44.12500  44.34375  26.123499   201300\n3  1993-02-03  44.40625  44.84375  44.37500  44.81250  26.399649   529400\n4  1993-02-04  44.96875  45.09375  44.46875  45.00000  26.510111   531500\n\"\"\"\n\n# General statistics\ndf.describe().loc[['mean', 'min', 'max']]\n\"\"\"\n            Open        High         Low       Close   Adj Close        Volume\nmean  146.896395  147.766581  145.928716  146.896373  121.611954  8.453727e+07\nmin    43.343750   43.531250   42.812500   43.406250   25.571209  5.200000e+03\nmax   422.500000  422.820007  419.160004  422.119995  422.119995  8.710263e+08\n\"\"\"\n\n# Day to day percent changes of Highs\ndf[['Date', 'High']].set_index('Date').pct_change().reset_index()\n\"\"\"\n            Date      High\n0     1993-01-29       NaN\n1     1993-02-01  0.006397\n2     1993-02-02  0.002825\n3     1993-02-03  0.010563\n4     1993-02-04  0.005575\n         ...       ...\n7120  2021-05-10 -0.000189\n7121  2021-05-11 -0.017670\n7122  2021-05-12 -0.006454\n7123  2021-05-13 -0.000582\n7124  2021-05-14  0.012465\n\n[7125 rows x 2 columns]\n\"\"\"\n</code></pre>\n<p>Now that we know a bit more about our data in general, we can create a model using Prophet.</p>\n<hr>\n<h2>Fitting the model</h2>\n<p>Since we're not concerned in this post about making our model the best it can be, we can train our model on the entire dataset.</p>\n<p>This typically isn't a good practice.  When trying to make an accurate prediction, you should use training and test subsets of the data and calculate errors within your model and use those results to tune hyperparameters.</p>\n<p>Nevertheless, let's continue.</p>\n<pre><code># The prophet model fits to a DataFrame with a date column (ds)\n# and a value to predict (y)\ndf_predict = df[['Date', 'Close']]\ndf_predict.columns = ['ds', 'y']\n\n# We can find all of the missing days within our dataset\n# and mark those as \"holidays\"\ndate_series = pd.to_datetime(df['Date'])\ndf_missing_dates = pd\\\n    .date_range(start=date_series.min(), end=date_series.max())\\\n    .difference(date_series)\\\n    .to_frame()\\\n    .reset_index()\ndf_missing_dates.columns = ['holiday', 'ds']\ndf_missing_dates['holiday'] = 'Stock Market Closed'\n\n# Fitting our model is incredibly simple and can be done in the\n# most basic sense in just two lines of code\nm = Prophet(daily_seasonality=True, holidays=df_missing_dates)\nm.fit(df_predict)\n</code></pre>\n<p>Just like that, we have built our model for a forecast.  All we have left to do is generate dates to predict values for, and run the actual prediction.</p>\n<hr>\n<h2>Visualizing the forecast</h2>\n<p>Now let's forecast with our model and visualize the results.</p>\n<pre><code># Create a DataFrame with past and future dates (only weekdays)\nfuture = m.make_future_dataframe(periods=365)\nfuture = future[pd.to_datetime(future['ds']).dt.weekday &#x3C; 5]\n\n# Now we can forecast and visualize in just two more lines of code\nforecast = m.predict(future)\nm.plot(forecast, xlabel='Date', ylabel='Daily Closing Price')\n</code></pre>\n<p><img src=\"/images/forecasting-spy/first-prediction.jpg\" alt=\"First SPY forecast {800x480}\"></p>\n<blockquote>\n<p><strong>A few things to notice</strong></p>\n<ul>\n<li>The black dots are the training data points</li>\n<li>The blue outline is the confidence interval</li>\n<li>The line within the confidence interval is the actual forecast</li>\n</ul>\n</blockquote>\n<p>Based on our results, we can see the forecast is fairly linear and the confidence interval is relatively narrow (due to the volume of date).  The behavior of the stock market since Covid-19 started back around February 2020 has be a little unorthodox, so let's narrow our model to be trained back to data starting in 2017 to see if there is an effect.</p>\n<pre><code># Narrow down to start at 2017\ndf_recent_predict = df_predict.iloc[date_series[date_series.dt.year > 2016].index]\ndate_series = pd.to_datetime(df_recent_predict['ds'])\ndf_recent_missing_dates =  pd\\\n    .date_range(start=date_series.min(), end=date_series.max())\\\n    .difference(date_series)\\\n    .to_frame()\\\n    .reset_index()\ndf_recent_missing_dates.columns = ['holiday', 'ds']\ndf_recent_missing_dates['holiday'] = 'Stock Market Closed'\n\n# Create and fit our new model\nm = Prophet(daily_seasonality=True, holidays=df_recent_missing_dates)\nm.fit(df_recent_predict)\n\n# Recreate our future predictions\nfuture = m.make_future_dataframe(periods=365)\nfuture = future[pd.to_datetime(future['ds']).dt.weekday &#x3C; 5]\n\n# Forecast and visualize\nforecast = m.predict(future)\nm.plot(forecast, xlabel='Date', ylabel='Daily Closing Price')\n</code></pre>\n<p><img src=\"/images/forecasting-spy/second-prediction.jpg\" alt=\"Second SPY forecast {800x480}\"></p>\n<p>Now we can see a much wider confidence interval and a bit more of a bumpy forecast line; however, this looks much more realistic in terms of stock market prediction.</p>\n<hr>\n<h2>Conclusion</h2>\n<p>All in all, Facebook's Prophet is a very fast, impressive, and strongly abstracted library.  The entire script, including reading in the data, training and forecasting two models, and plotting both of the forecasts took right around <strong>25 seconds</strong>.</p>\n<p>I would love to see this tool in the hands of an actual data scientist to see the accuracy of the models they'd be able to create using Prophet.</p>\n<hr>\n","markdown":"\n## tl;dr\n\n### Goal\n_To apply Facebook's Prophet forecasting procedure to historical SPY (SPDR S&P 500 ETF Trust) market data to gather future pricing predictions._\n\n### A few notes\n- I'm by no means a data scientist, so this is more of an exploratory analysis than an accurate one\n- For sake of brevity, I won't be using a training/test split or measuring the error of the model, I will just train the model on the entire dataset and then make a prediction\n\n### Process overview\n1. **Downloading the data** - exporting the data from Yahoo Finance as a CSV\n2. **Exploring the data** - loading and exploring the data using Pandas\n3. **Fitting the model** - reading in the data and applying a basic fit of the Prophet model to the data\n4. **Visualizing the forecast** - visualizing the forecasted pricing data\n\n### Python dependencies\n```python\nimport pandas as pd\nfrom prophet import Prophet\n```\n\n<p style=\"background-color: orange; padding: 7px 20px; border-radius: 6px;\">\n    <b>Important</b> This article is not investment advice, please conduct your own due diligence. This is merely a simple analysis.\n</p>\n\n---\n\nBefore we jump in, let's give a little background on SPY and on Facebook's Prophet.\n\nThe _SPDR S&P 500 ETF Trust_ (SPY) is an ETF (_Exchange Traded Fund_) that tracks the performance of the S&P 500 index.  SPY is also the largest ETF in the world, and is popular compared to other ETFs that track the S&P 500 because of the high volume, or the number of shares that trade on a given day (we'll be able to see the volume per day in the CSV we export from Yahoo Finance).\n\nFor more information on ETFs, [Investopedia gives a good overview](https://www.investopedia.com/terms/e/etf.asp).\n\n[Facebook Prophet](https://facebook.github.io/prophet/) is an open source, automated forecasting procedure for time series data.  I'm not going to dive too much into the mathematics or implementation details of Prophet, but if you are more interested, you can read the [research paper](https://peerj.com/preprints/3190/).  Prophet makes it easy to handle outliers, adjust to different time intervals, deal with holidays, and leaves the ability to easily tune the forecasting model.\n\nNow that we have a general idea of what we're trying to predict and the tool we'll use to forecast, let's dive into the actual data.\n\n---\n\n## Downloading the data\nThanks to Yahoo Finance, we can download historical pricing data for free. You can click [here](https://finance.yahoo.com/quote/SPY/history?p=SPY) to view the SPY historical pricing data.\n\nClick on the `Historical Data` tab, and then we can adjust our `Time Period` to the Max as seen below (back to January 1993).\n\n![Historical pricing data {priority}{680x243}](/images/forecasting-spy/export-data.jpg)\n\nNow we can click download to get our CSV and start diving into the data.\n\n---\n\n## Exploring the data\nLet's fire up Pandas and load our data into a DataFrame to see what general insights we can extract.\n\n```python\ndf = pd.read_csv('SPY.csv')\n\n# Columns and row count\ndf.info()\n\"\"\"\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 7125 entries, 0 to 7124\nData columns (total 7 columns):\n #   Column     Non-Null Count  Dtype  \n---  ------     --------------  -----  \n 0   Date       7125 non-null   object \n 1   Open       7125 non-null   float64\n 2   High       7125 non-null   float64\n 3   Low        7125 non-null   float64\n 4   Close      7125 non-null   float64\n 5   Adj Close  7125 non-null   float64\n 6   Volume     7125 non-null   int64  \ndtypes: float64(5), int64(1), object(1)\nmemory usage: 389.8+ KB\n\"\"\"\n\n# Preview of the data\ndf.head()\n\"\"\"\n         Date      Open      High       Low     Close  Adj Close   Volume\n0  1993-01-29  43.96875  43.96875  43.75000  43.93750  25.884184  1003200\n1  1993-02-01  43.96875  44.25000  43.96875  44.25000  26.068277   480500\n2  1993-02-02  44.21875  44.37500  44.12500  44.34375  26.123499   201300\n3  1993-02-03  44.40625  44.84375  44.37500  44.81250  26.399649   529400\n4  1993-02-04  44.96875  45.09375  44.46875  45.00000  26.510111   531500\n\"\"\"\n\n# General statistics\ndf.describe().loc[['mean', 'min', 'max']]\n\"\"\"\n            Open        High         Low       Close   Adj Close        Volume\nmean  146.896395  147.766581  145.928716  146.896373  121.611954  8.453727e+07\nmin    43.343750   43.531250   42.812500   43.406250   25.571209  5.200000e+03\nmax   422.500000  422.820007  419.160004  422.119995  422.119995  8.710263e+08\n\"\"\"\n\n# Day to day percent changes of Highs\ndf[['Date', 'High']].set_index('Date').pct_change().reset_index()\n\"\"\"\n            Date      High\n0     1993-01-29       NaN\n1     1993-02-01  0.006397\n2     1993-02-02  0.002825\n3     1993-02-03  0.010563\n4     1993-02-04  0.005575\n         ...       ...\n7120  2021-05-10 -0.000189\n7121  2021-05-11 -0.017670\n7122  2021-05-12 -0.006454\n7123  2021-05-13 -0.000582\n7124  2021-05-14  0.012465\n\n[7125 rows x 2 columns]\n\"\"\"\n```\n\nNow that we know a bit more about our data in general, we can create a model using Prophet.\n\n---\n\n## Fitting the model\n\nSince we're not concerned in this post about making our model the best it can be, we can train our model on the entire dataset.\n\nThis typically isn't a good practice.  When trying to make an accurate prediction, you should use training and test subsets of the data and calculate errors within your model and use those results to tune hyperparameters.\n\nNevertheless, let's continue.\n\n```python\n# The prophet model fits to a DataFrame with a date column (ds)\n# and a value to predict (y)\ndf_predict = df[['Date', 'Close']]\ndf_predict.columns = ['ds', 'y']\n\n# We can find all of the missing days within our dataset\n# and mark those as \"holidays\"\ndate_series = pd.to_datetime(df['Date'])\ndf_missing_dates = pd\\\n    .date_range(start=date_series.min(), end=date_series.max())\\\n    .difference(date_series)\\\n    .to_frame()\\\n    .reset_index()\ndf_missing_dates.columns = ['holiday', 'ds']\ndf_missing_dates['holiday'] = 'Stock Market Closed'\n\n# Fitting our model is incredibly simple and can be done in the\n# most basic sense in just two lines of code\nm = Prophet(daily_seasonality=True, holidays=df_missing_dates)\nm.fit(df_predict)\n```\n\nJust like that, we have built our model for a forecast.  All we have left to do is generate dates to predict values for, and run the actual prediction.\n\n---\n\n## Visualizing the forecast\nNow let's forecast with our model and visualize the results.\n\n```python\n# Create a DataFrame with past and future dates (only weekdays)\nfuture = m.make_future_dataframe(periods=365)\nfuture = future[pd.to_datetime(future['ds']).dt.weekday < 5]\n\n# Now we can forecast and visualize in just two more lines of code\nforecast = m.predict(future)\nm.plot(forecast, xlabel='Date', ylabel='Daily Closing Price')\n```\n\n![First SPY forecast {800x480}](/images/forecasting-spy/first-prediction.jpg)\n\n> **A few things to notice**\n> - The black dots are the training data points\n> - The blue outline is the confidence interval\n> - The line within the confidence interval is the actual forecast\n\nBased on our results, we can see the forecast is fairly linear and the confidence interval is relatively narrow (due to the volume of date).  The behavior of the stock market since Covid-19 started back around February 2020 has be a little unorthodox, so let's narrow our model to be trained back to data starting in 2017 to see if there is an effect.\n\n```python\n# Narrow down to start at 2017\ndf_recent_predict = df_predict.iloc[date_series[date_series.dt.year > 2016].index]\ndate_series = pd.to_datetime(df_recent_predict['ds'])\ndf_recent_missing_dates =  pd\\\n    .date_range(start=date_series.min(), end=date_series.max())\\\n    .difference(date_series)\\\n    .to_frame()\\\n    .reset_index()\ndf_recent_missing_dates.columns = ['holiday', 'ds']\ndf_recent_missing_dates['holiday'] = 'Stock Market Closed'\n\n# Create and fit our new model\nm = Prophet(daily_seasonality=True, holidays=df_recent_missing_dates)\nm.fit(df_recent_predict)\n\n# Recreate our future predictions\nfuture = m.make_future_dataframe(periods=365)\nfuture = future[pd.to_datetime(future['ds']).dt.weekday < 5]\n\n# Forecast and visualize\nforecast = m.predict(future)\nm.plot(forecast, xlabel='Date', ylabel='Daily Closing Price')\n```\n\n![Second SPY forecast {800x480}](/images/forecasting-spy/second-prediction.jpg)\n\nNow we can see a much wider confidence interval and a bit more of a bumpy forecast line; however, this looks much more realistic in terms of stock market prediction.\n\n---\n\n## Conclusion\n\nAll in all, Facebook's Prophet is a very fast, impressive, and strongly abstracted library.  The entire script, including reading in the data, training and forecasting two models, and plotting both of the forecasts took right around **25 seconds**.\n\nI would love to see this tool in the hands of an actual data scientist to see the accuracy of the models they'd be able to create using Prophet.\n\n---\n","title":"Forecasting SPY prices using Facebook's Prophet","date":"2021-05-19","tags":["python","pandas","data-analysis"],"description":"Using Facebookâ€™s Prophet, an open-source, time series forecasting procedure to predict SPY (SPDR S&P 500 ETF Trust) closing prices."},{"id":"slack-webhook","contentHtml":"<h2>tl;dr</h2>\n<h3>Goal</h3>\n<p><em>To set up a Slack webhook so we can send text and simple HTML notifications to receive in a Slack channel.</em></p>\n<h3>Process Overview</h3>\n<ol>\n<li>Setting up a Slack webhook URL in your Slack workspace to post to a channel</li>\n<li>Posting a notification to our webhook</li>\n<li>Creating a simple HTML parser to match the custom Slack markdown flavor</li>\n</ol>\n<h3>Python Dependencies</h3>\n<pre><code># Python standard library\nfrom html.parser import HTMLParser\nimport logging\nimport os\nimport re\nfrom typing import Any, List, Tuple\n\n# 3rd Party\nimport requests\n</code></pre>\n<h3>Assumptions</h3>\n<p>I'll assume you have a Slack account, a Slack workspace setup, Slack is installed, and you have knowledge of Python with a basic understanding of webhooks.</p>\n<hr>\n<p>If you haven't heard of it before, <a href=\"https://slack.com/\">Slack</a> is a very popular team/workplace communication tool.  In addition to direct messaging, it allows you to separate discussion into various topics or <strong>channels</strong> for more focused team communication.</p>\n<p>Another great feature of Slack is that you can add 3rd party <a href=\"https://slack.com/apps\">apps</a> (or integrations) from your existing stack, or even develop your own!  I have seen this streamline my own productivity, and I personally use a number of Slack apps.</p>\n<p>To name a few, you may want to check out the following (assuming you use these tools) which I've found a lot of value in:</p>\n<ul>\n<li><a href=\"https://slack.com/apps/A011MFBJEUU-sentry?tab=more_info\">Sentry</a> - for application monitoring</li>\n<li><a href=\"https://slack.com/apps/ADZ494LHY-google-calendar?tab=more_info\">Google Calendar</a> - to stay on top of my meetings schedule</li>\n<li><a href=\"https://slack.com/apps/A01BP7R4KNY-github?tab=more_info\">GitHub</a> - getting notified of pull requests and meaningful changes to important repositories</li>\n<li><a href=\"https://slack.com/apps/A2RPP3NFR-jira-cloud?tab=more_info\">Jira Cloud</a> - staying on top of changes to Jira tickets</li>\n<li><a href=\"https://slack.com/apps/A6L22LZNH-aws-chatbot?tab=more_info\">AWS Chatbot</a> - alerts from CloudWatch alarms</li>\n</ul>\n<p>You can browse the <a href=\"https://slack.com/apps\">Slack app directory</a> for more integrations.</p>\n<p>However, not every integration is going to provide the functionality you need.  This post will focus on creating our own custom Slack app with the goal of posting simple notifications to a Slack channel.</p>\n<p>A common use case where we can apply our app will be sending notifications when any sort of user activity happens on a platform.  As a developer, being notified of when a user completes a certain task can provide a lot of transparency and understanding into the usage of our application, while also keeping a sales teams informed on relevant activity on the platform.  This is the use case we'll focus on.</p>\n<p>We will do this by posting to a webhook hosted by Slack.  For more information on webhooks, you can check out <a href=\"https://zapier.com/blog/what-are-webhooks/\">this article</a> by Zapier.</p>\n<p>Let's get started!</p>\n<hr>\n<h2>Setting up the Slack App</h2>\n<p>Open Slack, click <strong>Add channels</strong>, and create a new channel called <code>notifications</code>.  This is where our Slack app will post to once we set it up.</p>\n<p><img src=\"/images/slack-webhook/create-channel.jpg\" alt=\"Create a Slack channel {priority}{1004x580}\"></p>\n<p>Now go to a web browser and head to https://api.slack.com/apps/.</p>\n<p>Click on <strong>Create an App</strong></p>\n<p><img src=\"/images/slack-webhook/create-app.jpg\" alt=\"Create a Slack App {1004x497}\"></p>\n<p>Select <strong>From scratch</strong></p>\n<p><img src=\"/images/slack-webhook/from-scratch.jpg\" alt=\"Select From Scratch {1004x497}\"></p>\n<p>Create a name for your app and select the workspace you just created your <code>notifications</code> channel in.</p>\n<p><img src=\"/images/slack-webhook/app-and-workspace.jpg\" alt=\"Choose an app name and workspace {1004x501}\"></p>\n<p>This will redirect you to the <strong>Basic Information</strong> tab for your app.  Here, we'll enable <strong>Incoming Webhooks</strong>.  As it states, this will enable us to post messages from an external source.  In this case, our platform.</p>\n<p><img src=\"/images/slack-webhook/add-webhooks.jpg\" alt=\"Enable incoming webhooks {1004x497}\"></p>\n<p>Turn on <strong>Activate Incoming Webhooks</strong> and you will see additional details appear.  Towards the bottom, click on <strong>Add New Webhook to Workspace</strong>.</p>\n<p><img src=\"/images/slack-webhook/add-new-webhook.jpg\" alt=\"Add a new webhook to your workspace {1004x485}\"></p>\n<p>You will be redirected again to select which channel to post to.  Select the <code>notifications</code> channel that we previously created and press <strong>Allow</strong>.</p>\n<p><img src=\"/images/slack-webhook/choose-channel.jpg\" alt=\"Select a channel for your app {1004x498}\"></p>\n<p>This will redirect you back to your app configuration and you will see a webhook URL you can now post to.  This will also include a simple curl POST request you can test with if you'd like.  Copy the webhook URL for later, and remember to <strong>keep it private</strong>.  This is a public URL that anyone can post to.</p>\n<p><img src=\"/images/slack-webhook/copy-url.jpg\" alt=\"Copy your webhook URL {680x506}\"></p>\n<p>You can return to the <strong>Basic Information</strong> of your app settings in Slack to view more API credentials and also edit the look and feel of your new Slack bot.</p>\n<p>Now we're ready to dive into the code to communicate with our webhook!</p>\n<hr>\n<h2>Communicating with our Webhook</h2>\n<p>To communicate with our webhook, we'll use the <a href=\"https://docs.python-requests.org/en/master/\"><code>requests</code></a> Python library.  This is a third party library, so you'll want to have a Python virtual environment set up to handle your dependencies.  Virtual environments are out of the scope of this article, but you can read more on them <a href=\"https://docs.python.org/3/tutorial/venv.html\">here</a>.</p>\n<p>Inside your virtual environment, you can run the following to install the library.</p>\n<pre><code>pip install requests\n</code></pre>\n<p>Now, we'll set up a class to communicate with our Slack endpoint.  We'll start by just sending a plain text message to Slack.</p>\n<pre><code>import logging\n\nimport requests\n\n\nlogger = logging.getLogger()\nlogger.setLevel(logging.INFO)\n\n\nclass SlackWebhookBot:\n    def __init__(self, webhook_url: str, timeout: int = 15):\n        \"\"\"Class to send messages to a provided Slack webhook URL.\n\n        You can read more about Slack's Incoming Webhooks here:\n            https://api.slack.com/messaging/webhooks\n        \n        Args:\n            webhook_url: The webhook URL to send a message to.  Typically\n                formatted like \"https://hooks.slack.com/services/...\".\n        \n        Kwargs:\n            timeout: Number of seconds before the request will timeout.\n                This is used to prevent a hang and is set to a default\n                value of 15 seconds.\n        \"\"\"\n        self.webhook_url = webhook_url\n        self.timeout = timeout\n        self.headers = {\n            'Content-Type': 'application/json',\n        }\n    \n\n    def send(self, message: str) -> bool:\n        \"\"\"Sends a message to the webhook URL.\n\n        Per the Slack Incoming Webhook example.  The body of the request\n        (for plain text) should be formatted as follows:\n            `{\"text\": \"Hello, World!\"}`\n\n        Args:\n            message: Plain text string to send to Slack.\n\n        Returns:\n            A boolean representing if the request was successful.\n        \"\"\"\n        success = False\n        payload = {\n            'text': message,\n        }\n        try:\n            r = requests.post(\n                self.webhook_url,\n                headers=self.headers,\n                json=payload,\n                timeout=self.timeout\n            )\n        except requests.Timeout:\n            logger.error('Timeout occurred when trying to send message to Slack.')\n        except requests.RequestException as e:\n            logger.error(f'Error occurred when communicating with Slack: {e}.')\n        else:\n            success = True\n            logger.info('Successfully sent message to Slack.')\n\n        return success\n</code></pre>\n<p>Above is the basic setup for communicating with the Slack webhook.  We can run a quick test by moving this code to a script and adding the following.</p>\n<pre><code>import os\n\nwebhook_url = os.environ.get('SLACK_WEBHOOK_URL')\nslack = SlackWebhookBot(webhook_url)\nslack.send('Hello, world!')\n</code></pre>\n<p>Make sure to set your Slack webhook URL to the <code>SLACK_WEBHOOK_URL</code> environment variable, and make sure you're in your virtual environment with the <code>requests</code> package installed before running the script.  This can be done on MacOS with the following.</p>\n<pre><code>export SLACK_WEBHOOK_URL=https://hooks.slack.com/services/...\npython slack_webhook.py\n</code></pre>\n<p>When you run this, you should see a message from you Slack bot appear in the <code>notifications</code> channel!</p>\n<p><img src=\"/images/slack-webhook/slack-first-message.jpg\" alt=\"Hello world message in Slack {1004x675}\"></p>\n<p>For our notifications to be more helpful, we may want to add links or other formatting.  To do this, we will write our notifications with HTML tags, and then parse these tags and convert them to the <a href=\"https://api.slack.com/reference/surfaces/formatting\">Slack flavored Markdown</a> called <code>mrkdwn</code>.</p>\n<hr>\n<h2>Adding a simple HTML parser to our class</h2>\n<p>From the <a href=\"https://api.slack.com/reference/surfaces/formatting\">Slack formatting guide</a> for messages, we can see all of the ways to format text in our messages.  For our purposes, we will focus on a primary list.</p>\n<ul>\n<li>Making text <code>_italicized_</code> (<code>&#x3C;i></code>)</li>\n<li>Making text <code>*bold*</code> (<code>&#x3C;b></code>)</li>\n<li>Striking through ~<code>text</code>~ (<code>&#x3C;strike></code>)</li>\n<li>Adding line breaks (<code>&#x3C;br></code>)</li>\n<li>Adding <code>one-line code blocks</code> using the backtick character (<code>&#x3C;code></code>)</li>\n<li>Adding unordered lists (line broken dashes) (<code>&#x3C;ul>&#x3C;li></code>)</li>\n<li>Adding external links <code>&#x3C;[external link]|[display text]></code> (<code>&#x3C;a></code>)</li>\n</ul>\n<p>Also note that the Slack documentation says that <a href=\"https://api.slack.com/reference/surfaces/formatting#escaping\">certain characters need to be escaped</a>.</p>\n<p>There are a few more styles that could be implemented, but we'll focus on just this list for this post.</p>\n<p>To do this, we will utilize the <a href=\"https://docs.python.org/3/library/html.html\"><code>html</code></a> module in the Python standard library to parse HTML tags, attributes, and values.</p>\n<p>Let's write a class (we need to inherit functions for the <code>HTMLParser</code> class) where we will parse all of the tags and attributes, and escape the message text when needed.  The idea here is that we can construct a string from scratch and for each tag we care about we can \"replace\" the HTML tags with the relevant mrkdwn syntax.</p>\n<pre><code>from html.parser import HTMLParser\nimport re\nfrom typing import Any, List, Tuple\n\n\nclass SlackHTMLParser(HTMLParser):\n    def __init__(self, *args, **kwargs):\n        \"\"\"Escapes and converts an HTML string to Slack flavored\n        Markdown (mrkdwn).\n\n        More about Slack's Markdown Flavor (mrkdwn) can be seen here:\n            https://api.slack.com/reference/surfaces/formatting\n        \n        Call using `SlackHTMLParser(message_body).parse()`.\n        \"\"\"\n        super().__init__(*args, **kwargs)\n        self.slack_message = ''\n        self.ignore_tag = False  # Used to skip tags we don't care about\n        self.line_break = '::LINE::BREAK::'  # Unique sequence for swapping a &#x3C;br>\n\n\n    def handle_starttag(self, tag: str, attrs: List[Tuple[str, Any]]):\n        \"\"\"Called when the opening of a tag is encountered.\n\n        The idea here is to swap out the tag with the respective mrkdwn\n        symbol.\n\n        Args:\n            tag: Lowercase name of the HTML tag.  E.G. `br` or `i`.\n            attrs: List of tuples with the tuple having the following form:\n                (attribute name, value).  E.G. ('href', 'www.example.com').\n        \"\"\"\n        if tag in ['i', 'em']:\n            self.slack_message += '_'\n        elif tag in ['b', 'strong']:\n            self.slack_message += '*'\n        elif tag == 'strike':\n            self.slack_message += '~'\n        elif tag in ['br', 'p', 'ul']:\n            self.slack_message += self.line_break\n        elif tag == 'li':\n            self.slack_message += f'{self.line_break}- '\n        elif tag == 'code':\n            self.slack_message += '`'\n        elif tag == 'a':\n            href = [x[1] for x in attrs if x[0] == 'href']\n            if len(href) > 0:\n                self.slack_message += f'&#x3C;{href[0]}|'\n        else:\n            self.ignore_tag = True\n\n\n    def handle_data(self, data: str):\n        \"\"\"Handles the data within a tag.\n\n        This is called after `handle_starttag` and before `handle_endtag`.\n\n        We will also escape the following text per Slack's documentation:\n        - '&#x26;' -> '&#x26;amp;'\n        - '&#x3C;' -> '&#x26;lt;'\n        - '>' -> '&#x26;gt;'\n\n        Args:\n            data: The data/string within the HTML tag.\n        \"\"\"\n        if not self.ignore_tag:\n            self.slack_message += data\\\n                .replace('&#x26;', '&#x26;amp;')\\\n                .replace('&#x3C;', '&#x26;lt;')\\\n                .replace('>', '&#x26;gt;')\n\n\n    def handle_endtag(self, tag: str):\n        \"\"\"Called when the closing of a tag is encountered.\n\n        The idea here is to swap out the tag with the respective mrkdwn\n        symbol.  This is basically the same as the handle_starttag.\n\n        Args:\n            tag: Lowercase name of the HTML tag.  E.G. `br` or `i`.\n        \"\"\"\n        if tag in ['i', 'em']:\n            self.slack_message += '_'\n        elif tag in ['b', 'strong']:\n            self.slack_message += '*'\n        elif tag == 'strike':\n            self.slack_message += '~'\n        elif tag == 'p':\n            self.slack_message += self.line_break\n        elif tag == 'code':\n            self.slack_message += '`'\n        elif tag == 'a':\n            self.slack_message += '>'\n        \n        self.ignore_tag = False\n\n\n    def parse(self, html_string: str) -> str:\n        \"\"\"Parses a given HTML string and applies simple formatting.\n        \n        Note that we need to apply the line break replacing here\n        instead of with the handle tag methods.\n\n        Args:\n            html_string: The HTML string to convert to Slack mrkdwn.\n\n        Returns:\n            A formatted Slack mrkdwn string.\n        \"\"\"\n        self.feed(html_string)\n        return re.sub(\n            r'^(\\n)+',  # Remove the leading line breaks\n            '',\n            ' '.join(self.slack_message.split()).replace(self.line_break, '\\n')\n        )\n</code></pre>\n<p>We can test our class out with the following code.</p>\n<pre><code>html_string = '''\n    &#x3C;p>\n        Here &#x3C;i>is&#x3C;/i> a &#x3C;strike>paragraph&#x3C;/strike> with a &#x3C;b>lot&#x3C;/b> of formatting.\n    &#x3C;/p>\n    &#x3C;br>\n    &#x3C;code>Code sample&#x3C;/code> &#x26; testing escape.\n    &#x3C;ul>\n        &#x3C;li>\n            &#x3C;a href=\"https://www.google.com\">Google&#x3C;/a>\n        &#x3C;/li>\n        &#x3C;li>\n            &#x3C;a href=\"https://www.amazon.com\">Amazon&#x3C;/a>\n        &#x3C;/li>\n    &#x3C;/ul>\n'''\nparser = SlackHTMLParser()\nslack_message = parser.parse(html_string)\nprint(slack_message)\n</code></pre>\n<p>Now we can test our formatter in an actual Slack message!  Import your formatter class or add it to your existing code so you're able to do the following.</p>\n<pre><code>html_string = '''\n    &#x3C;p>\n        Here &#x3C;i>is&#x3C;/i> a &#x3C;strike>paragraph&#x3C;/strike> with a &#x3C;b>lot&#x3C;/b> of formatting.\n    &#x3C;/p>\n    &#x3C;br>\n    &#x3C;code>Code sample&#x3C;/code> &#x26; testing escape.\n    &#x3C;ul>\n        &#x3C;li>\n            &#x3C;a href=\"https://www.google.com\">Google&#x3C;/a>\n        &#x3C;/li>\n        &#x3C;li>\n            &#x3C;a href=\"https://www.amazon.com\">Amazon&#x3C;/a>\n        &#x3C;/li>\n    &#x3C;/ul>\n'''\nwebhook_url = os.environ.get('SLACK_WEBHOOK_URL')\nparser = SlackHTMLParser()\nslack_message = parser.parse(html_string)\nslack = SlackWebhookBot(webhook_url)\nslack.send(slack_message)\n</code></pre>\n<p>You should see the following message in your notifications channel.</p>\n<p><img src=\"/images/slack-webhook/slack-format-message.jpg\" alt=\"Second message in Slack {680x140}\"></p>\n<p>Looks pretty good!  <em>Note that you can still send plain text messages, you don't need to use HTML.</em></p>\n<p>For some final adjustments, you may have noticed that the message preview on the notification that popped up showed the actual <code>mrkdwn</code> characters as opposed to a formatted notification.  This looks a little sloppy, so let's make a new notification title that is similar to an email subject line.</p>\n<p>We will briefly look at the basics of Slack's <a href=\"https://api.slack.com/block-kit\">Block Kit</a>, which is a powerful way to add lots of customization to your Slack messages.  You can also explore Block Kit with Slack's <a href=\"https://app.slack.com/block-kit-builder/\">Block Kit Builder</a> which provides a preview of your Slack message.</p>\n<p>Without diving too much into the details on the Block Kit, let's update our <code>SlackWebhookBot</code> class and add a method that adds a title block and a body block for our message.  Our subject line will appear in the notification itself, and also in the actual Slack message.</p>\n<pre><code># Add the `Dict` typing import to the existing typing imports\nfrom typing import Dict\n\ndef format_message(self, subject: str, body: str) -> Dict:\n    \"\"\"Formats the subject and message body into Slack blocks.\n\n    Args:\n        subject: Subject that will appear on the notification popup.\n        body: The full message body.\n\n    Returns:\n        A dictionary payload with Slack block formatting.\n    \"\"\"\n    return {\n        'text': subject,\n        'blocks': [\n            {\n                'type': 'section',\n                'text': {\n                    'type': 'mrkdwn',\n                    'text': f'*{subject}*',\n                },\n            },\n            {\n                'type': 'section',\n                'text': {\n                    'type': 'mrkdwn',\n                    'text': body,\n                },\n            },\n        ],\n    }\n</code></pre>\n<p>Now we can tweak our <code>send</code> method to format a new message and accept a subject string as a Kwarg.</p>\n<pre><code>def send(self, message: str, subject: str = 'New message!') -> bool:\n    \"\"\"Sends a formatted message to the webhook URL.\n\n    Args:\n        message: Plain text string to send to Slack.\n\n    Kwargs:\n        subject: The subject of the message that will appear in the notification\n            preview.\n\n    Returns:\n        A boolean representing if the request was successful.\n    \"\"\"\n    success = False\n    payload = self.format_message(subject, message)\n    try:\n        r = requests.post(\n            self.webhook_url,\n            headers=self.headers,\n            json=payload,\n            timeout=self.timeout\n        )\n    except requests.Timeout:\n        logger.error('Timeout occurred when trying to send message to Slack.')\n    except requests.RequestException as e:\n        logger.error(f'Error occurred when communicating with Slack: {e}.')\n    else:\n        success = True\n        logger.info('Successfully sent message to Slack.')\n\n    return success\n</code></pre>\n<p>And we can test our notification with a new subject line.</p>\n<pre><code>html_string = '''\n    &#x3C;p>\n        Here &#x3C;i>is&#x3C;/i> a &#x3C;strike>paragraph&#x3C;/strike> with a &#x3C;b>lot&#x3C;/b> of formatting.\n    &#x3C;/p>\n    &#x3C;br>\n    &#x3C;code>Code sample&#x3C;/code> &#x26; testing escape.\n    &#x3C;ul>\n        &#x3C;li>\n            &#x3C;a href=\"https://www.google.com\">Google&#x3C;/a>\n        &#x3C;/li>\n        &#x3C;li>\n            &#x3C;a href=\"https://www.amazon.com\">Amazon&#x3C;/a>\n        &#x3C;/li>\n    &#x3C;/ul>\n'''\nwebhook_url = os.environ.get('SLACK_WEBHOOK_URL')\nparser = SlackHTMLParser()\nslack_message = parser.parse(html_string)\nslack = SlackWebhookBot(webhook_url)\nslack.send(slack_message, subject='You\\'ve completed the tutorial!')\n</code></pre>\n<p>You should see a notification appear with the following preview</p>\n<p><img src=\"/images/slack-webhook/slack-popup.jpg\" alt=\"Slack notification {453x101}\"></p>\n<p>and the following message in your channel.</p>\n<p><img src=\"/images/slack-webhook/slack-last-message.jpg\" alt=\"Last message in Slack {680x159}\"></p>\n<p>We have a custom Slack notification app!  You can place the <code>send</code> message calls all across your applications with related messages and now you can have a better pulse on user activity that developers and any other employees/stakeholders can easily access.</p>\n<hr>\n<p>For those wanting additional challenges or to continue developing their custom app, Slack has added a lot of really cool tools to the Block Kit.  There are a ton of really cool possibilities that can be added on by updating the <code>format_message</code> method in our <code>SlackWebhookBot</code> class.</p>\n<p>Explore the Slack's <a href=\"https://app.slack.com/block-kit-builder/\">Block Kit Builder</a> and see what you can make!</p>\n<hr>\n","markdown":"\n## tl;dr\n\n### Goal\n_To set up a Slack webhook so we can send text and simple HTML notifications to receive in a Slack channel._\n\n### Process Overview\n1. Setting up a Slack webhook URL in your Slack workspace to post to a channel\n2. Posting a notification to our webhook\n3. Creating a simple HTML parser to match the custom Slack markdown flavor\n\n### Python Dependencies\n```python\n# Python standard library\nfrom html.parser import HTMLParser\nimport logging\nimport os\nimport re\nfrom typing import Any, List, Tuple\n\n# 3rd Party\nimport requests\n```\n\n### Assumptions\nI'll assume you have a Slack account, a Slack workspace setup, Slack is installed, and you have knowledge of Python with a basic understanding of webhooks.\n\n---\n\nIf you haven't heard of it before, [Slack](https://slack.com/) is a very popular team/workplace communication tool.  In addition to direct messaging, it allows you to separate discussion into various topics or **channels** for more focused team communication.\n\nAnother great feature of Slack is that you can add 3rd party [apps](https://slack.com/apps) (or integrations) from your existing stack, or even develop your own!  I have seen this streamline my own productivity, and I personally use a number of Slack apps.\n\nTo name a few, you may want to check out the following (assuming you use these tools) which I've found a lot of value in:\n- [Sentry](https://slack.com/apps/A011MFBJEUU-sentry?tab=more_info) - for application monitoring\n- [Google Calendar](https://slack.com/apps/ADZ494LHY-google-calendar?tab=more_info) - to stay on top of my meetings schedule\n- [GitHub](https://slack.com/apps/A01BP7R4KNY-github?tab=more_info) - getting notified of pull requests and meaningful changes to important repositories\n- [Jira Cloud](https://slack.com/apps/A2RPP3NFR-jira-cloud?tab=more_info) - staying on top of changes to Jira tickets\n- [AWS Chatbot](https://slack.com/apps/A6L22LZNH-aws-chatbot?tab=more_info) - alerts from CloudWatch alarms\n\nYou can browse the [Slack app directory](https://slack.com/apps) for more integrations.\n\nHowever, not every integration is going to provide the functionality you need.  This post will focus on creating our own custom Slack app with the goal of posting simple notifications to a Slack channel.\n\nA common use case where we can apply our app will be sending notifications when any sort of user activity happens on a platform.  As a developer, being notified of when a user completes a certain task can provide a lot of transparency and understanding into the usage of our application, while also keeping a sales teams informed on relevant activity on the platform.  This is the use case we'll focus on.\n\nWe will do this by posting to a webhook hosted by Slack.  For more information on webhooks, you can check out [this article](https://zapier.com/blog/what-are-webhooks/) by Zapier.\n\nLet's get started!\n\n---\n\n## Setting up the Slack App\nOpen Slack, click **Add channels**, and create a new channel called `notifications`.  This is where our Slack app will post to once we set it up.\n\n![Create a Slack channel {priority}{1004x580}](/images/slack-webhook/create-channel.jpg)\n\nNow go to a web browser and head to https://api.slack.com/apps/.\n\nClick on **Create an App**\n\n![Create a Slack App {1004x497}](/images/slack-webhook/create-app.jpg)\n\nSelect **From scratch**\n\n![Select From Scratch {1004x497}](/images/slack-webhook/from-scratch.jpg)\n\nCreate a name for your app and select the workspace you just created your `notifications` channel in.\n\n![Choose an app name and workspace {1004x501}](/images/slack-webhook/app-and-workspace.jpg)\n\n\nThis will redirect you to the **Basic Information** tab for your app.  Here, we'll enable **Incoming Webhooks**.  As it states, this will enable us to post messages from an external source.  In this case, our platform.\n\n![Enable incoming webhooks {1004x497}](/images/slack-webhook/add-webhooks.jpg)\n\n\nTurn on **Activate Incoming Webhooks** and you will see additional details appear.  Towards the bottom, click on **Add New Webhook to Workspace**.\n\n![Add a new webhook to your workspace {1004x485}](/images/slack-webhook/add-new-webhook.jpg)\n\nYou will be redirected again to select which channel to post to.  Select the `notifications` channel that we previously created and press **Allow**.\n\n![Select a channel for your app {1004x498}](/images/slack-webhook/choose-channel.jpg)\n\n\nThis will redirect you back to your app configuration and you will see a webhook URL you can now post to.  This will also include a simple curl POST request you can test with if you'd like.  Copy the webhook URL for later, and remember to **keep it private**.  This is a public URL that anyone can post to.\n\n![Copy your webhook URL {680x506}](/images/slack-webhook/copy-url.jpg)\n\n\nYou can return to the **Basic Information** of your app settings in Slack to view more API credentials and also edit the look and feel of your new Slack bot.\n\nNow we're ready to dive into the code to communicate with our webhook!\n\n---\n\n## Communicating with our Webhook\nTo communicate with our webhook, we'll use the [`requests`](https://docs.python-requests.org/en/master/) Python library.  This is a third party library, so you'll want to have a Python virtual environment set up to handle your dependencies.  Virtual environments are out of the scope of this article, but you can read more on them [here](https://docs.python.org/3/tutorial/venv.html).\n\nInside your virtual environment, you can run the following to install the library.\n```bash\npip install requests\n```\n\nNow, we'll set up a class to communicate with our Slack endpoint.  We'll start by just sending a plain text message to Slack.\n\n```python\nimport logging\n\nimport requests\n\n\nlogger = logging.getLogger()\nlogger.setLevel(logging.INFO)\n\n\nclass SlackWebhookBot:\n    def __init__(self, webhook_url: str, timeout: int = 15):\n        \"\"\"Class to send messages to a provided Slack webhook URL.\n\n        You can read more about Slack's Incoming Webhooks here:\n            https://api.slack.com/messaging/webhooks\n        \n        Args:\n            webhook_url: The webhook URL to send a message to.  Typically\n                formatted like \"https://hooks.slack.com/services/...\".\n        \n        Kwargs:\n            timeout: Number of seconds before the request will timeout.\n                This is used to prevent a hang and is set to a default\n                value of 15 seconds.\n        \"\"\"\n        self.webhook_url = webhook_url\n        self.timeout = timeout\n        self.headers = {\n            'Content-Type': 'application/json',\n        }\n    \n\n    def send(self, message: str) -> bool:\n        \"\"\"Sends a message to the webhook URL.\n\n        Per the Slack Incoming Webhook example.  The body of the request\n        (for plain text) should be formatted as follows:\n            `{\"text\": \"Hello, World!\"}`\n\n        Args:\n            message: Plain text string to send to Slack.\n\n        Returns:\n            A boolean representing if the request was successful.\n        \"\"\"\n        success = False\n        payload = {\n            'text': message,\n        }\n        try:\n            r = requests.post(\n                self.webhook_url,\n                headers=self.headers,\n                json=payload,\n                timeout=self.timeout\n            )\n        except requests.Timeout:\n            logger.error('Timeout occurred when trying to send message to Slack.')\n        except requests.RequestException as e:\n            logger.error(f'Error occurred when communicating with Slack: {e}.')\n        else:\n            success = True\n            logger.info('Successfully sent message to Slack.')\n\n        return success\n```\n\nAbove is the basic setup for communicating with the Slack webhook.  We can run a quick test by moving this code to a script and adding the following.\n```python\nimport os\n\nwebhook_url = os.environ.get('SLACK_WEBHOOK_URL')\nslack = SlackWebhookBot(webhook_url)\nslack.send('Hello, world!')\n```\n\nMake sure to set your Slack webhook URL to the `SLACK_WEBHOOK_URL` environment variable, and make sure you're in your virtual environment with the `requests` package installed before running the script.  This can be done on MacOS with the following.\n```bash\nexport SLACK_WEBHOOK_URL=https://hooks.slack.com/services/...\npython slack_webhook.py\n```\n\nWhen you run this, you should see a message from you Slack bot appear in the `notifications` channel!\n\n![Hello world message in Slack {1004x675}](/images/slack-webhook/slack-first-message.jpg)\n\n\nFor our notifications to be more helpful, we may want to add links or other formatting.  To do this, we will write our notifications with HTML tags, and then parse these tags and convert them to the [Slack flavored Markdown](https://api.slack.com/reference/surfaces/formatting) called `mrkdwn`.\n\n---\n\n## Adding a simple HTML parser to our class\nFrom the [Slack formatting guide](https://api.slack.com/reference/surfaces/formatting) for messages, we can see all of the ways to format text in our messages.  For our purposes, we will focus on a primary list.\n\n- Making text <i>`_italicized_`</i> (`<i>`)\n- Making text <b>`*bold*`</b> (`<b>`)\n- Striking through ~<strike>`text`</strike>~ (`<strike>`)\n- Adding line breaks (`<br>`)\n- Adding `one-line code blocks` using the backtick character (`<code>`)\n- Adding unordered lists (line broken dashes) (`<ul><li>`)\n- Adding external links `<[external link]|[display text]>` (`<a>`)\n\nAlso note that the Slack documentation says that [certain characters need to be escaped](https://api.slack.com/reference/surfaces/formatting#escaping).\n\nThere are a few more styles that could be implemented, but we'll focus on just this list for this post.\n\nTo do this, we will utilize the [`html`](https://docs.python.org/3/library/html.html) module in the Python standard library to parse HTML tags, attributes, and values.\n\nLet's write a class (we need to inherit functions for the `HTMLParser` class) where we will parse all of the tags and attributes, and escape the message text when needed.  The idea here is that we can construct a string from scratch and for each tag we care about we can \"replace\" the HTML tags with the relevant mrkdwn syntax.\n\n```python\nfrom html.parser import HTMLParser\nimport re\nfrom typing import Any, List, Tuple\n\n\nclass SlackHTMLParser(HTMLParser):\n    def __init__(self, *args, **kwargs):\n        \"\"\"Escapes and converts an HTML string to Slack flavored\n        Markdown (mrkdwn).\n\n        More about Slack's Markdown Flavor (mrkdwn) can be seen here:\n            https://api.slack.com/reference/surfaces/formatting\n        \n        Call using `SlackHTMLParser(message_body).parse()`.\n        \"\"\"\n        super().__init__(*args, **kwargs)\n        self.slack_message = ''\n        self.ignore_tag = False  # Used to skip tags we don't care about\n        self.line_break = '::LINE::BREAK::'  # Unique sequence for swapping a <br>\n\n\n    def handle_starttag(self, tag: str, attrs: List[Tuple[str, Any]]):\n        \"\"\"Called when the opening of a tag is encountered.\n\n        The idea here is to swap out the tag with the respective mrkdwn\n        symbol.\n\n        Args:\n            tag: Lowercase name of the HTML tag.  E.G. `br` or `i`.\n            attrs: List of tuples with the tuple having the following form:\n                (attribute name, value).  E.G. ('href', 'www.example.com').\n        \"\"\"\n        if tag in ['i', 'em']:\n            self.slack_message += '_'\n        elif tag in ['b', 'strong']:\n            self.slack_message += '*'\n        elif tag == 'strike':\n            self.slack_message += '~'\n        elif tag in ['br', 'p', 'ul']:\n            self.slack_message += self.line_break\n        elif tag == 'li':\n            self.slack_message += f'{self.line_break}- '\n        elif tag == 'code':\n            self.slack_message += '`'\n        elif tag == 'a':\n            href = [x[1] for x in attrs if x[0] == 'href']\n            if len(href) > 0:\n                self.slack_message += f'<{href[0]}|'\n        else:\n            self.ignore_tag = True\n\n\n    def handle_data(self, data: str):\n        \"\"\"Handles the data within a tag.\n\n        This is called after `handle_starttag` and before `handle_endtag`.\n\n        We will also escape the following text per Slack's documentation:\n        - '&' -> '&amp;'\n        - '<' -> '&lt;'\n        - '>' -> '&gt;'\n\n        Args:\n            data: The data/string within the HTML tag.\n        \"\"\"\n        if not self.ignore_tag:\n            self.slack_message += data\\\n                .replace('&', '&amp;')\\\n                .replace('<', '&lt;')\\\n                .replace('>', '&gt;')\n\n\n    def handle_endtag(self, tag: str):\n        \"\"\"Called when the closing of a tag is encountered.\n\n        The idea here is to swap out the tag with the respective mrkdwn\n        symbol.  This is basically the same as the handle_starttag.\n\n        Args:\n            tag: Lowercase name of the HTML tag.  E.G. `br` or `i`.\n        \"\"\"\n        if tag in ['i', 'em']:\n            self.slack_message += '_'\n        elif tag in ['b', 'strong']:\n            self.slack_message += '*'\n        elif tag == 'strike':\n            self.slack_message += '~'\n        elif tag == 'p':\n            self.slack_message += self.line_break\n        elif tag == 'code':\n            self.slack_message += '`'\n        elif tag == 'a':\n            self.slack_message += '>'\n        \n        self.ignore_tag = False\n\n\n    def parse(self, html_string: str) -> str:\n        \"\"\"Parses a given HTML string and applies simple formatting.\n        \n        Note that we need to apply the line break replacing here\n        instead of with the handle tag methods.\n\n        Args:\n            html_string: The HTML string to convert to Slack mrkdwn.\n\n        Returns:\n            A formatted Slack mrkdwn string.\n        \"\"\"\n        self.feed(html_string)\n        return re.sub(\n            r'^(\\n)+',  # Remove the leading line breaks\n            '',\n            ' '.join(self.slack_message.split()).replace(self.line_break, '\\n')\n        )\n```\n\nWe can test our class out with the following code.\n\n```python\nhtml_string = '''\n    <p>\n        Here <i>is</i> a <strike>paragraph</strike> with a <b>lot</b> of formatting.\n    </p>\n    <br>\n    <code>Code sample</code> & testing escape.\n    <ul>\n        <li>\n            <a href=\"https://www.google.com\">Google</a>\n        </li>\n        <li>\n            <a href=\"https://www.amazon.com\">Amazon</a>\n        </li>\n    </ul>\n'''\nparser = SlackHTMLParser()\nslack_message = parser.parse(html_string)\nprint(slack_message)\n```\n\nNow we can test our formatter in an actual Slack message!  Import your formatter class or add it to your existing code so you're able to do the following.\n\n```python\nhtml_string = '''\n    <p>\n        Here <i>is</i> a <strike>paragraph</strike> with a <b>lot</b> of formatting.\n    </p>\n    <br>\n    <code>Code sample</code> & testing escape.\n    <ul>\n        <li>\n            <a href=\"https://www.google.com\">Google</a>\n        </li>\n        <li>\n            <a href=\"https://www.amazon.com\">Amazon</a>\n        </li>\n    </ul>\n'''\nwebhook_url = os.environ.get('SLACK_WEBHOOK_URL')\nparser = SlackHTMLParser()\nslack_message = parser.parse(html_string)\nslack = SlackWebhookBot(webhook_url)\nslack.send(slack_message)\n```\n\nYou should see the following message in your notifications channel.\n\n![Second message in Slack {680x140}](/images/slack-webhook/slack-format-message.jpg)\n\nLooks pretty good!  _Note that you can still send plain text messages, you don't need to use HTML._\n\nFor some final adjustments, you may have noticed that the message preview on the notification that popped up showed the actual `mrkdwn` characters as opposed to a formatted notification.  This looks a little sloppy, so let's make a new notification title that is similar to an email subject line.\n\nWe will briefly look at the basics of Slack's [Block Kit](https://api.slack.com/block-kit), which is a powerful way to add lots of customization to your Slack messages.  You can also explore Block Kit with Slack's [Block Kit Builder](https://app.slack.com/block-kit-builder/) which provides a preview of your Slack message.\n\nWithout diving too much into the details on the Block Kit, let's update our `SlackWebhookBot` class and add a method that adds a title block and a body block for our message.  Our subject line will appear in the notification itself, and also in the actual Slack message.\n\n```python\n# Add the `Dict` typing import to the existing typing imports\nfrom typing import Dict\n\ndef format_message(self, subject: str, body: str) -> Dict:\n    \"\"\"Formats the subject and message body into Slack blocks.\n\n    Args:\n        subject: Subject that will appear on the notification popup.\n        body: The full message body.\n\n    Returns:\n        A dictionary payload with Slack block formatting.\n    \"\"\"\n    return {\n        'text': subject,\n        'blocks': [\n            {\n                'type': 'section',\n                'text': {\n                    'type': 'mrkdwn',\n                    'text': f'*{subject}*',\n                },\n            },\n            {\n                'type': 'section',\n                'text': {\n                    'type': 'mrkdwn',\n                    'text': body,\n                },\n            },\n        ],\n    }\n```\n\nNow we can tweak our `send` method to format a new message and accept a subject string as a Kwarg.\n\n```python\ndef send(self, message: str, subject: str = 'New message!') -> bool:\n    \"\"\"Sends a formatted message to the webhook URL.\n\n    Args:\n        message: Plain text string to send to Slack.\n\n    Kwargs:\n        subject: The subject of the message that will appear in the notification\n            preview.\n\n    Returns:\n        A boolean representing if the request was successful.\n    \"\"\"\n    success = False\n    payload = self.format_message(subject, message)\n    try:\n        r = requests.post(\n            self.webhook_url,\n            headers=self.headers,\n            json=payload,\n            timeout=self.timeout\n        )\n    except requests.Timeout:\n        logger.error('Timeout occurred when trying to send message to Slack.')\n    except requests.RequestException as e:\n        logger.error(f'Error occurred when communicating with Slack: {e}.')\n    else:\n        success = True\n        logger.info('Successfully sent message to Slack.')\n\n    return success\n```\n\nAnd we can test our notification with a new subject line.\n\n```python\nhtml_string = '''\n    <p>\n        Here <i>is</i> a <strike>paragraph</strike> with a <b>lot</b> of formatting.\n    </p>\n    <br>\n    <code>Code sample</code> & testing escape.\n    <ul>\n        <li>\n            <a href=\"https://www.google.com\">Google</a>\n        </li>\n        <li>\n            <a href=\"https://www.amazon.com\">Amazon</a>\n        </li>\n    </ul>\n'''\nwebhook_url = os.environ.get('SLACK_WEBHOOK_URL')\nparser = SlackHTMLParser()\nslack_message = parser.parse(html_string)\nslack = SlackWebhookBot(webhook_url)\nslack.send(slack_message, subject='You\\'ve completed the tutorial!')\n```\n\nYou should see a notification appear with the following preview\n\n![Slack notification {453x101}](/images/slack-webhook/slack-popup.jpg)\n\n\nand the following message in your channel.\n\n![Last message in Slack {680x159}](/images/slack-webhook/slack-last-message.jpg)\n\n\nWe have a custom Slack notification app!  You can place the `send` message calls all across your applications with related messages and now you can have a better pulse on user activity that developers and any other employees/stakeholders can easily access.\n\n---\n\nFor those wanting additional challenges or to continue developing their custom app, Slack has added a lot of really cool tools to the Block Kit.  There are a ton of really cool possibilities that can be added on by updating the `format_message` method in our `SlackWebhookBot` class.\n\nExplore the Slack's [Block Kit Builder](https://app.slack.com/block-kit-builder/) and see what you can make!\n\n---\n","title":"Setting up a Slack webhook for simple notifications","date":"2021-07-11","tags":["python","slack","webhook","api"],"description":"Setting up a Slack webhook to send plain text or simple HTML notifications to a Slack channel."},{"id":"visualizing-your-linkedin-connections","contentHtml":"<h2>tl;dr</h2>\n<h3>Goal</h3>\n<p><em>To understand and visualize the companies within my directly connected network on LinkedIn</em></p>\n<h3>Process overview</h3>\n<ol>\n<li><strong>LinkedIn data sources</strong> - retrieving LinkedIn Network data from a \"Get a copy of your data\" CSV export</li>\n<li><strong>Diving into the data</strong> - exploring, cleaning, and aggregating the data with <a href=\"https://pandas.pydata.org/\"><code>Pandas</code></a></li>\n<li><strong>Creating the network</strong> - creating a network graph using <a href=\"https://networkx.org/\"><code>NetworkX</code></a></li>\n<li><strong>Visualization</strong> - visualizing the network with <a href=\"https://pyvis.readthedocs.io/en/latest/\"><code>pyvis</code></a></li>\n<li><strong>Improving the output</strong> - cleaning up the network graph with additional filtering</li>\n</ol>\n<h3>Results</h3>\n<p><em>Hover over the nodes for more details</em></p>\n<ul>\n<li><a href=\"/network/first-nx-graph.html\">The first network graph</a></li>\n<li><a href=\"/network/second-nx-graph.html\">The second (more specific) network graph</a></li>\n</ul>\n<h3>Python dependencies</h3>\n<pre><code># Python standard library\nfrom difflib import get_close_matches\n\n# 3rd party\nimport networkx as nx\nimport pandas as pd\nfrom pyvis.network import Network\n</code></pre>\n<hr>\n<p>Recently, I was exploring <a href=\"https://www.linkedin.com/in/bradley-schoeneweis/\">my LinkedIn</a> network to see what some of my colleagues from high school and undergrad are currently up to.</p>\n<p>As I was scrolling through the connections page, I noticed LinkedIn gives you options to filter and searching with ease, but it doesn't really provide tools to learn about your network as a whole.</p>\n<p>So I decided to see if there was an easy way to export my network data to see what I could do with a few hours of exploring the data.</p>\n<h2>LinkedIn data sources</h2>\n<p>My first thought was to checkout out the <a href=\"https://www.linkedin.com/developers/\">LinkedIn's Developer API</a>.</p>\n<p>Something I do fairly frequently at my current job is integrating various 3rd-party REST APIs into our platform, so I wanted to see all the functionality and possibilities that this API would provide.</p>\n<p>After reading through some documentation, I decided this wasn't a direction I wanted to pursue. Most of their developer products require approval, so I decided to look into other options.</p>\n<p>Another thought I had was to write a quick scraping script to pull down the HTML of my connections page and parse out names and companies, but I assumed there had to be a more simple way to get this data.</p>\n<p>Finally, after a bit of research, I found that there are various \"Get a copy of your data\" reports that you can run within LinkedIn.  In order to get to these reports, you can do the following:</p>\n<ol>\n<li>On the homepage toolbar, click the <strong>Me</strong> dropdown</li>\n<li>Under the <em>Account</em> section, click <strong>Settings &#x26; Privacy</strong></li>\n<li>Click on <strong>Get a copy of your data</strong>, and you can view the various reports</li>\n<li>Select the reports you're interested in, for this, I just checked <strong>Connections</strong></li>\n</ol>\n<p>After requesting the report, it should only take a few minutes before you get an email saying your report is ready for export.</p>\n<h2>Diving into the data</h2>\n<p>To reiterate our goal, we want to get a broad understanding of the companies within the first layer of our network (direct connections). Now, let's load up Python and learn more about this data in this CSV.</p>\n<h3>Reading in the data</h3>\n<p>Once the CSV is downloaded, we can open it up with Pandas and take a look (<em>output will be commented below</em>).</p>\n<pre><code>import pandas as pd\n\n# We want to skip the first three rows because of Notes at the top\ndf = pd.read_csv('Connections.csv', skiprows=3)\n\ndf.columns\n# ['First Name', 'Last Name', 'Email Address', 'Company', 'Position', 'Connected On',]\n\ndf.info()\n\"\"\"\n&#x3C;class 'pandas.core.frame.DataFrame'>\nRangeIndex: 376 entries, 0 to 375\nData columns (total 6 columns):\n #   Column         Non-Null Count  Dtype \n---  ------         --------------  ----- \n 0   First Name     375 non-null    object\n 1   Last Name      375 non-null    object\n 2   Email Address  1 non-null      object\n 3   Company        371 non-null    object\n 4   Position       371 non-null    object\n 5   Connected On   376 non-null    object\ndtypes: object(6)\nmemory usage: 17.8+ KB\n\"\"\"\n</code></pre>\n<p>I won't post the name's of any individuals or full rows to respect the privacy of my connections, but when I searched through the my Connections CSV, I noticed a few initial patterns that would help clean up the data.</p>\n<h3>Cleaning up the data</h3>\n<p>At first glance, the first thing I notice is connections who don't list a current company, so let's get rid of those.</p>\n<pre><code>df = df[df['Company'].notna()].sort_values(by='Company')\n</code></pre>\n<p>After sorting, another thing I noticed was that some of these company names belong to the same company, but the individuals wrote them differently.</p>\n<p>An example of this is <code>'IBM Global Solution Center'</code> and <code>'IBM'</code>; for our purposes, these should both be classified as <code>IBM</code>.</p>\n<p>Let's run through a fuzzy match run using <a href=\"https://docs.python.org/3/library/difflib.html#difflib.get_close_matches\">difflib's <code>get_close_matches</code></a> to try and bucket some of these similar company names.</p>\n<pre><code>from difflib import get_close_matches\n\ncompanies = df['Company'].drop_duplicates()\n\n# cutoff=0.7 is a similarity ranking, and n=10 just takes the top 10 values\nsimilar_companies = {x: get_close_matches(x, companies, n=10, cutoff=0.7)\n                     for x in companies}\n\n# We are only interested in the entries that had another match\nsimilar_companies = {x: [name for name in y if name != x]\n                     for x, y in similar_companies.items() if len(y) > 1}\n</code></pre>\n<p>Now, this solution is not perfect, but it will help draw out some similar companies. You should still run a manual inspection of the data (the IBM example I gave above is one that doesn't show up in the fuzzy match results).</p>\n<p>Based upon the results, let's group together some of the companies that had matches.</p>\n<pre><code>df['Company'] = df['Company'].replace({\n    'KPMG US': similar_companies['KPMG US'],\n    'Self-employed': similar_companies['Self-employed'],\n    'IBM Global Solution Center': 'IBM',\n})\n</code></pre>\n<p>The next thing you may have noticed is that in our <code>similar_companies</code> dictionary, we cleaned up a <code>Self-employed</code> entry.</p>\n<p>To stay aligned with our goal, let's drop these entries, as well as your current company.</p>\n<pre><code>companies_to_drop = ['self employed', 'your current company']\ndf = df[~df['Company'].str.lower().isin(companies_to_drop)]\n</code></pre>\n<h3>Aggregating the data</h3>\n<p>Now that our data is cleaned up a bit, let's aggregate and sum the number of connections for each of the companies.</p>\n<pre><code>df_company_counts = df['Company'].value_counts().reset_index()\ndf_company_counts.columns = ['Company', 'Count']  # For ease of understanding\ndf_company_counts = df_company_counts.sort_values(by='Count', ascending=False)\n</code></pre>\n<h2>Creating the network</h2>\n<p>We have the numbers we want for each company, now let's jump into using <code>NetworkX</code> to recreate a network.</p>\n<p>The first step will be to initialize our graph, and add yourself as the central node, as it is your network.</p>\n<pre><code>import networkx as nx\n\nG = nx.Graph()\nG.add_node('Me')\n</code></pre>\n<p>Then, we'll loop through our <code>df_company_counts</code> DataFrame and add each company as a node.</p>\n<p><em>You'll notice some HTML tags in the title below, this is just to make it more readable for later</em></p>\n<pre><code>for _, row in df_company_counts.iterrows():\n\t# The title will be for more information later on\n    title = '&#x3C;b>{0}&#x3C;/b> ({1})&#x3C;br>&#x3C;hr>Positions:&#x3C;br>'.format(row['Company'],\n    \t\t\t\t\t\t\t\t\t\t\t\t\t\trow['Count'])\n\n    # In addition to the full company name, let's add each position in a\n    # list to see the roles our connections have at these companies\n    position_list = ''.join('&#x3C;li>{}&#x3C;/li>'.format(x)\n    \t\t\t\t\t\tfor x in df[df['Company'] == row['Company']]['Position'])\n    title += '&#x3C;ul>{0}&#x3C;/ul>'.format(position_list)\n\n    # For ease of viewing, limit company names to 15 letters\n    node_name = row['Company']\n    if len(node_name) > 15:\n        node_name = node_name[:15] + '...'\n\n    # Add the node and an edge connection ourself to the new node\n    G.add_node(node_name, weight=row['Count'], size=row['Count'] * 2, title=title)\n    G.add_edge('Me', node_name)\n</code></pre>\n<p>And just like that, we've created our network of connections.</p>\n<h2>Visualization</h2>\n<p>Our network graph is created, so let's get into visualizing the network.</p>\n<p>There are a few options for visualizing networks including <code>matplotlib.pyplot</code>, but I found that <code>pyvis</code> was the easiest to use for several reasons:</p>\n<ul>\n<li><code>pyvis</code> generates an HTML file</li>\n<li>Customization is made very easy</li>\n<li>The graph is interactive by default</li>\n</ul>\n<p>Let's look into generating this HTML file.</p>\n<pre><code>from pyvis.network import Network\n\nnt = Network('100%', '100%', bgcolor='#222222', font_color='white')\nnt.from_nx(G)\nnt.repulsion()  # Spaces out the nodes\nnt.show('nx.html')\n</code></pre>\n<p>And it's that simple! We specify a width and height, optional styling attributes, and then we can generate the network graph visual straight from what we created with NetworkX.</p>\n<p>Now we can see <a href=\"/network/first-nx-graph.html\">the network we generated</a>.</p>\n<p>You can hover over each node to see the total number of connections that work at the respective company, and below is a list of the positions held by your connections.</p>\n<p>As you can see, this is a bit hard to read into since there are a lot of nodes. Try and imagine reading this with +1,000 connections.</p>\n<h2>Improving the output</h2>\n<p>There are a few ways that our network could be narrowed down.</p>\n<p>Being a <em>Software Developer</em>, the thought that first occurred to me was to try and dial in on tech-related companies through known positions titles.</p>\n<p>To do this, I thought of a list of buzzwords/common job titles that I've seen across LinkedIn, and filtered down the initial DataFrame.</p>\n<p>Then, we go through the same process we did in previous sections of generating and displaying the graph.</p>\n<p><em>Again, this is not perfect, but it's a good starting point.</em></p>\n<pre><code># Filter down from a list of popular tech positions\npositions = [\n    'developer', 'engineer', 'ai', 'analytics', 'software', 'cloud', 'cto',\n    'sde', 'sre', 'saas', 'product', 'engineering', 'scientist', 'data',\n]\ndf = df[df['Position'].str.contains('|'.join(positions), case=False)]\ndf_company_counts = df['Company'].value_counts().reset_index()\ndf_company_counts.columns = ['Company', 'Count']\ndf_company_counts = df_company_counts.sort_values(by='Count', ascending=False)\n\n# Re-initialize the graph and add the nodes/edges again\nG = nx.Graph()\nG.add_node('Me')\n\nfor _, row in df_company_counts.iterrows():\n    title = '&#x3C;b>{0}&#x3C;/b> ({1})&#x3C;br>&#x3C;hr>Positions:&#x3C;br>'.format(row['Company'], row['Count'])\n    position_list = ''.join('&#x3C;li>{}&#x3C;/li>'.format(x)\n    \t\t\t\t\t\tfor x in df[df['Company'] == row['Company']]['Position'])\n    title += '&#x3C;ul>{0}&#x3C;/ul>'.format(position_list)\n    node_name = row['Company']\n    if len(node_name) > 15:\n        node_name = node_name[:15] + '...'\n\n    # Since there are less nodes, let's increase the sizes\n    G.add_node(node_name, weight=row['Count'], size=row['Count'] * 5, title=title)\n    G.add_edge('Me', node_name)\n\n# Generate the visualization\nnt = Network('100%', '100%', bgcolor='#222222', font_color='white')\nnt.from_nx(G)\nnt.repulsion()\nnt.show('nx.html')\n</code></pre>\n<p>Now, let's look at the <a href=\"/network/second-nx-graph.html\">updated results</a>.</p>\n<p>Much better! This is more readable and easier to interact with.</p>\n<p>And just like that, we achieved our goal of gaining a broader understanding of the companies in our LinkedIn network.</p>\n<hr>\n<p><strong><em>Possible improvements for those interested</em></strong></p>\n<ul>\n<li>Scraping the profile location of each of your connections to segment by location</li>\n<li>Compiling a list of companies you'd like to work for/are interested in and creating a filtering system</li>\n<li>Researching salary data for positions and gathering average pay by company</li>\n</ul>\n<hr>\n","markdown":"\n## tl;dr\n\n### Goal\n_To understand and visualize the companies within my directly connected network on LinkedIn_\n\n### Process overview\n1. **LinkedIn data sources** - retrieving LinkedIn Network data from a \"Get a copy of your data\" CSV export\n2. **Diving into the data** - exploring, cleaning, and aggregating the data with [`Pandas`](https://pandas.pydata.org/)\n3. **Creating the network** - creating a network graph using [`NetworkX`](https://networkx.org/)\n4. **Visualization** - visualizing the network with [`pyvis`](https://pyvis.readthedocs.io/en/latest/)\n5. **Improving the output** - cleaning up the network graph with additional filtering\n\n### Results\n_Hover over the nodes for more details_\n- [The first network graph](/network/first-nx-graph.html)\n- [The second (more specific) network graph](/network/second-nx-graph.html)\n\n### Python dependencies\n```python\n# Python standard library\nfrom difflib import get_close_matches\n\n# 3rd party\nimport networkx as nx\nimport pandas as pd\nfrom pyvis.network import Network\n```\n\n---\n\nRecently, I was exploring [my LinkedIn](https://www.linkedin.com/in/bradley-schoeneweis/) network to see what some of my colleagues from high school and undergrad are currently up to.\n\nAs I was scrolling through the connections page, I noticed LinkedIn gives you options to filter and searching with ease, but it doesn't really provide tools to learn about your network as a whole.\n\nSo I decided to see if there was an easy way to export my network data to see what I could do with a few hours of exploring the data.\n\n\n## LinkedIn data sources\n\nMy first thought was to checkout out the [LinkedIn's Developer API](https://www.linkedin.com/developers/).\n\nSomething I do fairly frequently at my current job is integrating various 3rd-party REST APIs into our platform, so I wanted to see all the functionality and possibilities that this API would provide.\n\nAfter reading through some documentation, I decided this wasn't a direction I wanted to pursue. Most of their developer products require approval, so I decided to look into other options.\n\nAnother thought I had was to write a quick scraping script to pull down the HTML of my connections page and parse out names and companies, but I assumed there had to be a more simple way to get this data.\n\nFinally, after a bit of research, I found that there are various \"Get a copy of your data\" reports that you can run within LinkedIn.  In order to get to these reports, you can do the following:\n1. On the homepage toolbar, click the **Me** dropdown\n2. Under the _Account_ section, click **Settings & Privacy**\n3. Click on **Get a copy of your data**, and you can view the various reports\n4. Select the reports you're interested in, for this, I just checked **Connections**\n\nAfter requesting the report, it should only take a few minutes before you get an email saying your report is ready for export.\n\n\n## Diving into the data\n\nTo reiterate our goal, we want to get a broad understanding of the companies within the first layer of our network (direct connections). Now, let's load up Python and learn more about this data in this CSV.\n\n### Reading in the data\nOnce the CSV is downloaded, we can open it up with Pandas and take a look (_output will be commented below_).\n\n```python\nimport pandas as pd\n\n# We want to skip the first three rows because of Notes at the top\ndf = pd.read_csv('Connections.csv', skiprows=3)\n\ndf.columns\n# ['First Name', 'Last Name', 'Email Address', 'Company', 'Position', 'Connected On',]\n\ndf.info()\n\"\"\"\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 376 entries, 0 to 375\nData columns (total 6 columns):\n #   Column         Non-Null Count  Dtype \n---  ------         --------------  ----- \n 0   First Name     375 non-null    object\n 1   Last Name      375 non-null    object\n 2   Email Address  1 non-null      object\n 3   Company        371 non-null    object\n 4   Position       371 non-null    object\n 5   Connected On   376 non-null    object\ndtypes: object(6)\nmemory usage: 17.8+ KB\n\"\"\"\n```\n\nI won't post the name's of any individuals or full rows to respect the privacy of my connections, but when I searched through the my Connections CSV, I noticed a few initial patterns that would help clean up the data.\n\n### Cleaning up the data\n\nAt first glance, the first thing I notice is connections who don't list a current company, so let's get rid of those.\n\n```python\ndf = df[df['Company'].notna()].sort_values(by='Company')\n```\n\nAfter sorting, another thing I noticed was that some of these company names belong to the same company, but the individuals wrote them differently.\n\nAn example of this is `'IBM Global Solution Center'` and `'IBM'`; for our purposes, these should both be classified as `IBM`.\n\nLet's run through a fuzzy match run using [difflib's `get_close_matches`](https://docs.python.org/3/library/difflib.html#difflib.get_close_matches) to try and bucket some of these similar company names.\n```python\nfrom difflib import get_close_matches\n\ncompanies = df['Company'].drop_duplicates()\n\n# cutoff=0.7 is a similarity ranking, and n=10 just takes the top 10 values\nsimilar_companies = {x: get_close_matches(x, companies, n=10, cutoff=0.7)\n                     for x in companies}\n\n# We are only interested in the entries that had another match\nsimilar_companies = {x: [name for name in y if name != x]\n                     for x, y in similar_companies.items() if len(y) > 1}\n```\n\nNow, this solution is not perfect, but it will help draw out some similar companies. You should still run a manual inspection of the data (the IBM example I gave above is one that doesn't show up in the fuzzy match results).\n\nBased upon the results, let's group together some of the companies that had matches.\n```python\ndf['Company'] = df['Company'].replace({\n    'KPMG US': similar_companies['KPMG US'],\n    'Self-employed': similar_companies['Self-employed'],\n    'IBM Global Solution Center': 'IBM',\n})\n```\n\nThe next thing you may have noticed is that in our `similar_companies` dictionary, we cleaned up a `Self-employed` entry.\n\nTo stay aligned with our goal, let's drop these entries, as well as your current company.\n```python\ncompanies_to_drop = ['self employed', 'your current company']\ndf = df[~df['Company'].str.lower().isin(companies_to_drop)]\n```\n\n### Aggregating the data\nNow that our data is cleaned up a bit, let's aggregate and sum the number of connections for each of the companies.\n\n```python\ndf_company_counts = df['Company'].value_counts().reset_index()\ndf_company_counts.columns = ['Company', 'Count']  # For ease of understanding\ndf_company_counts = df_company_counts.sort_values(by='Count', ascending=False)\n```\n\n## Creating the network\n\nWe have the numbers we want for each company, now let's jump into using `NetworkX` to recreate a network.\n\nThe first step will be to initialize our graph, and add yourself as the central node, as it is your network.\n\n```python\nimport networkx as nx\n\nG = nx.Graph()\nG.add_node('Me')\n```\n\nThen, we'll loop through our `df_company_counts` DataFrame and add each company as a node.\n\n_You'll notice some HTML tags in the title below, this is just to make it more readable for later_\n```python\nfor _, row in df_company_counts.iterrows():\n\t# The title will be for more information later on\n    title = '<b>{0}</b> ({1})<br><hr>Positions:<br>'.format(row['Company'],\n    \t\t\t\t\t\t\t\t\t\t\t\t\t\trow['Count'])\n\n    # In addition to the full company name, let's add each position in a\n    # list to see the roles our connections have at these companies\n    position_list = ''.join('<li>{}</li>'.format(x)\n    \t\t\t\t\t\tfor x in df[df['Company'] == row['Company']]['Position'])\n    title += '<ul>{0}</ul>'.format(position_list)\n\n    # For ease of viewing, limit company names to 15 letters\n    node_name = row['Company']\n    if len(node_name) > 15:\n        node_name = node_name[:15] + '...'\n\n    # Add the node and an edge connection ourself to the new node\n    G.add_node(node_name, weight=row['Count'], size=row['Count'] * 2, title=title)\n    G.add_edge('Me', node_name)\n```\n\nAnd just like that, we've created our network of connections.\n\n\n## Visualization\n\nOur network graph is created, so let's get into visualizing the network.\n\nThere are a few options for visualizing networks including `matplotlib.pyplot`, but I found that `pyvis` was the easiest to use for several reasons:\n- `pyvis` generates an HTML file\n- Customization is made very easy\n- The graph is interactive by default\n\nLet's look into generating this HTML file.\n```python\nfrom pyvis.network import Network\n\nnt = Network('100%', '100%', bgcolor='#222222', font_color='white')\nnt.from_nx(G)\nnt.repulsion()  # Spaces out the nodes\nnt.show('nx.html')\n```\n\nAnd it's that simple! We specify a width and height, optional styling attributes, and then we can generate the network graph visual straight from what we created with NetworkX.\n\nNow we can see [the network we generated](/network/first-nx-graph.html).\n\nYou can hover over each node to see the total number of connections that work at the respective company, and below is a list of the positions held by your connections.\n\nAs you can see, this is a bit hard to read into since there are a lot of nodes. Try and imagine reading this with +1,000 connections.\n\n## Improving the output\n\nThere are a few ways that our network could be narrowed down.\n\nBeing a _Software Developer_, the thought that first occurred to me was to try and dial in on tech-related companies through known positions titles.\n\nTo do this, I thought of a list of buzzwords/common job titles that I've seen across LinkedIn, and filtered down the initial DataFrame.\n\nThen, we go through the same process we did in previous sections of generating and displaying the graph.\n\n_Again, this is not perfect, but it's a good starting point._\n```python\n# Filter down from a list of popular tech positions\npositions = [\n    'developer', 'engineer', 'ai', 'analytics', 'software', 'cloud', 'cto',\n    'sde', 'sre', 'saas', 'product', 'engineering', 'scientist', 'data',\n]\ndf = df[df['Position'].str.contains('|'.join(positions), case=False)]\ndf_company_counts = df['Company'].value_counts().reset_index()\ndf_company_counts.columns = ['Company', 'Count']\ndf_company_counts = df_company_counts.sort_values(by='Count', ascending=False)\n\n# Re-initialize the graph and add the nodes/edges again\nG = nx.Graph()\nG.add_node('Me')\n\nfor _, row in df_company_counts.iterrows():\n    title = '<b>{0}</b> ({1})<br><hr>Positions:<br>'.format(row['Company'], row['Count'])\n    position_list = ''.join('<li>{}</li>'.format(x)\n    \t\t\t\t\t\tfor x in df[df['Company'] == row['Company']]['Position'])\n    title += '<ul>{0}</ul>'.format(position_list)\n    node_name = row['Company']\n    if len(node_name) > 15:\n        node_name = node_name[:15] + '...'\n\n    # Since there are less nodes, let's increase the sizes\n    G.add_node(node_name, weight=row['Count'], size=row['Count'] * 5, title=title)\n    G.add_edge('Me', node_name)\n\n# Generate the visualization\nnt = Network('100%', '100%', bgcolor='#222222', font_color='white')\nnt.from_nx(G)\nnt.repulsion()\nnt.show('nx.html')\n```\n\nNow, let's look at the [updated results](/network/second-nx-graph.html).\n\nMuch better! This is more readable and easier to interact with.\n\nAnd just like that, we achieved our goal of gaining a broader understanding of the companies in our LinkedIn network.\n\n---\n\n**_Possible improvements for those interested_**\n- Scraping the profile location of each of your connections to segment by location\n- Compiling a list of companies you'd like to work for/are interested in and creating a filtering system\n- Researching salary data for positions and gathering average pay by company\n\n---\n","title":"Visualizing your LinkedIn Connections using Python","date":"2021-04-08","tags":["python","pandas","data-visualization","networkx"],"description":"Using Python's Pandas, NetworkX, and pyvis to understand and visualize companies within a directly connected LinkedIn network."}]},"__N_SSG":true}