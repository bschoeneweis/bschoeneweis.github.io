<!DOCTYPE html><html><head><script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-193041393-1"></script><script>
            window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
            gtag('config', 'UA-193041393-1', {
              page_path: window.location.pathname,
            });
          </script><meta name="viewport" content="width=device-width"/><meta charSet="utf-8"/><link rel="alternate" type="application/rss+xml" title="RSS" href="/feed.xml"/><link rel="preload" href="/fonts/FiraCode-VariableFont_wght.ttf" as="font" crossorigin="anonymous"/><link rel="icon" href="data:image/svg+xml,&lt;svg xmlns=&#x27;http://www.w3.org/2000/svg&#x27; viewBox=&#x27;0 0 100 100&#x27;&gt;&lt;text y=&#x27;.9em&#x27; font-size=&#x27;90&#x27;&gt;üëã&lt;/text&gt;&lt;/svg&gt;"/><meta name="description" content="All Tags"/><meta property="og:image" content="https://og-image.vercel.app/All%20Tags.png?theme=light&amp;md=1&amp;fontSize=50px&amp;images=https%3A%2F%2Fassets.vercel.com%2Fimage%2Fupload%2Ffront%2Fassets%2Fdesign%2Fhyper-color-logo.svg&amp;widths=350&amp;heights=350"/><meta name="robots" content="follow, index"/><meta name="og:title" content="All Tags"/><meta property="og:site_name" content="All Tags"/><meta property="og:description" content="All Tags"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:site" content="@bschoeneweis"/><meta name="twitter:title" content="Bradley Schoeneweis"/><meta name="twitter:description" content="All Tags"/><meta name="twitter:image" content="https://og-image.vercel.app/All%20Tags.png?theme=light&amp;md=1&amp;fontSize=50px&amp;images=https%3A%2F%2Fassets.vercel.com%2Fimage%2Fupload%2Ffront%2Fassets%2Fdesign%2Fhyper-color-logo.svg&amp;widths=350&amp;heights=350"/><title>All Tags</title><meta name="next-head-count" content="17"/><link rel="preload" href="/_next/static/css/06dea8e0c799365a.css" as="style"/><link rel="stylesheet" href="/_next/static/css/06dea8e0c799365a.css" data-n-g=""/><link rel="preload" href="/_next/static/css/22c5b56681c15756.css" as="style"/><link rel="stylesheet" href="/_next/static/css/22c5b56681c15756.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-5cd94c89d3acac5f.js"></script><script src="/_next/static/chunks/webpack-265d442ef7c5c82e.js" defer=""></script><script src="/_next/static/chunks/framework-7d488969745094b0.js" defer=""></script><script src="/_next/static/chunks/main-c3ed9a593ffd1a6c.js" defer=""></script><script src="/_next/static/chunks/pages/_app-d542c2ab22c8ff03.js" defer=""></script><script src="/_next/static/chunks/4824-86805e89d9bc00a3.js" defer=""></script><script src="/_next/static/chunks/pages/tags-66869115473197a0.js" defer=""></script><script src="/_next/static/Llfq-lYryHX2DkunnEbsb/_buildManifest.js" defer=""></script><script src="/_next/static/Llfq-lYryHX2DkunnEbsb/_ssgManifest.js" defer=""></script><script src="/_next/static/Llfq-lYryHX2DkunnEbsb/_middlewareManifest.js" defer=""></script></head><body><div id="__next" data-reactroot=""><div class="layout_ArticleContainer__QR4qB"><header><div class="layout_LayoutLinks__92rCe"><a href="/">‚Üê Back home</a></div></header><main><header><h1 class="utils_headingXl__u25Y2">All tags</h1><div class="utils_floatRight__n_EZh"><label><input type="checkbox" class="utils_marginRight5px__PM_rI"/>Show posts</label></div></header><section class="utils_headingMd__gD1Ok utils_marginLeft0_5rem__qnumX "><div class="utils_displayFlex__VCtvW"><a href="/tags/python"><div class="utils_marginTop2_25__bRt80 utils_marginBottom1_25__XjeT0"><span class="tag_Badge__e6qwu tag_BadgeLarge__O0ytt utils_cursorPointer__oXutf">python</span></div></a><span class="tag_TagLabel__AdflM">‚Ä¢ <small class="utils_lightText__eUzGY">4</small></span></div></section><section class="utils_headingMd__gD1Ok utils_marginLeft0_5rem__qnumX "><div class="utils_displayFlex__VCtvW"><a href="/tags/aws"><div class="utils_marginTop2_25__bRt80 utils_marginBottom1_25__XjeT0"><span class="tag_Badge__e6qwu tag_BadgeLarge__O0ytt utils_cursorPointer__oXutf">aws</span></div></a><span class="tag_TagLabel__AdflM">‚Ä¢ <small class="utils_lightText__eUzGY">1</small></span></div></section><section class="utils_headingMd__gD1Ok utils_marginLeft0_5rem__qnumX "><div class="utils_displayFlex__VCtvW"><a href="/tags/pandas"><div class="utils_marginTop2_25__bRt80 utils_marginBottom1_25__XjeT0"><span class="tag_Badge__e6qwu tag_BadgeLarge__O0ytt utils_cursorPointer__oXutf">pandas</span></div></a><span class="tag_TagLabel__AdflM">‚Ä¢ <small class="utils_lightText__eUzGY">2</small></span></div></section><section class="utils_headingMd__gD1Ok utils_marginLeft0_5rem__qnumX "><div class="utils_displayFlex__VCtvW"><a href="/tags/data-analysis"><div class="utils_marginTop2_25__bRt80 utils_marginBottom1_25__XjeT0"><span class="tag_Badge__e6qwu tag_BadgeLarge__O0ytt utils_cursorPointer__oXutf">data-analysis</span></div></a><span class="tag_TagLabel__AdflM">‚Ä¢ <small class="utils_lightText__eUzGY">2</small></span></div></section><section class="utils_headingMd__gD1Ok utils_marginLeft0_5rem__qnumX "><div class="utils_displayFlex__VCtvW"><a href="/tags/nextjs"><div class="utils_marginTop2_25__bRt80 utils_marginBottom1_25__XjeT0"><span class="tag_Badge__e6qwu tag_BadgeLarge__O0ytt utils_cursorPointer__oXutf">nextjs</span></div></a><span class="tag_TagLabel__AdflM">‚Ä¢ <small class="utils_lightText__eUzGY">1</small></span></div></section><section class="utils_headingMd__gD1Ok utils_marginLeft0_5rem__qnumX "><div class="utils_displayFlex__VCtvW"><a href="/tags/react"><div class="utils_marginTop2_25__bRt80 utils_marginBottom1_25__XjeT0"><span class="tag_Badge__e6qwu tag_BadgeLarge__O0ytt utils_cursorPointer__oXutf">react</span></div></a><span class="tag_TagLabel__AdflM">‚Ä¢ <small class="utils_lightText__eUzGY">1</small></span></div></section><section class="utils_headingMd__gD1Ok utils_marginLeft0_5rem__qnumX "><div class="utils_displayFlex__VCtvW"><a href="/tags/javascript"><div class="utils_marginTop2_25__bRt80 utils_marginBottom1_25__XjeT0"><span class="tag_Badge__e6qwu tag_BadgeLarge__O0ytt utils_cursorPointer__oXutf">javascript</span></div></a><span class="tag_TagLabel__AdflM">‚Ä¢ <small class="utils_lightText__eUzGY">1</small></span></div></section><section class="utils_headingMd__gD1Ok utils_marginLeft0_5rem__qnumX "><div class="utils_displayFlex__VCtvW"><a href="/tags/slack"><div class="utils_marginTop2_25__bRt80 utils_marginBottom1_25__XjeT0"><span class="tag_Badge__e6qwu tag_BadgeLarge__O0ytt utils_cursorPointer__oXutf">slack</span></div></a><span class="tag_TagLabel__AdflM">‚Ä¢ <small class="utils_lightText__eUzGY">1</small></span></div></section><section class="utils_headingMd__gD1Ok utils_marginLeft0_5rem__qnumX "><div class="utils_displayFlex__VCtvW"><a href="/tags/webhook"><div class="utils_marginTop2_25__bRt80 utils_marginBottom1_25__XjeT0"><span class="tag_Badge__e6qwu tag_BadgeLarge__O0ytt utils_cursorPointer__oXutf">webhook</span></div></a><span class="tag_TagLabel__AdflM">‚Ä¢ <small class="utils_lightText__eUzGY">1</small></span></div></section><section class="utils_headingMd__gD1Ok utils_marginLeft0_5rem__qnumX "><div class="utils_displayFlex__VCtvW"><a href="/tags/api"><div class="utils_marginTop2_25__bRt80 utils_marginBottom1_25__XjeT0"><span class="tag_Badge__e6qwu tag_BadgeLarge__O0ytt utils_cursorPointer__oXutf">api</span></div></a><span class="tag_TagLabel__AdflM">‚Ä¢ <small class="utils_lightText__eUzGY">1</small></span></div></section><section class="utils_headingMd__gD1Ok utils_marginLeft0_5rem__qnumX "><div class="utils_displayFlex__VCtvW"><a href="/tags/networkx"><div class="utils_marginTop2_25__bRt80 utils_marginBottom1_25__XjeT0"><span class="tag_Badge__e6qwu tag_BadgeLarge__O0ytt utils_cursorPointer__oXutf">networkx</span></div></a><span class="tag_TagLabel__AdflM">‚Ä¢ <small class="utils_lightText__eUzGY">1</small></span></div></section></main></div><footer class="footer_FooterContainer__oKXDJ"><div class="footer_Footer__wsKMY"><div class="footer_LeftFooterWrapper__ml0HU"><span class="footer_SocialLinkWrapper__0F2i_"><a href="https://www.linkedin.com/in/bradley-schoeneweis/" target="_blank" rel="noreferrer"><img width="16" src="/icons/linkedin.svg" alt="linkedin logo" class="footer_SocialLinkLogo__OWB_i"/></a><a href="https://github.com/bschoeneweis" target="_blank" rel="noreferrer"><img width="16" src="/icons/github.svg" alt="github logo" class="footer_SocialLinkLogo__OWB_i"/></a><a href="https://medium.com/@bradley-schoeneweis" target="_blank" rel="noreferrer"><img width="16" src="/icons/medium.svg" alt="medium logo" class="footer_SocialLinkLogo__OWB_i"/></a><a href="https://dev.to/bschoeneweis" target="_blank" rel="noreferrer"><img width="16" src="/icons/dev.svg" alt="dev logo" class="footer_SocialLinkLogo__OWB_i"/></a><a href="/feed.xml"><img width="16" src="/icons/rss.svg" alt="rss logo" class="footer_SocialLinkLogo__OWB_i"/></a></span></div><div class="footer_SiteLinks__nUPbv"><a href="/books">üìö</a><a href="/tools">üõ†</a></div></div><div class="footer_CopyrightWrapper__NZEPb"><small>¬© <time>2022</time> Bradley Schoeneweis</small></div></footer></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"tagsWithPosts":{"python":[{"id":"converting-html-to-pdf","contentHtml":"\u003ch2\u003etl;dr\u003c/h2\u003e\n\u003ch3\u003eGoal\u003c/h3\u003e\n\u003cp\u003e\u003cem\u003eTo set up an easy to call HTML to PDF converter as an AWS Lambda function.\u003c/em\u003e\u003c/p\u003e\n\u003ch3\u003eProcess Overview\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eDownloading the \u003ccode\u003ewkhtmltopdf\u003c/code\u003e binary\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eCreating the AWS Lambda layer(s) and configuring our function\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eWriting the AWS Lambda function\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eWe will use Python's \u003ca href=\"https://docs.python.org/3/library/subprocess.html\"\u003e\u003ccode\u003esubprocess\u003c/code\u003e module\u003c/a\u003e to call the \u003ccode\u003ewkhtmltopdf\u003c/code\u003e command\u003c/li\u003e\n\u003cli\u003eFor more in-depth Python focused usage, also check out \u003ca href=\"https://pypi.org/project/pdfkit/\"\u003epdfkit\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3\u003ePrerequisites\u003c/h3\u003e\n\u003cp\u003eThis article assumes access to an AWS account (free-tier is acceptable) and basic knowledge of AWS Lambda/S3 and Python.\u003c/p\u003e\n\u003ch3\u003eFunctional Requirements\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003eAllow passing either an S3 file key or an HTML string\u003c/li\u003e\n\u003cli\u003eReturn a file key for the generated PDF\u003c/li\u003e\n\u003cli\u003eAccept a small set of options for the \u003ccode\u003ewkhtmltopdf\u003c/code\u003e command\n\u003cul\u003e\n\u003cli\u003eA full man page can be found \u003ca href=\"https://wkhtmltopdf.org/usage/wkhtmltopdf.txt\"\u003ehere\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003eMost of the ones we'd want anyways are the default (i.e. \u003ccode\u003e--images\u003c/code\u003e, \u003ccode\u003e--enable-external-links\u003c/code\u003e, etc.)\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eFunctionality for the following options\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003e--orientation \u0026#x3C;orientation\u003e\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003e--title \u0026#x3C;text\u003e\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003e--margin-bottom \u0026#x3C;unitreal\u003e\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003e--margin-left \u0026#x3C;unitreal\u003e\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003e--margin-right \u0026#x3C;unitreal\u003e\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003e--margin-top \u0026#x3C;unitreal\u003e\u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003eAssumptions\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003eThe HTML string or file will be valid and will include the necessary tags (\u003ccode\u003e\u0026#x3C;!DOCTYPE html\u003e\u003c/code\u003e, \u003ccode\u003e\u0026#x3C;html\u003e\u003c/code\u003e, \u003ccode\u003e\u0026#x3C;head\u003e\u003c/code\u003e, \u003ccode\u003e\u0026#x3C;body\u003e\u003c/code\u003e). \u003cstrong\u003eIt is very important that you check validity of this HTML prior to calling this function if you ever use something similar in production. It may be best to only accept S3 file keys instead of HTML strings, but this is simply to show our functions possibilities or be used as an internal tool.\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003eThe event payload will contain all valid values (S3 bucket name, file key, \u003ccode\u003ewkhtmltopdf\u003c/code\u003e options etc.)\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3\u003eNotes\u003c/h3\u003e\n\u003cp\u003eThis article will use \u003ccode\u003eus-east-2\u003c/code\u003e for the AWS region, changing this shouldn't effect functionality, just the links within the article.\u003c/p\u003e\n\u003cp\u003eA better way to do this is through \u003ca href=\"https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/what-is-sam.html\"\u003eAWS Serverless Application Model (SAM)\u003c/a\u003e, but this is more tailored for those looking for the basic setup through the AWS Management Console.\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003eA common task I've found myself undertaking recently is programmatically converting an HTML file/string to an embedded and stylized PDF file.\u003c/p\u003e\n\u003cp\u003eAn example use case for this might be exporting a self-managed customer invoice or generating a daily report from an existing HTML template. For those who have used template languages before, you can probably imagine the usefulness of a function like this in combination with \u003ca href=\"https://jinja.palletsprojects.com/en/2.11.x/\"\u003eJinja\u003c/a\u003e or template rendering engines commonly found in Web Frameworks (like \u003ca href=\"https://www.djangoproject.com/\"\u003eDjango\u003c/a\u003e).\u003c/p\u003e\n\u003cp\u003eAfter doing some research on third party libraries that could simplify our goal, I decided to use \u003ca href=\"https://wkhtmltopdf.org/\"\u003e\u003ccode\u003ewkhtmltopdf\u003c/code\u003e\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003ewkhtmltopdf\u003c/code\u003e is an open-source command line tool that enables you to easy convert an HTML file to a PDF file. This is exactly what we're looking for. We will call the \u003ccode\u003ewkhtmltopdf\u003c/code\u003e command using the \u003ca href=\"https://docs.python.org/3/library/subprocess.html\"\u003e\u003ccode\u003esubprocess\u003c/code\u003e\u003c/a\u003e Python library. For more in-depth Python usage, you can check out \u003ca href=\"https://pypi.org/project/pdfkit/\"\u003epdfkit\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eLet's dive into it.\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003eWhy AWS Lambda?\u003c/h2\u003e\n\u003cp\u003e\u003ca href=\"https://aws.amazon.com/lambda/\"\u003eAWS Lambda\u003c/a\u003e provides serverless computing functions where you don't need to manage any servers or containers, you can simply call your function synchronously or asynchronously, and it will be executed and scaled automatically.\u003c/p\u003e\n\u003cp\u003eLambda has a ton of use cases and is something I have personally used many times and am a big fan of.\u003c/p\u003e\n\u003cp\u003e\u003cem\u003eFor our goal, AWS Lambda is a powerful tool for the following reasons\u003c/em\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eIt allows us to offload processing away from the server\n\u003cul\u003e\n\u003cli\u003eThis is more of a general benefit, we won't actually be calling this function from a running server\u003c/li\u003e\n\u003cli\u003eThese calls will also be scaled automatically\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eOur dependencies, specifically the \u003ccode\u003ewkhtmltopdf\u003c/code\u003e binary, can be handled well through \u003ca href=\"https://docs.aws.amazon.com/lambda/latest/dg/configuration-layers.html\"\u003eAWS Lambda layers\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003eThis helps to avoid dealing with different Linux distributions or multiple installation locations\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eBelow is an explanation of why handling the dependencies through layers will avoid issues. For continued instruction, you can skip to the next section.\u003c/strong\u003e\u003c/p\u003e\n\u003ch3\u003eIssues with downloading the binary\u003c/h3\u003e\n\u003cp\u003eWhen I was first using this library, I was also using \u003ca href=\"https://pypi.org/project/pdfkit/\"\u003e\u003ccode\u003epdfkit\u003c/code\u003e\u003c/a\u003e to drive this interaction.  At the top of the installation instructions, you can see the following warning:\u003c/p\u003e\n\u003cp\u003eWhen I first installed \u003ccode\u003ewkhtmltopdf\u003c/code\u003e, I didn't heed the warning and just ran the following:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003esudo apt-get install wkhtmltopdf\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eOn initial inspection, I wasn't experiencing the problems they mentioned (\u003cem\u003eat least in my local environment\u003c/em\u003e). The issues came when I actually pushed up code using this library to a staging environment and I noticed the PDFs were no longer generating.\u003c/p\u003e\n\u003cp\u003eI was able to remedy this by installing in an alternative way:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003esudo apt-get remove --purge wkhtmltopdf\nwget https://github.com/wkhtmltopdf/packaging/releases/download/0.12.6-1/wkhtmltox_0.12.6-1.bionic_amd64.deb\nsudo dpkg -i wkhtmltox_0.12.6-1.bionic_amd64.deb\nrm wkhtmltox_0.12.6-1.bionic_amd64.deb\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThis isn't a big deal, but managing this dependency could get tedious if your architecture has multiple servers that need installed with different Linux distributions.\u003c/p\u003e\n\u003cp\u003ePutting this binary into an AWS Lambda Layer can help solve this by having a single point of installation and management.\u003c/p\u003e\n\u003ch2\u003eDownloading the \u003ccode\u003ewkhtmltopdf\u003c/code\u003e binary\u003c/h2\u003e\n\u003cp\u003eThe \u003ccode\u003ewkhtmltopdf\u003c/code\u003e site actually lists using this library with AWS Lambda as a \u003ca href=\"https://wkhtmltopdf.org/downloads.html#how-do-i-use-it-in-aws-lambda\"\u003eFAQ\u003c/a\u003e and gives the following response to this question:\u003c/p\u003e\n\u003cp\u003e\u003cem\u003e\"All files required for lambda layer are packed in one zip archive (Amazon Linux 2 / lambda zip)\"\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003eYou can download the binary on the releases page under the \u003ca href=\"https://wkhtmltopdf.org/downloads.html#stable\"\u003eStable releases\u003c/a\u003e. You'll see an entry under \u003ccode\u003eAmazon Linux\u003c/code\u003e with \u003ccode\u003elambda zip\u003c/code\u003e as the architecture.\u003c/p\u003e\n\u003cp\u003eOr, you can click \u003ca href=\"https://github.com/wkhtmltopdf/packaging/releases/download/0.12.6-4/wkhtmltox-0.12.6-4.amazonlinux2_lambda.zip\"\u003ehere\u003c/a\u003e (I likely won't update this link, so probably best to go directly to the release page).\u003c/p\u003e\n\u003cp\u003e\u003cem\u003eRandom note:\u003c/em\u003e If you need more fonts for future usage, I've found that \u003ca href=\"https://github.com/brandonlim-hs/fonts-aws-lambda-layer\"\u003ethis is a good resource\u003c/a\u003e. You may need to include one of these fonts as a layer in your lambda function (via ARN) if your function has issues in the beginning.\u003c/p\u003e\n\u003ch2\u003eCreating the AWS Lambda layers\u003c/h2\u003e\n\u003cp\u003e\u003ca href=\"https://docs.aws.amazon.com/lambda/latest/dg/configuration-layers.html\"\u003eAWS Lambda layers\u003c/a\u003e allow us to add in \"layers\" of dependencies for our functions. An alternative to this is uploading your lambda function as a deployment package or using AWS SAM (Serverless Application Model), but that is out of the scope of this post.\u003c/p\u003e\n\u003ch3\u003e\u003ccode\u003ewkhtmltopdf\u003c/code\u003e\u003c/h3\u003e\n\u003cp\u003eNow that we have the zip file downloaded, let's add our file as a layer in the \u003ca href=\"https://us-east-2.console.aws.amazon.com/console/home?region=us-east-2\"\u003eAWS Management Console\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eGo to the \u003ca href=\"https://us-east-2.console.aws.amazon.com/lambda/home?region=us-east-2#/layers\"\u003eLayers section\u003c/a\u003e on the AWS Lambda page and click \u003ccode\u003eCreate layer\u003c/code\u003e.\u003c/p\u003e\n\u003cp\u003eThen, add the following Layer configuration.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/converting-html-to-pdf/layer-configuration.jpg\" alt=\"AWS Lambda layer configuration {priority}{680x488}\"\u003e\u003c/p\u003e\n\u003cp\u003eNotice that we don't add a runtime here, this is intentional since our layer is a binary.\u003c/p\u003e\n\u003cp\u003eClick Create and take note of your new layer's Version ARN as we are about to use it to add to our function.\u003c/p\u003e\n\u003cp\u003eNow we're set up to create our function!\u003c/p\u003e\n\u003ch2\u003eWriting the AWS Lambda function\u003c/h2\u003e\n\u003cp\u003eNavigate to the \u003ca href=\"https://us-east-2.console.aws.amazon.com/lambda/home?region=us-east-2#/functions\"\u003eFunctions page\u003c/a\u003e within the AWS Lambda service and click \u003ccode\u003eCreate function\u003c/code\u003e.\u003c/p\u003e\n\u003cp\u003eSelect \u003ccode\u003eAuthor from scratch\u003c/code\u003e, and add the following configuration.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/converting-html-to-pdf/function-configuration.jpg\" alt=\"AWS Lambda function configuration {1004x475}\"\u003e\u003c/p\u003e\n\u003cp\u003eYou can ignore the \u003ccode\u003eAdvanced settings\u003c/code\u003e for our use case.\u003c/p\u003e\n\u003cp\u003eOnce the function is created, we have just a few configuration additions to make.\u003c/p\u003e\n\u003ch3\u003eAdding the layer to our Lambda function\u003c/h3\u003e\n\u003cp\u003eNow that our function is created, the first thing we want to do is add our \u003ccode\u003ewkhtmltopdf\u003c/code\u003e layer.\u003c/p\u003e\n\u003cp\u003eAt the top of the Function Overview panel, click the \u003ccode\u003eLayers\u003c/code\u003e button right below your function name. This will bring you down to the layers section. Now click Add a layer.\u003c/p\u003e\n\u003cp\u003eClick on \u003ccode\u003eSpecify an ARN\u003c/code\u003e and copy your Layer Version ARN from earlier.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/converting-html-to-pdf/add-layer.jpg\" alt=\"AWS Lambda add layer {680x316}\"\u003e\u003c/p\u003e\n\u003cp\u003eThe reason why we need to specify our layer by ARN is because we didn't define a runtime above.\u003c/p\u003e\n\u003ch3\u003eAdd permission to access your S3 bucket\u003c/h3\u003e\n\u003cp\u003eOne final function configuration that we need to add is permission for our function to access Amazon S3.  To do this, navigate to the Configuration tab below your Function Overview.\u003c/p\u003e\n\u003cp\u003eUnder Configuration, go to the Permissions section. Here, you will see your generated Execution Role. Click this link to go to the IAM Console.\u003c/p\u003e\n\u003cp\u003eFrom here, click Attach policies, and add the \u003cstrong\u003eAmazonS3FullAccess\u003c/strong\u003e policy like so\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/converting-html-to-pdf/iam-policy.jpg\" alt=\"AWS Lambda IAM policy {1004x461}\"\u003e\u003c/p\u003e\n\u003cp\u003eNow that our function is configured, we can dive into the actual requirements and code!\u003c/p\u003e\n\u003ch3\u003eRequirements\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003eAllow passing either an S3 file key or an HTML string\u003c/li\u003e\n\u003cli\u003eReturn a file key for the generated PDF\u003c/li\u003e\n\u003cli\u003eAccept a small set of options for the \u003ccode\u003ewkhtmltopdf\u003c/code\u003e command\n\u003cul\u003e\n\u003cli\u003eA full man page can be found \u003ca href=\"https://wkhtmltopdf.org/usage/wkhtmltopdf.txt\"\u003ehere\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003eMost of the ones we'd want anyways are the default (i.e. \u003ccode\u003e--images\u003c/code\u003e, \u003ccode\u003e--enable-external-links\u003c/code\u003e, etc.)\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eLet's allow the user to pass the following options\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003e--orientation \u0026#x3C;orientation\u003e\u003c/code\u003e - the common page orientation for the PDF file.\n\u003cul\u003e\n\u003cli\u003eValid values are \u003ccode\u003eLandscape\u003c/code\u003e or \u003ccode\u003ePortrait\u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003e--title \u0026#x3C;text\u003e\u003c/code\u003e - the title of the generated file.\u003c/li\u003e\n\u003cli\u003eThe margins of the file\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003e--margin-bottom \u0026#x3C;unitreal\u003e\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003e--margin-left \u0026#x3C;unitreal\u003e\u003c/code\u003e (default is 10mm)\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003e--margin-right \u0026#x3C;unitreal\u003e\u003c/code\u003e  (default is 10mm)\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003e--margin-top \u0026#x3C;unitreal\u003e\u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003eAssumptions\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003eThe HTML string or file will be valid and will include the necessary tags (\u003ccode\u003e\u0026#x3C;!DOCTYPE html\u003e\u003c/code\u003e, \u003ccode\u003e\u0026#x3C;html\u003e\u003c/code\u003e, \u003ccode\u003e\u0026#x3C;head\u003e\u003c/code\u003e, \u003ccode\u003e\u0026#x3C;body\u003e\u003c/code\u003e)\u003c/li\u003e\n\u003cli\u003eThe event payload will contain all valid values (S3 bucket name, file key, \u003ccode\u003ewkhtmltopdf\u003c/code\u003e options etc.)\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3\u003eThe function code\u003c/h3\u003e\n\u003cp\u003eBy default, you will see the following handler.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003edef lambda_handler(event, context):\n    # TODO implement\n    return {\n        'statusCode': 200,\n        'body': json.dumps('Hello from Lambda!')\n    }\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThis is the code that will be executed when your function is called. We'll come back to this in a bit.\u003c/p\u003e\n\u003ch4\u003eThe imports\u003c/h4\u003e\n\u003cp\u003eFirst, let's go ahead and import all of the Python libraries that we'll need and set up some basic tools like the \u003ccode\u003eS3 client\u003c/code\u003e and our \u003ccode\u003elogger\u003c/code\u003e.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003efrom datetime import datetime\nimport json\nimport logging\nimport os\nimport subprocess\nfrom typing import Optional\n\nimport boto3\nfrom botocore.exceptions import ClientError\n\n\n# Set up logging\nlogger = logging.getLogger()\nlogger.setLevel(logging.INFO)\n\n# Get the s3 client\ns3 = boto3.client('s3')\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eNow based upon our requirements, we'll need helper functions to\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eDownload an HTML file from S3\u003c/li\u003e\n\u003cli\u003eUpload a file to S3\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eLet's start with those, and then we'll return to our lambda handler.\u003c/p\u003e\n\u003ch4\u003eDownloading/uploading the file\u003c/h4\u003e\n\u003cp\u003e\u003ca href=\"https://boto3.amazonaws.com/v1/documentation/api/latest/index.html\"\u003e\u003ccode\u003eboto3\u003c/code\u003e\u003c/a\u003e makes it really easy to interact with S3.  Using \u003ccode\u003eboto3\u003c/code\u003e, we can add the following helper functions.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003edef download_s3_file(bucket: str, file_key: str) -\u003e str:\n    \"\"\"Downloads a file from s3 to `/tmp/[File Key]`.\n    \n    Args:\n        bucket (str): Name of the bucket where the file lives.\n        file_key (str): The file key of the file in the bucket.\n\n    Returns:\n        The local file name as a string.\n    \"\"\"\n    local_filename = f'/tmp/{file_key}'\n    s3.download_file(Bucket=bucket, Key=file_key, Filename=local_filename)\n    logger.info('Downloaded HTML file to %s' % local_filename)\n\n    return local_filename\n    \n    \ndef upload_file_to_s3(bucket: str, filename: str) -\u003e Optional[str]:\n    \"\"\"Uploads the generated PDF to s3.\n    \n    Args:\n        bucket (str): Name of the s3 bucket to upload the PDF to.\n        filename (str): Location of the file to upload to s3.\n        \n    Returns:\n        The file key of the file in s3 if the upload was successful.\n        If the upload failed, then `None` will be returned.\n    \"\"\"\n    file_key = None\n    try:\n        file_key = filename.replace('/tmp/', '')\n        s3.upload_file(Filename=filename, Bucket=bucket, Key=file_key)\n        logger.info('Successfully uploaded the PDF to %s as %s'\n                    % (bucket, file_key))\n    except ClientError as e:\n        logger.error('Failed to upload file to s3.')\n        logger.error(e)\n        file_key = None\n        \n    return file_key\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch4\u003eParsing the event\u003c/h4\u003e\n\u003cp\u003eOne thing we haven't talked about yet is the data that we'll need to pass our function.\u003c/p\u003e\n\u003cp\u003eLet's define our JSON event schema as the following.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e{\n    \"bucket\": \"\u0026#x3C;Name of the bucket where the file is stored currently and will be stored after processing\u003e [Required]\",\n    \"file_key\": \"\u0026#x3C;File key where the file is store in S3\u003e [Required if `html_string` is not defined]\",\n    \"html_string\": \"\u0026#x3C;HTML string to convert to a PDF\u003e [Required if `file_key` is not defined]\",\n    \"wkhtmltopdf_options\": {\n        \"orientation\": \"\u0026#x3C;`landscape` or `portrait`\u003e [Optional: Default is `portrait`]\",\n        \"title\": \"\u0026#x3C;Title of the PDF\u003e [Optional]\",\n        \"margin\": \"\u0026#x3C;Margin of the PDF (same format as css [\u0026#x3C;top\u003e \u0026#x3C;right\u003e \u0026#x3C;bottom\u003e \u0026#x3C;left\u003e] (all must be included)).\u003e [Optional]\"\n    }\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003ccode\u003ewkhtmltopdf_options\u003c/code\u003e is an optional object. If the included options are not valid, they will not be included.\u003c/p\u003e\n\u003cp\u003eWe can access all of the data passed to our function from the \u003ccode\u003eevent\u003c/code\u003e parameter in the \u003ccode\u003elambda_handler\u003c/code\u003e function.\u003c/p\u003e\n\u003cp\u003eNow, let's jump back to the \u003ccode\u003elambda_handler\u003c/code\u003e function and add some code to pull out the data from our event and put together the remaining pieces of actually calling the \u003ccode\u003ewkhtmltopdf\u003c/code\u003e executable to finish our lambda function.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003edef lambda_handler(event, context):\n    logger.info(event)\n\n    # bucket is always required\n    try:\n        bucket = event['bucket']\n    except KeyError:\n        error_message = 'Missing required \"bucket\" parameter from request payload.'\n        logger.error(error_message)\n        return {\n            'status': 400,\n            'body': json.dumps(error_message),\n        }\n\n    # html_string and file_key are conditionally required, so let's try to get both\n    try:\n        file_key = event['file_key']\n    except KeyError:\n        file_key = None\n\n    try:\n        html_string = event['html_string']\n    except KeyError:\n        html_string = None\n\n    if file_key is None and html_string is None:\n        error_message = (\n            'Missing both a \"file_key\" and \"html_string\" '\n            'from request payload. One of these must be '\n            'included.'\n        )\n        logger.error(error_message)\n        return {\n            'status': 400,\n            'body': json.dumps(error_message),\n        }\n\n    # Now we can check for the option wkhtmltopdf_options and map them to values\n    # Again, part of our assumptions are that these are valid\n    wkhtmltopdf_options = {}\n    if 'wkhtmltopdf_options' in event:\n        # Margin is \u0026#x3C;top\u003e \u0026#x3C;right\u003e \u0026#x3C;bottom\u003e \u0026#x3C;left\u003e\n        if 'margin' in event['wkhtmltopdf_options']:\n            margins = event['wkhtmltopdf_options']['margin'].split(' ')\n            if len(margins) == 4:\n                wkhtmltopdf_options['margin-top'] = margins[0]\n                wkhtmltopdf_options['margin-right'] = margins[1]\n                wkhtmltopdf_options['margin-bottom'] = margins[2]\n                wkhtmltopdf_options['margin-left'] = margins[3]\n\n        if 'orientation' in event['wkhtmltopdf_options']:\n            wkhtmltopdf_options['orientation'] = 'portrait' \\\n                if event['wkhtmltopdf_options']['orientation'].lower() not in ['portrait', 'landscape'] \\\n                else event['wkhtmltopdf_options']['orientation'].lower()\n\n        if 'title' in event['wkhtmltopdf_options']:\n            wkhtmltopdf_options['title'] = event['wkhtmltopdf_options']['title']\n\n    # If we got a file_key in the request, let's download our file\n    # If not, we'll write the HTML string to a file\n    if file_key is not None:\n        local_filename = download_s3_file(bucket, file_key)\n    else:\n        timestamp = str(datetime.now()).replace('.', '').replace(' ', '_')\n        local_filename = f'/tmp/{timestamp}-html-string.html'\n\n        # Delete any existing files with that name\n        try:\n            os.unlink(local_filename)\n        except FileNotFoundError:\n            pass\n\n        with open(local_filename, 'w') as f:\n            f.write(html_string)\n\n    # Now we can create our command string to execute and upload the result to s3\n    command = 'wkhtmltopdf  --load-error-handling ignore'  # ignore unecessary errors\n    for key, value in wkhtmltopdf_options.items():\n        if key == 'title':\n            value = f'\"{value}\"'\n        command += ' --{0} {1}'.format(key, value)\n    command += ' {0} {1}'.format(local_filename, local_filename.replace('.html', '.pdf'))\n\n    # Important! Remember, we said that we are assuming we're accepting valid HTML\n    # this should always be checked to avoid allowing any string to be executed\n    # from this command. The reason we use shell=True here is because our title\n    # can be multiple words.\n    subprocess.run(command, shell=True)\n    logger.info('Successfully generated the PDF.')\n    file_key = upload_file_to_s3(bucket, local_filename.replace('.html', '.pdf'))\n\n    if file_key is None:\n        error_message = (\n            'Failed to generate PDF from the given HTML file.'\n            ' Please check to make sure the file is valid HTML.'\n        )\n        logger.error(error_message)\n        return {\n            'status': 400,\n            'body': json.dumps(error_message),\n        }\n\n    return {\n        'status': 200,\n        'file_key': file_key,\n    }\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eNow you can go to the \u003cstrong\u003eTest\u003c/strong\u003e tab and create the following test event (change your bucket name as necessary)\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e{\n    \"bucket\": \"bucket-for-articles\",\n    \"html_string\": \"\u0026#x3C;!DOCTYPE html\u003e\u0026#x3C;html\u003e\u0026#x3C;head\u003e\u0026#x3C;/head\u003e\u0026#x3C;body\u003eThis is an example of a simple HTML page.\u0026#x3C;/body\u003e\u0026#x3C;/html\u003e\",\n    \"wkhtmltopdf_options\": {\n        \"orientation\": \"portrait\",\n        \"title\": \"Test PDF Generation\",\n        \"margin\": \"10mm 10mm 10mm 10mm\"\n    }\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eYou should get a return event with a \u003ccode\u003estatus\u003c/code\u003e of \u003ccode\u003e200\u003c/code\u003e, and a \u003ccode\u003efile_key\u003c/code\u003e of your converted file, thus achieving our goal! üéâ\u003c/p\u003e\n\u003chr\u003e\n","markdown":"\n## tl;dr\n\n### Goal\n_To set up an easy to call HTML to PDF converter as an AWS Lambda function._\n\n### Process Overview\n1. **Downloading the `wkhtmltopdf` binary**\n2. **Creating the AWS Lambda layer(s) and configuring our function**\n3. **Writing the AWS Lambda function**\n    - We will use Python's [`subprocess` module](https://docs.python.org/3/library/subprocess.html) to call the `wkhtmltopdf` command\n    - For more in-depth Python focused usage, also check out [pdfkit](https://pypi.org/project/pdfkit/)\n\n### Prerequisites\nThis article assumes access to an AWS account (free-tier is acceptable) and basic knowledge of AWS Lambda/S3 and Python.\n\n### Functional Requirements\n\n1. Allow passing either an S3 file key or an HTML string\n2. Return a file key for the generated PDF\n3. Accept a small set of options for the `wkhtmltopdf` command\n    - A full man page can be found [here](https://wkhtmltopdf.org/usage/wkhtmltopdf.txt)\n    - Most of the ones we'd want anyways are the default (i.e. `--images`, `--enable-external-links`, etc.)\n\nFunctionality for the following options\n- `--orientation \u003corientation\u003e`\n- `--title \u003ctext\u003e`\n- `--margin-bottom \u003cunitreal\u003e`\n- `--margin-left \u003cunitreal\u003e`\n- `--margin-right \u003cunitreal\u003e`\n- `--margin-top \u003cunitreal\u003e`\n\n### Assumptions\n\n1. The HTML string or file will be valid and will include the necessary tags (`\u003c!DOCTYPE html\u003e`, `\u003chtml\u003e`, `\u003chead\u003e`, `\u003cbody\u003e`). **It is very important that you check validity of this HTML prior to calling this function if you ever use something similar in production. It may be best to only accept S3 file keys instead of HTML strings, but this is simply to show our functions possibilities or be used as an internal tool.**\n2. The event payload will contain all valid values (S3 bucket name, file key, `wkhtmltopdf` options etc.)\n\n### Notes\nThis article will use `us-east-2` for the AWS region, changing this shouldn't effect functionality, just the links within the article.\n\nA better way to do this is through [AWS Serverless Application Model (SAM)](https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/what-is-sam.html), but this is more tailored for those looking for the basic setup through the AWS Management Console.\n\n---\nA common task I've found myself undertaking recently is programmatically converting an HTML file/string to an embedded and stylized PDF file.\n\nAn example use case for this might be exporting a self-managed customer invoice or generating a daily report from an existing HTML template. For those who have used template languages before, you can probably imagine the usefulness of a function like this in combination with [Jinja](https://jinja.palletsprojects.com/en/2.11.x/) or template rendering engines commonly found in Web Frameworks (like [Django](https://www.djangoproject.com/)).\n\nAfter doing some research on third party libraries that could simplify our goal, I decided to use [`wkhtmltopdf`](https://wkhtmltopdf.org/).\n\n`wkhtmltopdf` is an open-source command line tool that enables you to easy convert an HTML file to a PDF file. This is exactly what we're looking for. We will call the `wkhtmltopdf` command using the [`subprocess`](https://docs.python.org/3/library/subprocess.html) Python library. For more in-depth Python usage, you can check out [pdfkit](https://pypi.org/project/pdfkit/).\n\nLet's dive into it.\n\n---\n\n## Why AWS Lambda?\n[AWS Lambda](https://aws.amazon.com/lambda/) provides serverless computing functions where you don't need to manage any servers or containers, you can simply call your function synchronously or asynchronously, and it will be executed and scaled automatically.\n\nLambda has a ton of use cases and is something I have personally used many times and am a big fan of.\n\n_For our goal, AWS Lambda is a powerful tool for the following reasons_\n- It allows us to offload processing away from the server\n    - This is more of a general benefit, we won't actually be calling this function from a running server\n    - These calls will also be scaled automatically\n- Our dependencies, specifically the `wkhtmltopdf` binary, can be handled well through [AWS Lambda layers](https://docs.aws.amazon.com/lambda/latest/dg/configuration-layers.html)\n    - This helps to avoid dealing with different Linux distributions or multiple installation locations\n\n**Below is an explanation of why handling the dependencies through layers will avoid issues. For continued instruction, you can skip to the next section.**\n\n### Issues with downloading the binary\nWhen I was first using this library, I was also using [`pdfkit`](https://pypi.org/project/pdfkit/) to drive this interaction.  At the top of the installation instructions, you can see the following warning:\n\n\u003cp style=\"background-color: orange; padding: 7px 20px; text-align: center; border-radius: 6px;\"\u003e\n\u003ci\u003e\"\u003cb\u003eWarning!\u003c/b\u003e\u0026nbsp;Version in debian/ubuntu repos have reduced functionality (because it compiled without the wkhtmltopdf QT patches), such as adding outlines, headers, footers, TOC etc. To use this options you should install static binary from wkhtmltopdf site\"\u003c/i\u003e\n\u003c/p\u003e\n\nWhen I first installed `wkhtmltopdf`, I didn't heed the warning and just ran the following:\n```bash\nsudo apt-get install wkhtmltopdf\n```\n\nOn initial inspection, I wasn't experiencing the problems they mentioned (_at least in my local environment_). The issues came when I actually pushed up code using this library to a staging environment and I noticed the PDFs were no longer generating.\n\nI was able to remedy this by installing in an alternative way:\n```bash\nsudo apt-get remove --purge wkhtmltopdf\nwget https://github.com/wkhtmltopdf/packaging/releases/download/0.12.6-1/wkhtmltox_0.12.6-1.bionic_amd64.deb\nsudo dpkg -i wkhtmltox_0.12.6-1.bionic_amd64.deb\nrm wkhtmltox_0.12.6-1.bionic_amd64.deb\n```\n\nThis isn't a big deal, but managing this dependency could get tedious if your architecture has multiple servers that need installed with different Linux distributions.\n\nPutting this binary into an AWS Lambda Layer can help solve this by having a single point of installation and management.\n\n## Downloading the `wkhtmltopdf` binary\nThe `wkhtmltopdf` site actually lists using this library with AWS Lambda as a [FAQ](https://wkhtmltopdf.org/downloads.html#how-do-i-use-it-in-aws-lambda) and gives the following response to this question:\n\n_\"All files required for lambda layer are packed in one zip archive (Amazon Linux 2 / lambda zip)\"_\n\nYou can download the binary on the releases page under the [Stable releases](https://wkhtmltopdf.org/downloads.html#stable). You'll see an entry under `Amazon Linux` with `lambda zip` as the architecture.\n\nOr, you can click [here](https://github.com/wkhtmltopdf/packaging/releases/download/0.12.6-4/wkhtmltox-0.12.6-4.amazonlinux2_lambda.zip) (I likely won't update this link, so probably best to go directly to the release page).\n\n_Random note:_ If you need more fonts for future usage, I've found that [this is a good resource](https://github.com/brandonlim-hs/fonts-aws-lambda-layer). You may need to include one of these fonts as a layer in your lambda function (via ARN) if your function has issues in the beginning.\n\n## Creating the AWS Lambda layers\n\n[AWS Lambda layers](https://docs.aws.amazon.com/lambda/latest/dg/configuration-layers.html) allow us to add in \"layers\" of dependencies for our functions. An alternative to this is uploading your lambda function as a deployment package or using AWS SAM (Serverless Application Model), but that is out of the scope of this post.\n\n### `wkhtmltopdf`\nNow that we have the zip file downloaded, let's add our file as a layer in the [AWS Management Console](https://us-east-2.console.aws.amazon.com/console/home?region=us-east-2).\n\nGo to the [Layers section](https://us-east-2.console.aws.amazon.com/lambda/home?region=us-east-2#/layers) on the AWS Lambda page and click `Create layer`.\n\nThen, add the following Layer configuration.\n\n![AWS Lambda layer configuration {priority}{680x488}](/images/converting-html-to-pdf/layer-configuration.jpg)\n\nNotice that we don't add a runtime here, this is intentional since our layer is a binary.\n\nClick Create and take note of your new layer's Version ARN as we are about to use it to add to our function.\n\nNow we're set up to create our function!\n\n\n## Writing the AWS Lambda function\nNavigate to the [Functions page](https://us-east-2.console.aws.amazon.com/lambda/home?region=us-east-2#/functions) within the AWS Lambda service and click `Create function`.\n\nSelect `Author from scratch`, and add the following configuration.\n\n![AWS Lambda function configuration {1004x475}](/images/converting-html-to-pdf/function-configuration.jpg)\n\nYou can ignore the `Advanced settings` for our use case.\n\nOnce the function is created, we have just a few configuration additions to make.\n\n### Adding the layer to our Lambda function\n\nNow that our function is created, the first thing we want to do is add our `wkhtmltopdf` layer.\n\nAt the top of the Function Overview panel, click the `Layers` button right below your function name. This will bring you down to the layers section. Now click Add a layer.\n\nClick on `Specify an ARN` and copy your Layer Version ARN from earlier.\n\n![AWS Lambda add layer {680x316}](/images/converting-html-to-pdf/add-layer.jpg)\n\nThe reason why we need to specify our layer by ARN is because we didn't define a runtime above.\n\n\u003cp style=\"background-color: #9bc2cf; padding: 7px 20px; text-align: center; border-radius: 6px;\"\u003e\n\u003cb\u003eImportant!\u003c/b\u003e If your function generates a PDF with a bunch of black squares, this is likely because there is no font configuration within Lambda. To solve this, you can go to [this link](https://github.com/brandonlim-hs/fonts-aws-lambda-layer\") that I mentioned earlier, and copy one of the AWS Linux Fonts ARNs for your region (or build from scratch), add the environment variable in the README, and repeat these steps to add a font layer.\n\u003c/p\u003e\n\n### Add permission to access your S3 bucket\n\nOne final function configuration that we need to add is permission for our function to access Amazon S3.  To do this, navigate to the Configuration tab below your Function Overview.\n\nUnder Configuration, go to the Permissions section. Here, you will see your generated Execution Role. Click this link to go to the IAM Console.\n\nFrom here, click Attach policies, and add the **AmazonS3FullAccess** policy like so\n\n![AWS Lambda IAM policy {1004x461}](/images/converting-html-to-pdf/iam-policy.jpg)\n\nNow that our function is configured, we can dive into the actual requirements and code!\n\n### Requirements\n\n1. Allow passing either an S3 file key or an HTML string\n2. Return a file key for the generated PDF\n3. Accept a small set of options for the `wkhtmltopdf` command\n    - A full man page can be found [here](https://wkhtmltopdf.org/usage/wkhtmltopdf.txt)\n    - Most of the ones we'd want anyways are the default (i.e. `--images`, `--enable-external-links`, etc.)\n\nLet's allow the user to pass the following options\n- `--orientation \u003corientation\u003e` - the common page orientation for the PDF file.\n    - Valid values are `Landscape` or `Portrait`\n- `--title \u003ctext\u003e` - the title of the generated file.\n- The margins of the file\n    - `--margin-bottom \u003cunitreal\u003e`\n    - `--margin-left \u003cunitreal\u003e` (default is 10mm)\n    - `--margin-right \u003cunitreal\u003e`  (default is 10mm)\n    - `--margin-top \u003cunitreal\u003e`\n\n### Assumptions\n\n1. The HTML string or file will be valid and will include the necessary tags (`\u003c!DOCTYPE html\u003e`, `\u003chtml\u003e`, `\u003chead\u003e`, `\u003cbody\u003e`)\n2. The event payload will contain all valid values (S3 bucket name, file key, `wkhtmltopdf` options etc.)\n\n### The function code\nBy default, you will see the following handler.\n```python\ndef lambda_handler(event, context):\n    # TODO implement\n    return {\n        'statusCode': 200,\n        'body': json.dumps('Hello from Lambda!')\n    }\n```\nThis is the code that will be executed when your function is called. We'll come back to this in a bit.\n\n#### The imports\nFirst, let's go ahead and import all of the Python libraries that we'll need and set up some basic tools like the `S3 client` and our `logger`.\n```python\nfrom datetime import datetime\nimport json\nimport logging\nimport os\nimport subprocess\nfrom typing import Optional\n\nimport boto3\nfrom botocore.exceptions import ClientError\n\n\n# Set up logging\nlogger = logging.getLogger()\nlogger.setLevel(logging.INFO)\n\n# Get the s3 client\ns3 = boto3.client('s3')\n```\n\nNow based upon our requirements, we'll need helper functions to\n1. Download an HTML file from S3\n2. Upload a file to S3\n\nLet's start with those, and then we'll return to our lambda handler.\n\n#### Downloading/uploading the file\n[`boto3`](https://boto3.amazonaws.com/v1/documentation/api/latest/index.html) makes it really easy to interact with S3.  Using `boto3`, we can add the following helper functions.\n\n```python\ndef download_s3_file(bucket: str, file_key: str) -\u003e str:\n    \"\"\"Downloads a file from s3 to `/tmp/[File Key]`.\n    \n    Args:\n        bucket (str): Name of the bucket where the file lives.\n        file_key (str): The file key of the file in the bucket.\n\n    Returns:\n        The local file name as a string.\n    \"\"\"\n    local_filename = f'/tmp/{file_key}'\n    s3.download_file(Bucket=bucket, Key=file_key, Filename=local_filename)\n    logger.info('Downloaded HTML file to %s' % local_filename)\n\n    return local_filename\n    \n    \ndef upload_file_to_s3(bucket: str, filename: str) -\u003e Optional[str]:\n    \"\"\"Uploads the generated PDF to s3.\n    \n    Args:\n        bucket (str): Name of the s3 bucket to upload the PDF to.\n        filename (str): Location of the file to upload to s3.\n        \n    Returns:\n        The file key of the file in s3 if the upload was successful.\n        If the upload failed, then `None` will be returned.\n    \"\"\"\n    file_key = None\n    try:\n        file_key = filename.replace('/tmp/', '')\n        s3.upload_file(Filename=filename, Bucket=bucket, Key=file_key)\n        logger.info('Successfully uploaded the PDF to %s as %s'\n                    % (bucket, file_key))\n    except ClientError as e:\n        logger.error('Failed to upload file to s3.')\n        logger.error(e)\n        file_key = None\n        \n    return file_key\n```\n\n#### Parsing the event\nOne thing we haven't talked about yet is the data that we'll need to pass our function.\n\nLet's define our JSON event schema as the following.\n```json\n{\n    \"bucket\": \"\u003cName of the bucket where the file is stored currently and will be stored after processing\u003e [Required]\",\n    \"file_key\": \"\u003cFile key where the file is store in S3\u003e [Required if `html_string` is not defined]\",\n    \"html_string\": \"\u003cHTML string to convert to a PDF\u003e [Required if `file_key` is not defined]\",\n    \"wkhtmltopdf_options\": {\n        \"orientation\": \"\u003c`landscape` or `portrait`\u003e [Optional: Default is `portrait`]\",\n        \"title\": \"\u003cTitle of the PDF\u003e [Optional]\",\n        \"margin\": \"\u003cMargin of the PDF (same format as css [\u003ctop\u003e \u003cright\u003e \u003cbottom\u003e \u003cleft\u003e] (all must be included)).\u003e [Optional]\"\n    }\n}\n```\n`wkhtmltopdf_options` is an optional object. If the included options are not valid, they will not be included.\n\nWe can access all of the data passed to our function from the `event` parameter in the `lambda_handler` function.\n\nNow, let's jump back to the `lambda_handler` function and add some code to pull out the data from our event and put together the remaining pieces of actually calling the `wkhtmltopdf` executable to finish our lambda function.\n\n```python\ndef lambda_handler(event, context):\n    logger.info(event)\n\n    # bucket is always required\n    try:\n        bucket = event['bucket']\n    except KeyError:\n        error_message = 'Missing required \"bucket\" parameter from request payload.'\n        logger.error(error_message)\n        return {\n            'status': 400,\n            'body': json.dumps(error_message),\n        }\n\n    # html_string and file_key are conditionally required, so let's try to get both\n    try:\n        file_key = event['file_key']\n    except KeyError:\n        file_key = None\n\n    try:\n        html_string = event['html_string']\n    except KeyError:\n        html_string = None\n\n    if file_key is None and html_string is None:\n        error_message = (\n            'Missing both a \"file_key\" and \"html_string\" '\n            'from request payload. One of these must be '\n            'included.'\n        )\n        logger.error(error_message)\n        return {\n            'status': 400,\n            'body': json.dumps(error_message),\n        }\n\n    # Now we can check for the option wkhtmltopdf_options and map them to values\n    # Again, part of our assumptions are that these are valid\n    wkhtmltopdf_options = {}\n    if 'wkhtmltopdf_options' in event:\n        # Margin is \u003ctop\u003e \u003cright\u003e \u003cbottom\u003e \u003cleft\u003e\n        if 'margin' in event['wkhtmltopdf_options']:\n            margins = event['wkhtmltopdf_options']['margin'].split(' ')\n            if len(margins) == 4:\n                wkhtmltopdf_options['margin-top'] = margins[0]\n                wkhtmltopdf_options['margin-right'] = margins[1]\n                wkhtmltopdf_options['margin-bottom'] = margins[2]\n                wkhtmltopdf_options['margin-left'] = margins[3]\n\n        if 'orientation' in event['wkhtmltopdf_options']:\n            wkhtmltopdf_options['orientation'] = 'portrait' \\\n                if event['wkhtmltopdf_options']['orientation'].lower() not in ['portrait', 'landscape'] \\\n                else event['wkhtmltopdf_options']['orientation'].lower()\n\n        if 'title' in event['wkhtmltopdf_options']:\n            wkhtmltopdf_options['title'] = event['wkhtmltopdf_options']['title']\n\n    # If we got a file_key in the request, let's download our file\n    # If not, we'll write the HTML string to a file\n    if file_key is not None:\n        local_filename = download_s3_file(bucket, file_key)\n    else:\n        timestamp = str(datetime.now()).replace('.', '').replace(' ', '_')\n        local_filename = f'/tmp/{timestamp}-html-string.html'\n\n        # Delete any existing files with that name\n        try:\n            os.unlink(local_filename)\n        except FileNotFoundError:\n            pass\n\n        with open(local_filename, 'w') as f:\n            f.write(html_string)\n\n    # Now we can create our command string to execute and upload the result to s3\n    command = 'wkhtmltopdf  --load-error-handling ignore'  # ignore unecessary errors\n    for key, value in wkhtmltopdf_options.items():\n        if key == 'title':\n            value = f'\"{value}\"'\n        command += ' --{0} {1}'.format(key, value)\n    command += ' {0} {1}'.format(local_filename, local_filename.replace('.html', '.pdf'))\n\n    # Important! Remember, we said that we are assuming we're accepting valid HTML\n    # this should always be checked to avoid allowing any string to be executed\n    # from this command. The reason we use shell=True here is because our title\n    # can be multiple words.\n    subprocess.run(command, shell=True)\n    logger.info('Successfully generated the PDF.')\n    file_key = upload_file_to_s3(bucket, local_filename.replace('.html', '.pdf'))\n\n    if file_key is None:\n        error_message = (\n            'Failed to generate PDF from the given HTML file.'\n            ' Please check to make sure the file is valid HTML.'\n        )\n        logger.error(error_message)\n        return {\n            'status': 400,\n            'body': json.dumps(error_message),\n        }\n\n    return {\n        'status': 200,\n        'file_key': file_key,\n    }\n```\n\nNow you can go to the **Test** tab and create the following test event (change your bucket name as necessary)\n```json\n{\n    \"bucket\": \"bucket-for-articles\",\n    \"html_string\": \"\u003c!DOCTYPE html\u003e\u003chtml\u003e\u003chead\u003e\u003c/head\u003e\u003cbody\u003eThis is an example of a simple HTML page.\u003c/body\u003e\u003c/html\u003e\",\n    \"wkhtmltopdf_options\": {\n        \"orientation\": \"portrait\",\n        \"title\": \"Test PDF Generation\",\n        \"margin\": \"10mm 10mm 10mm 10mm\"\n    }\n}\n```\n\nYou should get a return event with a `status` of `200`, and a `file_key` of your converted file, thus achieving our goal! üéâ\n\n---\n\n","title":"Converting HTML to a PDF using Python, AWS Lambda, and wkhtmltopdf","date":"2021-04-29","tags":["python","aws"],"description":"Building an AWS lambda function that uses Python and wkhtmltopdf to convert an HTML file to a PDF file."},{"id":"forecasting-spy-prices","contentHtml":"\u003ch2\u003etl;dr\u003c/h2\u003e\n\u003ch3\u003eGoal\u003c/h3\u003e\n\u003cp\u003e\u003cem\u003eTo apply Facebook's Prophet forecasting procedure to historical SPY (SPDR S\u0026#x26;P 500 ETF Trust) market data to gather future pricing predictions.\u003c/em\u003e\u003c/p\u003e\n\u003ch3\u003eA few notes\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eI'm by no means a data scientist, so this is more of an exploratory analysis than an accurate one\u003c/li\u003e\n\u003cli\u003eFor sake of brevity, I won't be using a training/test split or measuring the error of the model, I will just train the model on the entire dataset and then make a prediction\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003eProcess overview\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eDownloading the data\u003c/strong\u003e - exporting the data from Yahoo Finance as a CSV\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eExploring the data\u003c/strong\u003e - loading and exploring the data using Pandas\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eFitting the model\u003c/strong\u003e - reading in the data and applying a basic fit of the Prophet model to the data\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eVisualizing the forecast\u003c/strong\u003e - visualizing the forecasted pricing data\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3\u003ePython dependencies\u003c/h3\u003e\n\u003cpre\u003e\u003ccode\u003eimport pandas as pd\nfrom prophet import Prophet\n\u003c/code\u003e\u003c/pre\u003e\n\u003chr\u003e\n\u003cp\u003eBefore we jump in, let's give a little background on SPY and on Facebook's Prophet.\u003c/p\u003e\n\u003cp\u003eThe \u003cem\u003eSPDR S\u0026#x26;P 500 ETF Trust\u003c/em\u003e (SPY) is an ETF (\u003cem\u003eExchange Traded Fund\u003c/em\u003e) that tracks the performance of the S\u0026#x26;P 500 index.  SPY is also the largest ETF in the world, and is popular compared to other ETFs that track the S\u0026#x26;P 500 because of the high volume, or the number of shares that trade on a given day (we'll be able to see the volume per day in the CSV we export from Yahoo Finance).\u003c/p\u003e\n\u003cp\u003eFor more information on ETFs, \u003ca href=\"https://www.investopedia.com/terms/e/etf.asp\"\u003eInvestopedia gives a good overview\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://facebook.github.io/prophet/\"\u003eFacebook Prophet\u003c/a\u003e is an open source, automated forecasting procedure for time series data.  I'm not going to dive too much into the mathematics or implementation details of Prophet, but if you are more interested, you can read the \u003ca href=\"https://peerj.com/preprints/3190/\"\u003eresearch paper\u003c/a\u003e.  Prophet makes it easy to handle outliers, adjust to different time intervals, deal with holidays, and leaves the ability to easily tune the forecasting model.\u003c/p\u003e\n\u003cp\u003eNow that we have a general idea of what we're trying to predict and the tool we'll use to forecast, let's dive into the actual data.\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003eDownloading the data\u003c/h2\u003e\n\u003cp\u003eThanks to Yahoo Finance, we can download historical pricing data for free. You can click \u003ca href=\"https://finance.yahoo.com/quote/SPY/history?p=SPY\"\u003ehere\u003c/a\u003e to view the SPY historical pricing data.\u003c/p\u003e\n\u003cp\u003eClick on the \u003ccode\u003eHistorical Data\u003c/code\u003e tab, and then we can adjust our \u003ccode\u003eTime Period\u003c/code\u003e to the Max as seen below (back to January 1993).\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/forecasting-spy/export-data.jpg\" alt=\"Historical pricing data {priority}{680x243}\"\u003e\u003c/p\u003e\n\u003cp\u003eNow we can click download to get our CSV and start diving into the data.\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003eExploring the data\u003c/h2\u003e\n\u003cp\u003eLet's fire up Pandas and load our data into a DataFrame to see what general insights we can extract.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003edf = pd.read_csv('SPY.csv')\n\n# Columns and row count\ndf.info()\n\"\"\"\n\u0026#x3C;class 'pandas.core.frame.DataFrame'\u003e\nRangeIndex: 7125 entries, 0 to 7124\nData columns (total 7 columns):\n #   Column     Non-Null Count  Dtype  \n---  ------     --------------  -----  \n 0   Date       7125 non-null   object \n 1   Open       7125 non-null   float64\n 2   High       7125 non-null   float64\n 3   Low        7125 non-null   float64\n 4   Close      7125 non-null   float64\n 5   Adj Close  7125 non-null   float64\n 6   Volume     7125 non-null   int64  \ndtypes: float64(5), int64(1), object(1)\nmemory usage: 389.8+ KB\n\"\"\"\n\n# Preview of the data\ndf.head()\n\"\"\"\n         Date      Open      High       Low     Close  Adj Close   Volume\n0  1993-01-29  43.96875  43.96875  43.75000  43.93750  25.884184  1003200\n1  1993-02-01  43.96875  44.25000  43.96875  44.25000  26.068277   480500\n2  1993-02-02  44.21875  44.37500  44.12500  44.34375  26.123499   201300\n3  1993-02-03  44.40625  44.84375  44.37500  44.81250  26.399649   529400\n4  1993-02-04  44.96875  45.09375  44.46875  45.00000  26.510111   531500\n\"\"\"\n\n# General statistics\ndf.describe().loc[['mean', 'min', 'max']]\n\"\"\"\n            Open        High         Low       Close   Adj Close        Volume\nmean  146.896395  147.766581  145.928716  146.896373  121.611954  8.453727e+07\nmin    43.343750   43.531250   42.812500   43.406250   25.571209  5.200000e+03\nmax   422.500000  422.820007  419.160004  422.119995  422.119995  8.710263e+08\n\"\"\"\n\n# Day to day percent changes of Highs\ndf[['Date', 'High']].set_index('Date').pct_change().reset_index()\n\"\"\"\n            Date      High\n0     1993-01-29       NaN\n1     1993-02-01  0.006397\n2     1993-02-02  0.002825\n3     1993-02-03  0.010563\n4     1993-02-04  0.005575\n         ...       ...\n7120  2021-05-10 -0.000189\n7121  2021-05-11 -0.017670\n7122  2021-05-12 -0.006454\n7123  2021-05-13 -0.000582\n7124  2021-05-14  0.012465\n\n[7125 rows x 2 columns]\n\"\"\"\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eNow that we know a bit more about our data in general, we can create a model using Prophet.\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003eFitting the model\u003c/h2\u003e\n\u003cp\u003eSince we're not concerned in this post about making our model the best it can be, we can train our model on the entire dataset.\u003c/p\u003e\n\u003cp\u003eThis typically isn't a good practice.  When trying to make an accurate prediction, you should use training and test subsets of the data and calculate errors within your model and use those results to tune hyperparameters.\u003c/p\u003e\n\u003cp\u003eNevertheless, let's continue.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e# The prophet model fits to a DataFrame with a date column (ds)\n# and a value to predict (y)\ndf_predict = df[['Date', 'Close']]\ndf_predict.columns = ['ds', 'y']\n\n# We can find all of the missing days within our dataset\n# and mark those as \"holidays\"\ndate_series = pd.to_datetime(df['Date'])\ndf_missing_dates = pd\\\n    .date_range(start=date_series.min(), end=date_series.max())\\\n    .difference(date_series)\\\n    .to_frame()\\\n    .reset_index()\ndf_missing_dates.columns = ['holiday', 'ds']\ndf_missing_dates['holiday'] = 'Stock Market Closed'\n\n# Fitting our model is incredibly simple and can be done in the\n# most basic sense in just two lines of code\nm = Prophet(daily_seasonality=True, holidays=df_missing_dates)\nm.fit(df_predict)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eJust like that, we have built our model for a forecast.  All we have left to do is generate dates to predict values for, and run the actual prediction.\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003eVisualizing the forecast\u003c/h2\u003e\n\u003cp\u003eNow let's forecast with our model and visualize the results.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e# Create a DataFrame with past and future dates (only weekdays)\nfuture = m.make_future_dataframe(periods=365)\nfuture = future[pd.to_datetime(future['ds']).dt.weekday \u0026#x3C; 5]\n\n# Now we can forecast and visualize in just two more lines of code\nforecast = m.predict(future)\nm.plot(forecast, xlabel='Date', ylabel='Daily Closing Price')\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cimg src=\"/images/forecasting-spy/first-prediction.jpg\" alt=\"First SPY forecast {800x480}\"\u003e\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003eA few things to notice\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eThe black dots are the training data points\u003c/li\u003e\n\u003cli\u003eThe blue outline is the confidence interval\u003c/li\u003e\n\u003cli\u003eThe line within the confidence interval is the actual forecast\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eBased on our results, we can see the forecast is fairly linear and the confidence interval is relatively narrow (due to the volume of date).  The behavior of the stock market since Covid-19 started back around February 2020 has be a little unorthodox, so let's narrow our model to be trained back to data starting in 2017 to see if there is an effect.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e# Narrow down to start at 2017\ndf_recent_predict = df_predict.iloc[date_series[date_series.dt.year \u003e 2016].index]\ndate_series = pd.to_datetime(df_recent_predict['ds'])\ndf_recent_missing_dates =  pd\\\n    .date_range(start=date_series.min(), end=date_series.max())\\\n    .difference(date_series)\\\n    .to_frame()\\\n    .reset_index()\ndf_recent_missing_dates.columns = ['holiday', 'ds']\ndf_recent_missing_dates['holiday'] = 'Stock Market Closed'\n\n# Create and fit our new model\nm = Prophet(daily_seasonality=True, holidays=df_recent_missing_dates)\nm.fit(df_recent_predict)\n\n# Recreate our future predictions\nfuture = m.make_future_dataframe(periods=365)\nfuture = future[pd.to_datetime(future['ds']).dt.weekday \u0026#x3C; 5]\n\n# Forecast and visualize\nforecast = m.predict(future)\nm.plot(forecast, xlabel='Date', ylabel='Daily Closing Price')\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cimg src=\"/images/forecasting-spy/second-prediction.jpg\" alt=\"Second SPY forecast {800x480}\"\u003e\u003c/p\u003e\n\u003cp\u003eNow we can see a much wider confidence interval and a bit more of a bumpy forecast line; however, this looks much more realistic in terms of stock market prediction.\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003eConclusion\u003c/h2\u003e\n\u003cp\u003eAll in all, Facebook's Prophet is a very fast, impressive, and strongly abstracted library.  The entire script, including reading in the data, training and forecasting two models, and plotting both of the forecasts took right around \u003cstrong\u003e25 seconds\u003c/strong\u003e.\u003c/p\u003e\n\u003cp\u003eI would love to see this tool in the hands of an actual data scientist to see the accuracy of the models they'd be able to create using Prophet.\u003c/p\u003e\n\u003chr\u003e\n","markdown":"\n## tl;dr\n\n### Goal\n_To apply Facebook's Prophet forecasting procedure to historical SPY (SPDR S\u0026P 500 ETF Trust) market data to gather future pricing predictions._\n\n### A few notes\n- I'm by no means a data scientist, so this is more of an exploratory analysis than an accurate one\n- For sake of brevity, I won't be using a training/test split or measuring the error of the model, I will just train the model on the entire dataset and then make a prediction\n\n### Process overview\n1. **Downloading the data** - exporting the data from Yahoo Finance as a CSV\n2. **Exploring the data** - loading and exploring the data using Pandas\n3. **Fitting the model** - reading in the data and applying a basic fit of the Prophet model to the data\n4. **Visualizing the forecast** - visualizing the forecasted pricing data\n\n### Python dependencies\n```python\nimport pandas as pd\nfrom prophet import Prophet\n```\n\n\u003cp style=\"background-color: orange; padding: 7px 20px; border-radius: 6px;\"\u003e\n    \u003cb\u003eImportant\u003c/b\u003e This article is not investment advice, please conduct your own due diligence. This is merely a simple analysis.\n\u003c/p\u003e\n\n---\n\nBefore we jump in, let's give a little background on SPY and on Facebook's Prophet.\n\nThe _SPDR S\u0026P 500 ETF Trust_ (SPY) is an ETF (_Exchange Traded Fund_) that tracks the performance of the S\u0026P 500 index.  SPY is also the largest ETF in the world, and is popular compared to other ETFs that track the S\u0026P 500 because of the high volume, or the number of shares that trade on a given day (we'll be able to see the volume per day in the CSV we export from Yahoo Finance).\n\nFor more information on ETFs, [Investopedia gives a good overview](https://www.investopedia.com/terms/e/etf.asp).\n\n[Facebook Prophet](https://facebook.github.io/prophet/) is an open source, automated forecasting procedure for time series data.  I'm not going to dive too much into the mathematics or implementation details of Prophet, but if you are more interested, you can read the [research paper](https://peerj.com/preprints/3190/).  Prophet makes it easy to handle outliers, adjust to different time intervals, deal with holidays, and leaves the ability to easily tune the forecasting model.\n\nNow that we have a general idea of what we're trying to predict and the tool we'll use to forecast, let's dive into the actual data.\n\n---\n\n## Downloading the data\nThanks to Yahoo Finance, we can download historical pricing data for free. You can click [here](https://finance.yahoo.com/quote/SPY/history?p=SPY) to view the SPY historical pricing data.\n\nClick on the `Historical Data` tab, and then we can adjust our `Time Period` to the Max as seen below (back to January 1993).\n\n![Historical pricing data {priority}{680x243}](/images/forecasting-spy/export-data.jpg)\n\nNow we can click download to get our CSV and start diving into the data.\n\n---\n\n## Exploring the data\nLet's fire up Pandas and load our data into a DataFrame to see what general insights we can extract.\n\n```python\ndf = pd.read_csv('SPY.csv')\n\n# Columns and row count\ndf.info()\n\"\"\"\n\u003cclass 'pandas.core.frame.DataFrame'\u003e\nRangeIndex: 7125 entries, 0 to 7124\nData columns (total 7 columns):\n #   Column     Non-Null Count  Dtype  \n---  ------     --------------  -----  \n 0   Date       7125 non-null   object \n 1   Open       7125 non-null   float64\n 2   High       7125 non-null   float64\n 3   Low        7125 non-null   float64\n 4   Close      7125 non-null   float64\n 5   Adj Close  7125 non-null   float64\n 6   Volume     7125 non-null   int64  \ndtypes: float64(5), int64(1), object(1)\nmemory usage: 389.8+ KB\n\"\"\"\n\n# Preview of the data\ndf.head()\n\"\"\"\n         Date      Open      High       Low     Close  Adj Close   Volume\n0  1993-01-29  43.96875  43.96875  43.75000  43.93750  25.884184  1003200\n1  1993-02-01  43.96875  44.25000  43.96875  44.25000  26.068277   480500\n2  1993-02-02  44.21875  44.37500  44.12500  44.34375  26.123499   201300\n3  1993-02-03  44.40625  44.84375  44.37500  44.81250  26.399649   529400\n4  1993-02-04  44.96875  45.09375  44.46875  45.00000  26.510111   531500\n\"\"\"\n\n# General statistics\ndf.describe().loc[['mean', 'min', 'max']]\n\"\"\"\n            Open        High         Low       Close   Adj Close        Volume\nmean  146.896395  147.766581  145.928716  146.896373  121.611954  8.453727e+07\nmin    43.343750   43.531250   42.812500   43.406250   25.571209  5.200000e+03\nmax   422.500000  422.820007  419.160004  422.119995  422.119995  8.710263e+08\n\"\"\"\n\n# Day to day percent changes of Highs\ndf[['Date', 'High']].set_index('Date').pct_change().reset_index()\n\"\"\"\n            Date      High\n0     1993-01-29       NaN\n1     1993-02-01  0.006397\n2     1993-02-02  0.002825\n3     1993-02-03  0.010563\n4     1993-02-04  0.005575\n         ...       ...\n7120  2021-05-10 -0.000189\n7121  2021-05-11 -0.017670\n7122  2021-05-12 -0.006454\n7123  2021-05-13 -0.000582\n7124  2021-05-14  0.012465\n\n[7125 rows x 2 columns]\n\"\"\"\n```\n\nNow that we know a bit more about our data in general, we can create a model using Prophet.\n\n---\n\n## Fitting the model\n\nSince we're not concerned in this post about making our model the best it can be, we can train our model on the entire dataset.\n\nThis typically isn't a good practice.  When trying to make an accurate prediction, you should use training and test subsets of the data and calculate errors within your model and use those results to tune hyperparameters.\n\nNevertheless, let's continue.\n\n```python\n# The prophet model fits to a DataFrame with a date column (ds)\n# and a value to predict (y)\ndf_predict = df[['Date', 'Close']]\ndf_predict.columns = ['ds', 'y']\n\n# We can find all of the missing days within our dataset\n# and mark those as \"holidays\"\ndate_series = pd.to_datetime(df['Date'])\ndf_missing_dates = pd\\\n    .date_range(start=date_series.min(), end=date_series.max())\\\n    .difference(date_series)\\\n    .to_frame()\\\n    .reset_index()\ndf_missing_dates.columns = ['holiday', 'ds']\ndf_missing_dates['holiday'] = 'Stock Market Closed'\n\n# Fitting our model is incredibly simple and can be done in the\n# most basic sense in just two lines of code\nm = Prophet(daily_seasonality=True, holidays=df_missing_dates)\nm.fit(df_predict)\n```\n\nJust like that, we have built our model for a forecast.  All we have left to do is generate dates to predict values for, and run the actual prediction.\n\n---\n\n## Visualizing the forecast\nNow let's forecast with our model and visualize the results.\n\n```python\n# Create a DataFrame with past and future dates (only weekdays)\nfuture = m.make_future_dataframe(periods=365)\nfuture = future[pd.to_datetime(future['ds']).dt.weekday \u003c 5]\n\n# Now we can forecast and visualize in just two more lines of code\nforecast = m.predict(future)\nm.plot(forecast, xlabel='Date', ylabel='Daily Closing Price')\n```\n\n![First SPY forecast {800x480}](/images/forecasting-spy/first-prediction.jpg)\n\n\u003e **A few things to notice**\n\u003e - The black dots are the training data points\n\u003e - The blue outline is the confidence interval\n\u003e - The line within the confidence interval is the actual forecast\n\nBased on our results, we can see the forecast is fairly linear and the confidence interval is relatively narrow (due to the volume of date).  The behavior of the stock market since Covid-19 started back around February 2020 has be a little unorthodox, so let's narrow our model to be trained back to data starting in 2017 to see if there is an effect.\n\n```python\n# Narrow down to start at 2017\ndf_recent_predict = df_predict.iloc[date_series[date_series.dt.year \u003e 2016].index]\ndate_series = pd.to_datetime(df_recent_predict['ds'])\ndf_recent_missing_dates =  pd\\\n    .date_range(start=date_series.min(), end=date_series.max())\\\n    .difference(date_series)\\\n    .to_frame()\\\n    .reset_index()\ndf_recent_missing_dates.columns = ['holiday', 'ds']\ndf_recent_missing_dates['holiday'] = 'Stock Market Closed'\n\n# Create and fit our new model\nm = Prophet(daily_seasonality=True, holidays=df_recent_missing_dates)\nm.fit(df_recent_predict)\n\n# Recreate our future predictions\nfuture = m.make_future_dataframe(periods=365)\nfuture = future[pd.to_datetime(future['ds']).dt.weekday \u003c 5]\n\n# Forecast and visualize\nforecast = m.predict(future)\nm.plot(forecast, xlabel='Date', ylabel='Daily Closing Price')\n```\n\n![Second SPY forecast {800x480}](/images/forecasting-spy/second-prediction.jpg)\n\nNow we can see a much wider confidence interval and a bit more of a bumpy forecast line; however, this looks much more realistic in terms of stock market prediction.\n\n---\n\n## Conclusion\n\nAll in all, Facebook's Prophet is a very fast, impressive, and strongly abstracted library.  The entire script, including reading in the data, training and forecasting two models, and plotting both of the forecasts took right around **25 seconds**.\n\nI would love to see this tool in the hands of an actual data scientist to see the accuracy of the models they'd be able to create using Prophet.\n\n---\n","title":"Forecasting SPY prices using Facebook's Prophet","date":"2021-05-19","tags":["python","pandas","data-analysis"],"description":"Using Facebook‚Äôs Prophet, an open-source, time series forecasting procedure to predict SPY (SPDR S\u0026P 500 ETF Trust) closing prices."},{"id":"slack-webhook","contentHtml":"\u003ch2\u003etl;dr\u003c/h2\u003e\n\u003ch3\u003eGoal\u003c/h3\u003e\n\u003cp\u003e\u003cem\u003eTo set up a Slack webhook so we can send text and simple HTML notifications to receive in a Slack channel.\u003c/em\u003e\u003c/p\u003e\n\u003ch3\u003eProcess Overview\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003eSetting up a Slack webhook URL in your Slack workspace to post to a channel\u003c/li\u003e\n\u003cli\u003ePosting a notification to our webhook\u003c/li\u003e\n\u003cli\u003eCreating a simple HTML parser to match the custom Slack markdown flavor\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3\u003ePython Dependencies\u003c/h3\u003e\n\u003cpre\u003e\u003ccode\u003e# Python standard library\nfrom html.parser import HTMLParser\nimport logging\nimport os\nimport re\nfrom typing import Any, List, Tuple\n\n# 3rd Party\nimport requests\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003eAssumptions\u003c/h3\u003e\n\u003cp\u003eI'll assume you have a Slack account, a Slack workspace setup, Slack is installed, and you have knowledge of Python with a basic understanding of webhooks.\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003eIf you haven't heard of it before, \u003ca href=\"https://slack.com/\"\u003eSlack\u003c/a\u003e is a very popular team/workplace communication tool.  In addition to direct messaging, it allows you to separate discussion into various topics or \u003cstrong\u003echannels\u003c/strong\u003e for more focused team communication.\u003c/p\u003e\n\u003cp\u003eAnother great feature of Slack is that you can add 3rd party \u003ca href=\"https://slack.com/apps\"\u003eapps\u003c/a\u003e (or integrations) from your existing stack, or even develop your own!  I have seen this streamline my own productivity, and I personally use a number of Slack apps.\u003c/p\u003e\n\u003cp\u003eTo name a few, you may want to check out the following (assuming you use these tools) which I've found a lot of value in:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://slack.com/apps/A011MFBJEUU-sentry?tab=more_info\"\u003eSentry\u003c/a\u003e - for application monitoring\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://slack.com/apps/ADZ494LHY-google-calendar?tab=more_info\"\u003eGoogle Calendar\u003c/a\u003e - to stay on top of my meetings schedule\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://slack.com/apps/A01BP7R4KNY-github?tab=more_info\"\u003eGitHub\u003c/a\u003e - getting notified of pull requests and meaningful changes to important repositories\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://slack.com/apps/A2RPP3NFR-jira-cloud?tab=more_info\"\u003eJira Cloud\u003c/a\u003e - staying on top of changes to Jira tickets\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://slack.com/apps/A6L22LZNH-aws-chatbot?tab=more_info\"\u003eAWS Chatbot\u003c/a\u003e - alerts from CloudWatch alarms\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eYou can browse the \u003ca href=\"https://slack.com/apps\"\u003eSlack app directory\u003c/a\u003e for more integrations.\u003c/p\u003e\n\u003cp\u003eHowever, not every integration is going to provide the functionality you need.  This post will focus on creating our own custom Slack app with the goal of posting simple notifications to a Slack channel.\u003c/p\u003e\n\u003cp\u003eA common use case where we can apply our app will be sending notifications when any sort of user activity happens on a platform.  As a developer, being notified of when a user completes a certain task can provide a lot of transparency and understanding into the usage of our application, while also keeping a sales teams informed on relevant activity on the platform.  This is the use case we'll focus on.\u003c/p\u003e\n\u003cp\u003eWe will do this by posting to a webhook hosted by Slack.  For more information on webhooks, you can check out \u003ca href=\"https://zapier.com/blog/what-are-webhooks/\"\u003ethis article\u003c/a\u003e by Zapier.\u003c/p\u003e\n\u003cp\u003eLet's get started!\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003eSetting up the Slack App\u003c/h2\u003e\n\u003cp\u003eOpen Slack, click \u003cstrong\u003eAdd channels\u003c/strong\u003e, and create a new channel called \u003ccode\u003enotifications\u003c/code\u003e.  This is where our Slack app will post to once we set it up.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/slack-webhook/create-channel.jpg\" alt=\"Create a Slack channel {priority}{1004x580}\"\u003e\u003c/p\u003e\n\u003cp\u003eNow go to a web browser and head to https://api.slack.com/apps/.\u003c/p\u003e\n\u003cp\u003eClick on \u003cstrong\u003eCreate an App\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/slack-webhook/create-app.jpg\" alt=\"Create a Slack App {1004x497}\"\u003e\u003c/p\u003e\n\u003cp\u003eSelect \u003cstrong\u003eFrom scratch\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/slack-webhook/from-scratch.jpg\" alt=\"Select From Scratch {1004x497}\"\u003e\u003c/p\u003e\n\u003cp\u003eCreate a name for your app and select the workspace you just created your \u003ccode\u003enotifications\u003c/code\u003e channel in.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/slack-webhook/app-and-workspace.jpg\" alt=\"Choose an app name and workspace {1004x501}\"\u003e\u003c/p\u003e\n\u003cp\u003eThis will redirect you to the \u003cstrong\u003eBasic Information\u003c/strong\u003e tab for your app.  Here, we'll enable \u003cstrong\u003eIncoming Webhooks\u003c/strong\u003e.  As it states, this will enable us to post messages from an external source.  In this case, our platform.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/slack-webhook/add-webhooks.jpg\" alt=\"Enable incoming webhooks {1004x497}\"\u003e\u003c/p\u003e\n\u003cp\u003eTurn on \u003cstrong\u003eActivate Incoming Webhooks\u003c/strong\u003e and you will see additional details appear.  Towards the bottom, click on \u003cstrong\u003eAdd New Webhook to Workspace\u003c/strong\u003e.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/slack-webhook/add-new-webhook.jpg\" alt=\"Add a new webhook to your workspace {1004x485}\"\u003e\u003c/p\u003e\n\u003cp\u003eYou will be redirected again to select which channel to post to.  Select the \u003ccode\u003enotifications\u003c/code\u003e channel that we previously created and press \u003cstrong\u003eAllow\u003c/strong\u003e.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/slack-webhook/choose-channel.jpg\" alt=\"Select a channel for your app {1004x498}\"\u003e\u003c/p\u003e\n\u003cp\u003eThis will redirect you back to your app configuration and you will see a webhook URL you can now post to.  This will also include a simple curl POST request you can test with if you'd like.  Copy the webhook URL for later, and remember to \u003cstrong\u003ekeep it private\u003c/strong\u003e.  This is a public URL that anyone can post to.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/slack-webhook/copy-url.jpg\" alt=\"Copy your webhook URL {680x506}\"\u003e\u003c/p\u003e\n\u003cp\u003eYou can return to the \u003cstrong\u003eBasic Information\u003c/strong\u003e of your app settings in Slack to view more API credentials and also edit the look and feel of your new Slack bot.\u003c/p\u003e\n\u003cp\u003eNow we're ready to dive into the code to communicate with our webhook!\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003eCommunicating with our Webhook\u003c/h2\u003e\n\u003cp\u003eTo communicate with our webhook, we'll use the \u003ca href=\"https://docs.python-requests.org/en/master/\"\u003e\u003ccode\u003erequests\u003c/code\u003e\u003c/a\u003e Python library.  This is a third party library, so you'll want to have a Python virtual environment set up to handle your dependencies.  Virtual environments are out of the scope of this article, but you can read more on them \u003ca href=\"https://docs.python.org/3/tutorial/venv.html\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eInside your virtual environment, you can run the following to install the library.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003epip install requests\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eNow, we'll set up a class to communicate with our Slack endpoint.  We'll start by just sending a plain text message to Slack.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eimport logging\n\nimport requests\n\n\nlogger = logging.getLogger()\nlogger.setLevel(logging.INFO)\n\n\nclass SlackWebhookBot:\n    def __init__(self, webhook_url: str, timeout: int = 15):\n        \"\"\"Class to send messages to a provided Slack webhook URL.\n\n        You can read more about Slack's Incoming Webhooks here:\n            https://api.slack.com/messaging/webhooks\n        \n        Args:\n            webhook_url: The webhook URL to send a message to.  Typically\n                formatted like \"https://hooks.slack.com/services/...\".\n        \n        Kwargs:\n            timeout: Number of seconds before the request will timeout.\n                This is used to prevent a hang and is set to a default\n                value of 15 seconds.\n        \"\"\"\n        self.webhook_url = webhook_url\n        self.timeout = timeout\n        self.headers = {\n            'Content-Type': 'application/json',\n        }\n    \n\n    def send(self, message: str) -\u003e bool:\n        \"\"\"Sends a message to the webhook URL.\n\n        Per the Slack Incoming Webhook example.  The body of the request\n        (for plain text) should be formatted as follows:\n            `{\"text\": \"Hello, World!\"}`\n\n        Args:\n            message: Plain text string to send to Slack.\n\n        Returns:\n            A boolean representing if the request was successful.\n        \"\"\"\n        success = False\n        payload = {\n            'text': message,\n        }\n        try:\n            r = requests.post(\n                self.webhook_url,\n                headers=self.headers,\n                json=payload,\n                timeout=self.timeout\n            )\n        except requests.Timeout:\n            logger.error('Timeout occurred when trying to send message to Slack.')\n        except requests.RequestException as e:\n            logger.error(f'Error occurred when communicating with Slack: {e}.')\n        else:\n            success = True\n            logger.info('Successfully sent message to Slack.')\n\n        return success\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eAbove is the basic setup for communicating with the Slack webhook.  We can run a quick test by moving this code to a script and adding the following.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eimport os\n\nwebhook_url = os.environ.get('SLACK_WEBHOOK_URL')\nslack = SlackWebhookBot(webhook_url)\nslack.send('Hello, world!')\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eMake sure to set your Slack webhook URL to the \u003ccode\u003eSLACK_WEBHOOK_URL\u003c/code\u003e environment variable, and make sure you're in your virtual environment with the \u003ccode\u003erequests\u003c/code\u003e package installed before running the script.  This can be done on MacOS with the following.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eexport SLACK_WEBHOOK_URL=https://hooks.slack.com/services/...\npython slack_webhook.py\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eWhen you run this, you should see a message from you Slack bot appear in the \u003ccode\u003enotifications\u003c/code\u003e channel!\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/slack-webhook/slack-first-message.jpg\" alt=\"Hello world message in Slack {1004x675}\"\u003e\u003c/p\u003e\n\u003cp\u003eFor our notifications to be more helpful, we may want to add links or other formatting.  To do this, we will write our notifications with HTML tags, and then parse these tags and convert them to the \u003ca href=\"https://api.slack.com/reference/surfaces/formatting\"\u003eSlack flavored Markdown\u003c/a\u003e called \u003ccode\u003emrkdwn\u003c/code\u003e.\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003eAdding a simple HTML parser to our class\u003c/h2\u003e\n\u003cp\u003eFrom the \u003ca href=\"https://api.slack.com/reference/surfaces/formatting\"\u003eSlack formatting guide\u003c/a\u003e for messages, we can see all of the ways to format text in our messages.  For our purposes, we will focus on a primary list.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eMaking text \u003ccode\u003e_italicized_\u003c/code\u003e (\u003ccode\u003e\u0026#x3C;i\u003e\u003c/code\u003e)\u003c/li\u003e\n\u003cli\u003eMaking text \u003ccode\u003e*bold*\u003c/code\u003e (\u003ccode\u003e\u0026#x3C;b\u003e\u003c/code\u003e)\u003c/li\u003e\n\u003cli\u003eStriking through ~\u003ccode\u003etext\u003c/code\u003e~ (\u003ccode\u003e\u0026#x3C;strike\u003e\u003c/code\u003e)\u003c/li\u003e\n\u003cli\u003eAdding line breaks (\u003ccode\u003e\u0026#x3C;br\u003e\u003c/code\u003e)\u003c/li\u003e\n\u003cli\u003eAdding \u003ccode\u003eone-line code blocks\u003c/code\u003e using the backtick character (\u003ccode\u003e\u0026#x3C;code\u003e\u003c/code\u003e)\u003c/li\u003e\n\u003cli\u003eAdding unordered lists (line broken dashes) (\u003ccode\u003e\u0026#x3C;ul\u003e\u0026#x3C;li\u003e\u003c/code\u003e)\u003c/li\u003e\n\u003cli\u003eAdding external links \u003ccode\u003e\u0026#x3C;[external link]|[display text]\u003e\u003c/code\u003e (\u003ccode\u003e\u0026#x3C;a\u003e\u003c/code\u003e)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eAlso note that the Slack documentation says that \u003ca href=\"https://api.slack.com/reference/surfaces/formatting#escaping\"\u003ecertain characters need to be escaped\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eThere are a few more styles that could be implemented, but we'll focus on just this list for this post.\u003c/p\u003e\n\u003cp\u003eTo do this, we will utilize the \u003ca href=\"https://docs.python.org/3/library/html.html\"\u003e\u003ccode\u003ehtml\u003c/code\u003e\u003c/a\u003e module in the Python standard library to parse HTML tags, attributes, and values.\u003c/p\u003e\n\u003cp\u003eLet's write a class (we need to inherit functions for the \u003ccode\u003eHTMLParser\u003c/code\u003e class) where we will parse all of the tags and attributes, and escape the message text when needed.  The idea here is that we can construct a string from scratch and for each tag we care about we can \"replace\" the HTML tags with the relevant mrkdwn syntax.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003efrom html.parser import HTMLParser\nimport re\nfrom typing import Any, List, Tuple\n\n\nclass SlackHTMLParser(HTMLParser):\n    def __init__(self, *args, **kwargs):\n        \"\"\"Escapes and converts an HTML string to Slack flavored\n        Markdown (mrkdwn).\n\n        More about Slack's Markdown Flavor (mrkdwn) can be seen here:\n            https://api.slack.com/reference/surfaces/formatting\n        \n        Call using `SlackHTMLParser(message_body).parse()`.\n        \"\"\"\n        super().__init__(*args, **kwargs)\n        self.slack_message = ''\n        self.ignore_tag = False  # Used to skip tags we don't care about\n        self.line_break = '::LINE::BREAK::'  # Unique sequence for swapping a \u0026#x3C;br\u003e\n\n\n    def handle_starttag(self, tag: str, attrs: List[Tuple[str, Any]]):\n        \"\"\"Called when the opening of a tag is encountered.\n\n        The idea here is to swap out the tag with the respective mrkdwn\n        symbol.\n\n        Args:\n            tag: Lowercase name of the HTML tag.  E.G. `br` or `i`.\n            attrs: List of tuples with the tuple having the following form:\n                (attribute name, value).  E.G. ('href', 'www.example.com').\n        \"\"\"\n        if tag in ['i', 'em']:\n            self.slack_message += '_'\n        elif tag in ['b', 'strong']:\n            self.slack_message += '*'\n        elif tag == 'strike':\n            self.slack_message += '~'\n        elif tag in ['br', 'p', 'ul']:\n            self.slack_message += self.line_break\n        elif tag == 'li':\n            self.slack_message += f'{self.line_break}- '\n        elif tag == 'code':\n            self.slack_message += '`'\n        elif tag == 'a':\n            href = [x[1] for x in attrs if x[0] == 'href']\n            if len(href) \u003e 0:\n                self.slack_message += f'\u0026#x3C;{href[0]}|'\n        else:\n            self.ignore_tag = True\n\n\n    def handle_data(self, data: str):\n        \"\"\"Handles the data within a tag.\n\n        This is called after `handle_starttag` and before `handle_endtag`.\n\n        We will also escape the following text per Slack's documentation:\n        - '\u0026#x26;' -\u003e '\u0026#x26;amp;'\n        - '\u0026#x3C;' -\u003e '\u0026#x26;lt;'\n        - '\u003e' -\u003e '\u0026#x26;gt;'\n\n        Args:\n            data: The data/string within the HTML tag.\n        \"\"\"\n        if not self.ignore_tag:\n            self.slack_message += data\\\n                .replace('\u0026#x26;', '\u0026#x26;amp;')\\\n                .replace('\u0026#x3C;', '\u0026#x26;lt;')\\\n                .replace('\u003e', '\u0026#x26;gt;')\n\n\n    def handle_endtag(self, tag: str):\n        \"\"\"Called when the closing of a tag is encountered.\n\n        The idea here is to swap out the tag with the respective mrkdwn\n        symbol.  This is basically the same as the handle_starttag.\n\n        Args:\n            tag: Lowercase name of the HTML tag.  E.G. `br` or `i`.\n        \"\"\"\n        if tag in ['i', 'em']:\n            self.slack_message += '_'\n        elif tag in ['b', 'strong']:\n            self.slack_message += '*'\n        elif tag == 'strike':\n            self.slack_message += '~'\n        elif tag == 'p':\n            self.slack_message += self.line_break\n        elif tag == 'code':\n            self.slack_message += '`'\n        elif tag == 'a':\n            self.slack_message += '\u003e'\n        \n        self.ignore_tag = False\n\n\n    def parse(self, html_string: str) -\u003e str:\n        \"\"\"Parses a given HTML string and applies simple formatting.\n        \n        Note that we need to apply the line break replacing here\n        instead of with the handle tag methods.\n\n        Args:\n            html_string: The HTML string to convert to Slack mrkdwn.\n\n        Returns:\n            A formatted Slack mrkdwn string.\n        \"\"\"\n        self.feed(html_string)\n        return re.sub(\n            r'^(\\n)+',  # Remove the leading line breaks\n            '',\n            ' '.join(self.slack_message.split()).replace(self.line_break, '\\n')\n        )\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eWe can test our class out with the following code.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ehtml_string = '''\n    \u0026#x3C;p\u003e\n        Here \u0026#x3C;i\u003eis\u0026#x3C;/i\u003e a \u0026#x3C;strike\u003eparagraph\u0026#x3C;/strike\u003e with a \u0026#x3C;b\u003elot\u0026#x3C;/b\u003e of formatting.\n    \u0026#x3C;/p\u003e\n    \u0026#x3C;br\u003e\n    \u0026#x3C;code\u003eCode sample\u0026#x3C;/code\u003e \u0026#x26; testing escape.\n    \u0026#x3C;ul\u003e\n        \u0026#x3C;li\u003e\n            \u0026#x3C;a href=\"https://www.google.com\"\u003eGoogle\u0026#x3C;/a\u003e\n        \u0026#x3C;/li\u003e\n        \u0026#x3C;li\u003e\n            \u0026#x3C;a href=\"https://www.amazon.com\"\u003eAmazon\u0026#x3C;/a\u003e\n        \u0026#x3C;/li\u003e\n    \u0026#x3C;/ul\u003e\n'''\nparser = SlackHTMLParser()\nslack_message = parser.parse(html_string)\nprint(slack_message)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eNow we can test our formatter in an actual Slack message!  Import your formatter class or add it to your existing code so you're able to do the following.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ehtml_string = '''\n    \u0026#x3C;p\u003e\n        Here \u0026#x3C;i\u003eis\u0026#x3C;/i\u003e a \u0026#x3C;strike\u003eparagraph\u0026#x3C;/strike\u003e with a \u0026#x3C;b\u003elot\u0026#x3C;/b\u003e of formatting.\n    \u0026#x3C;/p\u003e\n    \u0026#x3C;br\u003e\n    \u0026#x3C;code\u003eCode sample\u0026#x3C;/code\u003e \u0026#x26; testing escape.\n    \u0026#x3C;ul\u003e\n        \u0026#x3C;li\u003e\n            \u0026#x3C;a href=\"https://www.google.com\"\u003eGoogle\u0026#x3C;/a\u003e\n        \u0026#x3C;/li\u003e\n        \u0026#x3C;li\u003e\n            \u0026#x3C;a href=\"https://www.amazon.com\"\u003eAmazon\u0026#x3C;/a\u003e\n        \u0026#x3C;/li\u003e\n    \u0026#x3C;/ul\u003e\n'''\nwebhook_url = os.environ.get('SLACK_WEBHOOK_URL')\nparser = SlackHTMLParser()\nslack_message = parser.parse(html_string)\nslack = SlackWebhookBot(webhook_url)\nslack.send(slack_message)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eYou should see the following message in your notifications channel.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/slack-webhook/slack-format-message.jpg\" alt=\"Second message in Slack {680x140}\"\u003e\u003c/p\u003e\n\u003cp\u003eLooks pretty good!  \u003cem\u003eNote that you can still send plain text messages, you don't need to use HTML.\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003eFor some final adjustments, you may have noticed that the message preview on the notification that popped up showed the actual \u003ccode\u003emrkdwn\u003c/code\u003e characters as opposed to a formatted notification.  This looks a little sloppy, so let's make a new notification title that is similar to an email subject line.\u003c/p\u003e\n\u003cp\u003eWe will briefly look at the basics of Slack's \u003ca href=\"https://api.slack.com/block-kit\"\u003eBlock Kit\u003c/a\u003e, which is a powerful way to add lots of customization to your Slack messages.  You can also explore Block Kit with Slack's \u003ca href=\"https://app.slack.com/block-kit-builder/\"\u003eBlock Kit Builder\u003c/a\u003e which provides a preview of your Slack message.\u003c/p\u003e\n\u003cp\u003eWithout diving too much into the details on the Block Kit, let's update our \u003ccode\u003eSlackWebhookBot\u003c/code\u003e class and add a method that adds a title block and a body block for our message.  Our subject line will appear in the notification itself, and also in the actual Slack message.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e# Add the `Dict` typing import to the existing typing imports\nfrom typing import Dict\n\ndef format_message(self, subject: str, body: str) -\u003e Dict:\n    \"\"\"Formats the subject and message body into Slack blocks.\n\n    Args:\n        subject: Subject that will appear on the notification popup.\n        body: The full message body.\n\n    Returns:\n        A dictionary payload with Slack block formatting.\n    \"\"\"\n    return {\n        'text': subject,\n        'blocks': [\n            {\n                'type': 'section',\n                'text': {\n                    'type': 'mrkdwn',\n                    'text': f'*{subject}*',\n                },\n            },\n            {\n                'type': 'section',\n                'text': {\n                    'type': 'mrkdwn',\n                    'text': body,\n                },\n            },\n        ],\n    }\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eNow we can tweak our \u003ccode\u003esend\u003c/code\u003e method to format a new message and accept a subject string as a Kwarg.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003edef send(self, message: str, subject: str = 'New message!') -\u003e bool:\n    \"\"\"Sends a formatted message to the webhook URL.\n\n    Args:\n        message: Plain text string to send to Slack.\n\n    Kwargs:\n        subject: The subject of the message that will appear in the notification\n            preview.\n\n    Returns:\n        A boolean representing if the request was successful.\n    \"\"\"\n    success = False\n    payload = self.format_message(subject, message)\n    try:\n        r = requests.post(\n            self.webhook_url,\n            headers=self.headers,\n            json=payload,\n            timeout=self.timeout\n        )\n    except requests.Timeout:\n        logger.error('Timeout occurred when trying to send message to Slack.')\n    except requests.RequestException as e:\n        logger.error(f'Error occurred when communicating with Slack: {e}.')\n    else:\n        success = True\n        logger.info('Successfully sent message to Slack.')\n\n    return success\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eAnd we can test our notification with a new subject line.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ehtml_string = '''\n    \u0026#x3C;p\u003e\n        Here \u0026#x3C;i\u003eis\u0026#x3C;/i\u003e a \u0026#x3C;strike\u003eparagraph\u0026#x3C;/strike\u003e with a \u0026#x3C;b\u003elot\u0026#x3C;/b\u003e of formatting.\n    \u0026#x3C;/p\u003e\n    \u0026#x3C;br\u003e\n    \u0026#x3C;code\u003eCode sample\u0026#x3C;/code\u003e \u0026#x26; testing escape.\n    \u0026#x3C;ul\u003e\n        \u0026#x3C;li\u003e\n            \u0026#x3C;a href=\"https://www.google.com\"\u003eGoogle\u0026#x3C;/a\u003e\n        \u0026#x3C;/li\u003e\n        \u0026#x3C;li\u003e\n            \u0026#x3C;a href=\"https://www.amazon.com\"\u003eAmazon\u0026#x3C;/a\u003e\n        \u0026#x3C;/li\u003e\n    \u0026#x3C;/ul\u003e\n'''\nwebhook_url = os.environ.get('SLACK_WEBHOOK_URL')\nparser = SlackHTMLParser()\nslack_message = parser.parse(html_string)\nslack = SlackWebhookBot(webhook_url)\nslack.send(slack_message, subject='You\\'ve completed the tutorial!')\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eYou should see a notification appear with the following preview\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/slack-webhook/slack-popup.jpg\" alt=\"Slack notification {453x101}\"\u003e\u003c/p\u003e\n\u003cp\u003eand the following message in your channel.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/slack-webhook/slack-last-message.jpg\" alt=\"Last message in Slack {680x159}\"\u003e\u003c/p\u003e\n\u003cp\u003eWe have a custom Slack notification app!  You can place the \u003ccode\u003esend\u003c/code\u003e message calls all across your applications with related messages and now you can have a better pulse on user activity that developers and any other employees/stakeholders can easily access.\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003eFor those wanting additional challenges or to continue developing their custom app, Slack has added a lot of really cool tools to the Block Kit.  There are a ton of really cool possibilities that can be added on by updating the \u003ccode\u003eformat_message\u003c/code\u003e method in our \u003ccode\u003eSlackWebhookBot\u003c/code\u003e class.\u003c/p\u003e\n\u003cp\u003eExplore the Slack's \u003ca href=\"https://app.slack.com/block-kit-builder/\"\u003eBlock Kit Builder\u003c/a\u003e and see what you can make!\u003c/p\u003e\n\u003chr\u003e\n","markdown":"\n## tl;dr\n\n### Goal\n_To set up a Slack webhook so we can send text and simple HTML notifications to receive in a Slack channel._\n\n### Process Overview\n1. Setting up a Slack webhook URL in your Slack workspace to post to a channel\n2. Posting a notification to our webhook\n3. Creating a simple HTML parser to match the custom Slack markdown flavor\n\n### Python Dependencies\n```python\n# Python standard library\nfrom html.parser import HTMLParser\nimport logging\nimport os\nimport re\nfrom typing import Any, List, Tuple\n\n# 3rd Party\nimport requests\n```\n\n### Assumptions\nI'll assume you have a Slack account, a Slack workspace setup, Slack is installed, and you have knowledge of Python with a basic understanding of webhooks.\n\n---\n\nIf you haven't heard of it before, [Slack](https://slack.com/) is a very popular team/workplace communication tool.  In addition to direct messaging, it allows you to separate discussion into various topics or **channels** for more focused team communication.\n\nAnother great feature of Slack is that you can add 3rd party [apps](https://slack.com/apps) (or integrations) from your existing stack, or even develop your own!  I have seen this streamline my own productivity, and I personally use a number of Slack apps.\n\nTo name a few, you may want to check out the following (assuming you use these tools) which I've found a lot of value in:\n- [Sentry](https://slack.com/apps/A011MFBJEUU-sentry?tab=more_info) - for application monitoring\n- [Google Calendar](https://slack.com/apps/ADZ494LHY-google-calendar?tab=more_info) - to stay on top of my meetings schedule\n- [GitHub](https://slack.com/apps/A01BP7R4KNY-github?tab=more_info) - getting notified of pull requests and meaningful changes to important repositories\n- [Jira Cloud](https://slack.com/apps/A2RPP3NFR-jira-cloud?tab=more_info) - staying on top of changes to Jira tickets\n- [AWS Chatbot](https://slack.com/apps/A6L22LZNH-aws-chatbot?tab=more_info) - alerts from CloudWatch alarms\n\nYou can browse the [Slack app directory](https://slack.com/apps) for more integrations.\n\nHowever, not every integration is going to provide the functionality you need.  This post will focus on creating our own custom Slack app with the goal of posting simple notifications to a Slack channel.\n\nA common use case where we can apply our app will be sending notifications when any sort of user activity happens on a platform.  As a developer, being notified of when a user completes a certain task can provide a lot of transparency and understanding into the usage of our application, while also keeping a sales teams informed on relevant activity on the platform.  This is the use case we'll focus on.\n\nWe will do this by posting to a webhook hosted by Slack.  For more information on webhooks, you can check out [this article](https://zapier.com/blog/what-are-webhooks/) by Zapier.\n\nLet's get started!\n\n---\n\n## Setting up the Slack App\nOpen Slack, click **Add channels**, and create a new channel called `notifications`.  This is where our Slack app will post to once we set it up.\n\n![Create a Slack channel {priority}{1004x580}](/images/slack-webhook/create-channel.jpg)\n\nNow go to a web browser and head to https://api.slack.com/apps/.\n\nClick on **Create an App**\n\n![Create a Slack App {1004x497}](/images/slack-webhook/create-app.jpg)\n\nSelect **From scratch**\n\n![Select From Scratch {1004x497}](/images/slack-webhook/from-scratch.jpg)\n\nCreate a name for your app and select the workspace you just created your `notifications` channel in.\n\n![Choose an app name and workspace {1004x501}](/images/slack-webhook/app-and-workspace.jpg)\n\n\nThis will redirect you to the **Basic Information** tab for your app.  Here, we'll enable **Incoming Webhooks**.  As it states, this will enable us to post messages from an external source.  In this case, our platform.\n\n![Enable incoming webhooks {1004x497}](/images/slack-webhook/add-webhooks.jpg)\n\n\nTurn on **Activate Incoming Webhooks** and you will see additional details appear.  Towards the bottom, click on **Add New Webhook to Workspace**.\n\n![Add a new webhook to your workspace {1004x485}](/images/slack-webhook/add-new-webhook.jpg)\n\nYou will be redirected again to select which channel to post to.  Select the `notifications` channel that we previously created and press **Allow**.\n\n![Select a channel for your app {1004x498}](/images/slack-webhook/choose-channel.jpg)\n\n\nThis will redirect you back to your app configuration and you will see a webhook URL you can now post to.  This will also include a simple curl POST request you can test with if you'd like.  Copy the webhook URL for later, and remember to **keep it private**.  This is a public URL that anyone can post to.\n\n![Copy your webhook URL {680x506}](/images/slack-webhook/copy-url.jpg)\n\n\nYou can return to the **Basic Information** of your app settings in Slack to view more API credentials and also edit the look and feel of your new Slack bot.\n\nNow we're ready to dive into the code to communicate with our webhook!\n\n---\n\n## Communicating with our Webhook\nTo communicate with our webhook, we'll use the [`requests`](https://docs.python-requests.org/en/master/) Python library.  This is a third party library, so you'll want to have a Python virtual environment set up to handle your dependencies.  Virtual environments are out of the scope of this article, but you can read more on them [here](https://docs.python.org/3/tutorial/venv.html).\n\nInside your virtual environment, you can run the following to install the library.\n```bash\npip install requests\n```\n\nNow, we'll set up a class to communicate with our Slack endpoint.  We'll start by just sending a plain text message to Slack.\n\n```python\nimport logging\n\nimport requests\n\n\nlogger = logging.getLogger()\nlogger.setLevel(logging.INFO)\n\n\nclass SlackWebhookBot:\n    def __init__(self, webhook_url: str, timeout: int = 15):\n        \"\"\"Class to send messages to a provided Slack webhook URL.\n\n        You can read more about Slack's Incoming Webhooks here:\n            https://api.slack.com/messaging/webhooks\n        \n        Args:\n            webhook_url: The webhook URL to send a message to.  Typically\n                formatted like \"https://hooks.slack.com/services/...\".\n        \n        Kwargs:\n            timeout: Number of seconds before the request will timeout.\n                This is used to prevent a hang and is set to a default\n                value of 15 seconds.\n        \"\"\"\n        self.webhook_url = webhook_url\n        self.timeout = timeout\n        self.headers = {\n            'Content-Type': 'application/json',\n        }\n    \n\n    def send(self, message: str) -\u003e bool:\n        \"\"\"Sends a message to the webhook URL.\n\n        Per the Slack Incoming Webhook example.  The body of the request\n        (for plain text) should be formatted as follows:\n            `{\"text\": \"Hello, World!\"}`\n\n        Args:\n            message: Plain text string to send to Slack.\n\n        Returns:\n            A boolean representing if the request was successful.\n        \"\"\"\n        success = False\n        payload = {\n            'text': message,\n        }\n        try:\n            r = requests.post(\n                self.webhook_url,\n                headers=self.headers,\n                json=payload,\n                timeout=self.timeout\n            )\n        except requests.Timeout:\n            logger.error('Timeout occurred when trying to send message to Slack.')\n        except requests.RequestException as e:\n            logger.error(f'Error occurred when communicating with Slack: {e}.')\n        else:\n            success = True\n            logger.info('Successfully sent message to Slack.')\n\n        return success\n```\n\nAbove is the basic setup for communicating with the Slack webhook.  We can run a quick test by moving this code to a script and adding the following.\n```python\nimport os\n\nwebhook_url = os.environ.get('SLACK_WEBHOOK_URL')\nslack = SlackWebhookBot(webhook_url)\nslack.send('Hello, world!')\n```\n\nMake sure to set your Slack webhook URL to the `SLACK_WEBHOOK_URL` environment variable, and make sure you're in your virtual environment with the `requests` package installed before running the script.  This can be done on MacOS with the following.\n```bash\nexport SLACK_WEBHOOK_URL=https://hooks.slack.com/services/...\npython slack_webhook.py\n```\n\nWhen you run this, you should see a message from you Slack bot appear in the `notifications` channel!\n\n![Hello world message in Slack {1004x675}](/images/slack-webhook/slack-first-message.jpg)\n\n\nFor our notifications to be more helpful, we may want to add links or other formatting.  To do this, we will write our notifications with HTML tags, and then parse these tags and convert them to the [Slack flavored Markdown](https://api.slack.com/reference/surfaces/formatting) called `mrkdwn`.\n\n---\n\n## Adding a simple HTML parser to our class\nFrom the [Slack formatting guide](https://api.slack.com/reference/surfaces/formatting) for messages, we can see all of the ways to format text in our messages.  For our purposes, we will focus on a primary list.\n\n- Making text \u003ci\u003e`_italicized_`\u003c/i\u003e (`\u003ci\u003e`)\n- Making text \u003cb\u003e`*bold*`\u003c/b\u003e (`\u003cb\u003e`)\n- Striking through ~\u003cstrike\u003e`text`\u003c/strike\u003e~ (`\u003cstrike\u003e`)\n- Adding line breaks (`\u003cbr\u003e`)\n- Adding `one-line code blocks` using the backtick character (`\u003ccode\u003e`)\n- Adding unordered lists (line broken dashes) (`\u003cul\u003e\u003cli\u003e`)\n- Adding external links `\u003c[external link]|[display text]\u003e` (`\u003ca\u003e`)\n\nAlso note that the Slack documentation says that [certain characters need to be escaped](https://api.slack.com/reference/surfaces/formatting#escaping).\n\nThere are a few more styles that could be implemented, but we'll focus on just this list for this post.\n\nTo do this, we will utilize the [`html`](https://docs.python.org/3/library/html.html) module in the Python standard library to parse HTML tags, attributes, and values.\n\nLet's write a class (we need to inherit functions for the `HTMLParser` class) where we will parse all of the tags and attributes, and escape the message text when needed.  The idea here is that we can construct a string from scratch and for each tag we care about we can \"replace\" the HTML tags with the relevant mrkdwn syntax.\n\n```python\nfrom html.parser import HTMLParser\nimport re\nfrom typing import Any, List, Tuple\n\n\nclass SlackHTMLParser(HTMLParser):\n    def __init__(self, *args, **kwargs):\n        \"\"\"Escapes and converts an HTML string to Slack flavored\n        Markdown (mrkdwn).\n\n        More about Slack's Markdown Flavor (mrkdwn) can be seen here:\n            https://api.slack.com/reference/surfaces/formatting\n        \n        Call using `SlackHTMLParser(message_body).parse()`.\n        \"\"\"\n        super().__init__(*args, **kwargs)\n        self.slack_message = ''\n        self.ignore_tag = False  # Used to skip tags we don't care about\n        self.line_break = '::LINE::BREAK::'  # Unique sequence for swapping a \u003cbr\u003e\n\n\n    def handle_starttag(self, tag: str, attrs: List[Tuple[str, Any]]):\n        \"\"\"Called when the opening of a tag is encountered.\n\n        The idea here is to swap out the tag with the respective mrkdwn\n        symbol.\n\n        Args:\n            tag: Lowercase name of the HTML tag.  E.G. `br` or `i`.\n            attrs: List of tuples with the tuple having the following form:\n                (attribute name, value).  E.G. ('href', 'www.example.com').\n        \"\"\"\n        if tag in ['i', 'em']:\n            self.slack_message += '_'\n        elif tag in ['b', 'strong']:\n            self.slack_message += '*'\n        elif tag == 'strike':\n            self.slack_message += '~'\n        elif tag in ['br', 'p', 'ul']:\n            self.slack_message += self.line_break\n        elif tag == 'li':\n            self.slack_message += f'{self.line_break}- '\n        elif tag == 'code':\n            self.slack_message += '`'\n        elif tag == 'a':\n            href = [x[1] for x in attrs if x[0] == 'href']\n            if len(href) \u003e 0:\n                self.slack_message += f'\u003c{href[0]}|'\n        else:\n            self.ignore_tag = True\n\n\n    def handle_data(self, data: str):\n        \"\"\"Handles the data within a tag.\n\n        This is called after `handle_starttag` and before `handle_endtag`.\n\n        We will also escape the following text per Slack's documentation:\n        - '\u0026' -\u003e '\u0026amp;'\n        - '\u003c' -\u003e '\u0026lt;'\n        - '\u003e' -\u003e '\u0026gt;'\n\n        Args:\n            data: The data/string within the HTML tag.\n        \"\"\"\n        if not self.ignore_tag:\n            self.slack_message += data\\\n                .replace('\u0026', '\u0026amp;')\\\n                .replace('\u003c', '\u0026lt;')\\\n                .replace('\u003e', '\u0026gt;')\n\n\n    def handle_endtag(self, tag: str):\n        \"\"\"Called when the closing of a tag is encountered.\n\n        The idea here is to swap out the tag with the respective mrkdwn\n        symbol.  This is basically the same as the handle_starttag.\n\n        Args:\n            tag: Lowercase name of the HTML tag.  E.G. `br` or `i`.\n        \"\"\"\n        if tag in ['i', 'em']:\n            self.slack_message += '_'\n        elif tag in ['b', 'strong']:\n            self.slack_message += '*'\n        elif tag == 'strike':\n            self.slack_message += '~'\n        elif tag == 'p':\n            self.slack_message += self.line_break\n        elif tag == 'code':\n            self.slack_message += '`'\n        elif tag == 'a':\n            self.slack_message += '\u003e'\n        \n        self.ignore_tag = False\n\n\n    def parse(self, html_string: str) -\u003e str:\n        \"\"\"Parses a given HTML string and applies simple formatting.\n        \n        Note that we need to apply the line break replacing here\n        instead of with the handle tag methods.\n\n        Args:\n            html_string: The HTML string to convert to Slack mrkdwn.\n\n        Returns:\n            A formatted Slack mrkdwn string.\n        \"\"\"\n        self.feed(html_string)\n        return re.sub(\n            r'^(\\n)+',  # Remove the leading line breaks\n            '',\n            ' '.join(self.slack_message.split()).replace(self.line_break, '\\n')\n        )\n```\n\nWe can test our class out with the following code.\n\n```python\nhtml_string = '''\n    \u003cp\u003e\n        Here \u003ci\u003eis\u003c/i\u003e a \u003cstrike\u003eparagraph\u003c/strike\u003e with a \u003cb\u003elot\u003c/b\u003e of formatting.\n    \u003c/p\u003e\n    \u003cbr\u003e\n    \u003ccode\u003eCode sample\u003c/code\u003e \u0026 testing escape.\n    \u003cul\u003e\n        \u003cli\u003e\n            \u003ca href=\"https://www.google.com\"\u003eGoogle\u003c/a\u003e\n        \u003c/li\u003e\n        \u003cli\u003e\n            \u003ca href=\"https://www.amazon.com\"\u003eAmazon\u003c/a\u003e\n        \u003c/li\u003e\n    \u003c/ul\u003e\n'''\nparser = SlackHTMLParser()\nslack_message = parser.parse(html_string)\nprint(slack_message)\n```\n\nNow we can test our formatter in an actual Slack message!  Import your formatter class or add it to your existing code so you're able to do the following.\n\n```python\nhtml_string = '''\n    \u003cp\u003e\n        Here \u003ci\u003eis\u003c/i\u003e a \u003cstrike\u003eparagraph\u003c/strike\u003e with a \u003cb\u003elot\u003c/b\u003e of formatting.\n    \u003c/p\u003e\n    \u003cbr\u003e\n    \u003ccode\u003eCode sample\u003c/code\u003e \u0026 testing escape.\n    \u003cul\u003e\n        \u003cli\u003e\n            \u003ca href=\"https://www.google.com\"\u003eGoogle\u003c/a\u003e\n        \u003c/li\u003e\n        \u003cli\u003e\n            \u003ca href=\"https://www.amazon.com\"\u003eAmazon\u003c/a\u003e\n        \u003c/li\u003e\n    \u003c/ul\u003e\n'''\nwebhook_url = os.environ.get('SLACK_WEBHOOK_URL')\nparser = SlackHTMLParser()\nslack_message = parser.parse(html_string)\nslack = SlackWebhookBot(webhook_url)\nslack.send(slack_message)\n```\n\nYou should see the following message in your notifications channel.\n\n![Second message in Slack {680x140}](/images/slack-webhook/slack-format-message.jpg)\n\nLooks pretty good!  _Note that you can still send plain text messages, you don't need to use HTML._\n\nFor some final adjustments, you may have noticed that the message preview on the notification that popped up showed the actual `mrkdwn` characters as opposed to a formatted notification.  This looks a little sloppy, so let's make a new notification title that is similar to an email subject line.\n\nWe will briefly look at the basics of Slack's [Block Kit](https://api.slack.com/block-kit), which is a powerful way to add lots of customization to your Slack messages.  You can also explore Block Kit with Slack's [Block Kit Builder](https://app.slack.com/block-kit-builder/) which provides a preview of your Slack message.\n\nWithout diving too much into the details on the Block Kit, let's update our `SlackWebhookBot` class and add a method that adds a title block and a body block for our message.  Our subject line will appear in the notification itself, and also in the actual Slack message.\n\n```python\n# Add the `Dict` typing import to the existing typing imports\nfrom typing import Dict\n\ndef format_message(self, subject: str, body: str) -\u003e Dict:\n    \"\"\"Formats the subject and message body into Slack blocks.\n\n    Args:\n        subject: Subject that will appear on the notification popup.\n        body: The full message body.\n\n    Returns:\n        A dictionary payload with Slack block formatting.\n    \"\"\"\n    return {\n        'text': subject,\n        'blocks': [\n            {\n                'type': 'section',\n                'text': {\n                    'type': 'mrkdwn',\n                    'text': f'*{subject}*',\n                },\n            },\n            {\n                'type': 'section',\n                'text': {\n                    'type': 'mrkdwn',\n                    'text': body,\n                },\n            },\n        ],\n    }\n```\n\nNow we can tweak our `send` method to format a new message and accept a subject string as a Kwarg.\n\n```python\ndef send(self, message: str, subject: str = 'New message!') -\u003e bool:\n    \"\"\"Sends a formatted message to the webhook URL.\n\n    Args:\n        message: Plain text string to send to Slack.\n\n    Kwargs:\n        subject: The subject of the message that will appear in the notification\n            preview.\n\n    Returns:\n        A boolean representing if the request was successful.\n    \"\"\"\n    success = False\n    payload = self.format_message(subject, message)\n    try:\n        r = requests.post(\n            self.webhook_url,\n            headers=self.headers,\n            json=payload,\n            timeout=self.timeout\n        )\n    except requests.Timeout:\n        logger.error('Timeout occurred when trying to send message to Slack.')\n    except requests.RequestException as e:\n        logger.error(f'Error occurred when communicating with Slack: {e}.')\n    else:\n        success = True\n        logger.info('Successfully sent message to Slack.')\n\n    return success\n```\n\nAnd we can test our notification with a new subject line.\n\n```python\nhtml_string = '''\n    \u003cp\u003e\n        Here \u003ci\u003eis\u003c/i\u003e a \u003cstrike\u003eparagraph\u003c/strike\u003e with a \u003cb\u003elot\u003c/b\u003e of formatting.\n    \u003c/p\u003e\n    \u003cbr\u003e\n    \u003ccode\u003eCode sample\u003c/code\u003e \u0026 testing escape.\n    \u003cul\u003e\n        \u003cli\u003e\n            \u003ca href=\"https://www.google.com\"\u003eGoogle\u003c/a\u003e\n        \u003c/li\u003e\n        \u003cli\u003e\n            \u003ca href=\"https://www.amazon.com\"\u003eAmazon\u003c/a\u003e\n        \u003c/li\u003e\n    \u003c/ul\u003e\n'''\nwebhook_url = os.environ.get('SLACK_WEBHOOK_URL')\nparser = SlackHTMLParser()\nslack_message = parser.parse(html_string)\nslack = SlackWebhookBot(webhook_url)\nslack.send(slack_message, subject='You\\'ve completed the tutorial!')\n```\n\nYou should see a notification appear with the following preview\n\n![Slack notification {453x101}](/images/slack-webhook/slack-popup.jpg)\n\n\nand the following message in your channel.\n\n![Last message in Slack {680x159}](/images/slack-webhook/slack-last-message.jpg)\n\n\nWe have a custom Slack notification app!  You can place the `send` message calls all across your applications with related messages and now you can have a better pulse on user activity that developers and any other employees/stakeholders can easily access.\n\n---\n\nFor those wanting additional challenges or to continue developing their custom app, Slack has added a lot of really cool tools to the Block Kit.  There are a ton of really cool possibilities that can be added on by updating the `format_message` method in our `SlackWebhookBot` class.\n\nExplore the Slack's [Block Kit Builder](https://app.slack.com/block-kit-builder/) and see what you can make!\n\n---\n","title":"Setting up a Slack webhook for simple notifications","date":"2021-07-11","tags":["python","slack","webhook","api"],"description":"Setting up a Slack webhook to send plain text or simple HTML notifications to a Slack channel."},{"id":"visualizing-your-linkedin-connections","contentHtml":"\u003ch2\u003etl;dr\u003c/h2\u003e\n\u003ch3\u003eGoal\u003c/h3\u003e\n\u003cp\u003e\u003cem\u003eTo understand and visualize the companies within my directly connected network on LinkedIn\u003c/em\u003e\u003c/p\u003e\n\u003ch3\u003eProcess overview\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eLinkedIn data sources\u003c/strong\u003e - retrieving LinkedIn Network data from a \"Get a copy of your data\" CSV export\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eDiving into the data\u003c/strong\u003e - exploring, cleaning, and aggregating the data with \u003ca href=\"https://pandas.pydata.org/\"\u003e\u003ccode\u003ePandas\u003c/code\u003e\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eCreating the network\u003c/strong\u003e - creating a network graph using \u003ca href=\"https://networkx.org/\"\u003e\u003ccode\u003eNetworkX\u003c/code\u003e\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eVisualization\u003c/strong\u003e - visualizing the network with \u003ca href=\"https://pyvis.readthedocs.io/en/latest/\"\u003e\u003ccode\u003epyvis\u003c/code\u003e\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eImproving the output\u003c/strong\u003e - cleaning up the network graph with additional filtering\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3\u003eResults\u003c/h3\u003e\n\u003cp\u003e\u003cem\u003eHover over the nodes for more details\u003c/em\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"/network/first-nx-graph.html\"\u003eThe first network graph\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/network/second-nx-graph.html\"\u003eThe second (more specific) network graph\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003ePython dependencies\u003c/h3\u003e\n\u003cpre\u003e\u003ccode\u003e# Python standard library\nfrom difflib import get_close_matches\n\n# 3rd party\nimport networkx as nx\nimport pandas as pd\nfrom pyvis.network import Network\n\u003c/code\u003e\u003c/pre\u003e\n\u003chr\u003e\n\u003cp\u003eRecently, I was exploring \u003ca href=\"https://www.linkedin.com/in/bradley-schoeneweis/\"\u003emy LinkedIn\u003c/a\u003e network to see what some of my colleagues from high school and undergrad are currently up to.\u003c/p\u003e\n\u003cp\u003eAs I was scrolling through the connections page, I noticed LinkedIn gives you options to filter and searching with ease, but it doesn't really provide tools to learn about your network as a whole.\u003c/p\u003e\n\u003cp\u003eSo I decided to see if there was an easy way to export my network data to see what I could do with a few hours of exploring the data.\u003c/p\u003e\n\u003ch2\u003eLinkedIn data sources\u003c/h2\u003e\n\u003cp\u003eMy first thought was to checkout out the \u003ca href=\"https://www.linkedin.com/developers/\"\u003eLinkedIn's Developer API\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eSomething I do fairly frequently at my current job is integrating various 3rd-party REST APIs into our platform, so I wanted to see all the functionality and possibilities that this API would provide.\u003c/p\u003e\n\u003cp\u003eAfter reading through some documentation, I decided this wasn't a direction I wanted to pursue. Most of their developer products require approval, so I decided to look into other options.\u003c/p\u003e\n\u003cp\u003eAnother thought I had was to write a quick scraping script to pull down the HTML of my connections page and parse out names and companies, but I assumed there had to be a more simple way to get this data.\u003c/p\u003e\n\u003cp\u003eFinally, after a bit of research, I found that there are various \"Get a copy of your data\" reports that you can run within LinkedIn.  In order to get to these reports, you can do the following:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eOn the homepage toolbar, click the \u003cstrong\u003eMe\u003c/strong\u003e dropdown\u003c/li\u003e\n\u003cli\u003eUnder the \u003cem\u003eAccount\u003c/em\u003e section, click \u003cstrong\u003eSettings \u0026#x26; Privacy\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003eClick on \u003cstrong\u003eGet a copy of your data\u003c/strong\u003e, and you can view the various reports\u003c/li\u003e\n\u003cli\u003eSelect the reports you're interested in, for this, I just checked \u003cstrong\u003eConnections\u003c/strong\u003e\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eAfter requesting the report, it should only take a few minutes before you get an email saying your report is ready for export.\u003c/p\u003e\n\u003ch2\u003eDiving into the data\u003c/h2\u003e\n\u003cp\u003eTo reiterate our goal, we want to get a broad understanding of the companies within the first layer of our network (direct connections). Now, let's load up Python and learn more about this data in this CSV.\u003c/p\u003e\n\u003ch3\u003eReading in the data\u003c/h3\u003e\n\u003cp\u003eOnce the CSV is downloaded, we can open it up with Pandas and take a look (\u003cem\u003eoutput will be commented below\u003c/em\u003e).\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eimport pandas as pd\n\n# We want to skip the first three rows because of Notes at the top\ndf = pd.read_csv('Connections.csv', skiprows=3)\n\ndf.columns\n# ['First Name', 'Last Name', 'Email Address', 'Company', 'Position', 'Connected On',]\n\ndf.info()\n\"\"\"\n\u0026#x3C;class 'pandas.core.frame.DataFrame'\u003e\nRangeIndex: 376 entries, 0 to 375\nData columns (total 6 columns):\n #   Column         Non-Null Count  Dtype \n---  ------         --------------  ----- \n 0   First Name     375 non-null    object\n 1   Last Name      375 non-null    object\n 2   Email Address  1 non-null      object\n 3   Company        371 non-null    object\n 4   Position       371 non-null    object\n 5   Connected On   376 non-null    object\ndtypes: object(6)\nmemory usage: 17.8+ KB\n\"\"\"\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eI won't post the name's of any individuals or full rows to respect the privacy of my connections, but when I searched through the my Connections CSV, I noticed a few initial patterns that would help clean up the data.\u003c/p\u003e\n\u003ch3\u003eCleaning up the data\u003c/h3\u003e\n\u003cp\u003eAt first glance, the first thing I notice is connections who don't list a current company, so let's get rid of those.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003edf = df[df['Company'].notna()].sort_values(by='Company')\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eAfter sorting, another thing I noticed was that some of these company names belong to the same company, but the individuals wrote them differently.\u003c/p\u003e\n\u003cp\u003eAn example of this is \u003ccode\u003e'IBM Global Solution Center'\u003c/code\u003e and \u003ccode\u003e'IBM'\u003c/code\u003e; for our purposes, these should both be classified as \u003ccode\u003eIBM\u003c/code\u003e.\u003c/p\u003e\n\u003cp\u003eLet's run through a fuzzy match run using \u003ca href=\"https://docs.python.org/3/library/difflib.html#difflib.get_close_matches\"\u003edifflib's \u003ccode\u003eget_close_matches\u003c/code\u003e\u003c/a\u003e to try and bucket some of these similar company names.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003efrom difflib import get_close_matches\n\ncompanies = df['Company'].drop_duplicates()\n\n# cutoff=0.7 is a similarity ranking, and n=10 just takes the top 10 values\nsimilar_companies = {x: get_close_matches(x, companies, n=10, cutoff=0.7)\n                     for x in companies}\n\n# We are only interested in the entries that had another match\nsimilar_companies = {x: [name for name in y if name != x]\n                     for x, y in similar_companies.items() if len(y) \u003e 1}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eNow, this solution is not perfect, but it will help draw out some similar companies. You should still run a manual inspection of the data (the IBM example I gave above is one that doesn't show up in the fuzzy match results).\u003c/p\u003e\n\u003cp\u003eBased upon the results, let's group together some of the companies that had matches.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003edf['Company'] = df['Company'].replace({\n    'KPMG US': similar_companies['KPMG US'],\n    'Self-employed': similar_companies['Self-employed'],\n    'IBM Global Solution Center': 'IBM',\n})\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe next thing you may have noticed is that in our \u003ccode\u003esimilar_companies\u003c/code\u003e dictionary, we cleaned up a \u003ccode\u003eSelf-employed\u003c/code\u003e entry.\u003c/p\u003e\n\u003cp\u003eTo stay aligned with our goal, let's drop these entries, as well as your current company.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ecompanies_to_drop = ['self employed', 'your current company']\ndf = df[~df['Company'].str.lower().isin(companies_to_drop)]\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003eAggregating the data\u003c/h3\u003e\n\u003cp\u003eNow that our data is cleaned up a bit, let's aggregate and sum the number of connections for each of the companies.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003edf_company_counts = df['Company'].value_counts().reset_index()\ndf_company_counts.columns = ['Company', 'Count']  # For ease of understanding\ndf_company_counts = df_company_counts.sort_values(by='Count', ascending=False)\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2\u003eCreating the network\u003c/h2\u003e\n\u003cp\u003eWe have the numbers we want for each company, now let's jump into using \u003ccode\u003eNetworkX\u003c/code\u003e to recreate a network.\u003c/p\u003e\n\u003cp\u003eThe first step will be to initialize our graph, and add yourself as the central node, as it is your network.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eimport networkx as nx\n\nG = nx.Graph()\nG.add_node('Me')\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThen, we'll loop through our \u003ccode\u003edf_company_counts\u003c/code\u003e DataFrame and add each company as a node.\u003c/p\u003e\n\u003cp\u003e\u003cem\u003eYou'll notice some HTML tags in the title below, this is just to make it more readable for later\u003c/em\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003efor _, row in df_company_counts.iterrows():\n\t# The title will be for more information later on\n    title = '\u0026#x3C;b\u003e{0}\u0026#x3C;/b\u003e ({1})\u0026#x3C;br\u003e\u0026#x3C;hr\u003ePositions:\u0026#x3C;br\u003e'.format(row['Company'],\n    \t\t\t\t\t\t\t\t\t\t\t\t\t\trow['Count'])\n\n    # In addition to the full company name, let's add each position in a\n    # list to see the roles our connections have at these companies\n    position_list = ''.join('\u0026#x3C;li\u003e{}\u0026#x3C;/li\u003e'.format(x)\n    \t\t\t\t\t\tfor x in df[df['Company'] == row['Company']]['Position'])\n    title += '\u0026#x3C;ul\u003e{0}\u0026#x3C;/ul\u003e'.format(position_list)\n\n    # For ease of viewing, limit company names to 15 letters\n    node_name = row['Company']\n    if len(node_name) \u003e 15:\n        node_name = node_name[:15] + '...'\n\n    # Add the node and an edge connection ourself to the new node\n    G.add_node(node_name, weight=row['Count'], size=row['Count'] * 2, title=title)\n    G.add_edge('Me', node_name)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eAnd just like that, we've created our network of connections.\u003c/p\u003e\n\u003ch2\u003eVisualization\u003c/h2\u003e\n\u003cp\u003eOur network graph is created, so let's get into visualizing the network.\u003c/p\u003e\n\u003cp\u003eThere are a few options for visualizing networks including \u003ccode\u003ematplotlib.pyplot\u003c/code\u003e, but I found that \u003ccode\u003epyvis\u003c/code\u003e was the easiest to use for several reasons:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003epyvis\u003c/code\u003e generates an HTML file\u003c/li\u003e\n\u003cli\u003eCustomization is made very easy\u003c/li\u003e\n\u003cli\u003eThe graph is interactive by default\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eLet's look into generating this HTML file.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003efrom pyvis.network import Network\n\nnt = Network('100%', '100%', bgcolor='#222222', font_color='white')\nnt.from_nx(G)\nnt.repulsion()  # Spaces out the nodes\nnt.show('nx.html')\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eAnd it's that simple! We specify a width and height, optional styling attributes, and then we can generate the network graph visual straight from what we created with NetworkX.\u003c/p\u003e\n\u003cp\u003eNow we can see \u003ca href=\"/network/first-nx-graph.html\"\u003ethe network we generated\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eYou can hover over each node to see the total number of connections that work at the respective company, and below is a list of the positions held by your connections.\u003c/p\u003e\n\u003cp\u003eAs you can see, this is a bit hard to read into since there are a lot of nodes. Try and imagine reading this with +1,000 connections.\u003c/p\u003e\n\u003ch2\u003eImproving the output\u003c/h2\u003e\n\u003cp\u003eThere are a few ways that our network could be narrowed down.\u003c/p\u003e\n\u003cp\u003eBeing a \u003cem\u003eSoftware Developer\u003c/em\u003e, the thought that first occurred to me was to try and dial in on tech-related companies through known positions titles.\u003c/p\u003e\n\u003cp\u003eTo do this, I thought of a list of buzzwords/common job titles that I've seen across LinkedIn, and filtered down the initial DataFrame.\u003c/p\u003e\n\u003cp\u003eThen, we go through the same process we did in previous sections of generating and displaying the graph.\u003c/p\u003e\n\u003cp\u003e\u003cem\u003eAgain, this is not perfect, but it's a good starting point.\u003c/em\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e# Filter down from a list of popular tech positions\npositions = [\n    'developer', 'engineer', 'ai', 'analytics', 'software', 'cloud', 'cto',\n    'sde', 'sre', 'saas', 'product', 'engineering', 'scientist', 'data',\n]\ndf = df[df['Position'].str.contains('|'.join(positions), case=False)]\ndf_company_counts = df['Company'].value_counts().reset_index()\ndf_company_counts.columns = ['Company', 'Count']\ndf_company_counts = df_company_counts.sort_values(by='Count', ascending=False)\n\n# Re-initialize the graph and add the nodes/edges again\nG = nx.Graph()\nG.add_node('Me')\n\nfor _, row in df_company_counts.iterrows():\n    title = '\u0026#x3C;b\u003e{0}\u0026#x3C;/b\u003e ({1})\u0026#x3C;br\u003e\u0026#x3C;hr\u003ePositions:\u0026#x3C;br\u003e'.format(row['Company'], row['Count'])\n    position_list = ''.join('\u0026#x3C;li\u003e{}\u0026#x3C;/li\u003e'.format(x)\n    \t\t\t\t\t\tfor x in df[df['Company'] == row['Company']]['Position'])\n    title += '\u0026#x3C;ul\u003e{0}\u0026#x3C;/ul\u003e'.format(position_list)\n    node_name = row['Company']\n    if len(node_name) \u003e 15:\n        node_name = node_name[:15] + '...'\n\n    # Since there are less nodes, let's increase the sizes\n    G.add_node(node_name, weight=row['Count'], size=row['Count'] * 5, title=title)\n    G.add_edge('Me', node_name)\n\n# Generate the visualization\nnt = Network('100%', '100%', bgcolor='#222222', font_color='white')\nnt.from_nx(G)\nnt.repulsion()\nnt.show('nx.html')\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eNow, let's look at the \u003ca href=\"/network/second-nx-graph.html\"\u003eupdated results\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eMuch better! This is more readable and easier to interact with.\u003c/p\u003e\n\u003cp\u003eAnd just like that, we achieved our goal of gaining a broader understanding of the companies in our LinkedIn network.\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003e\u003cstrong\u003e\u003cem\u003ePossible improvements for those interested\u003c/em\u003e\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eScraping the profile location of each of your connections to segment by location\u003c/li\u003e\n\u003cli\u003eCompiling a list of companies you'd like to work for/are interested in and creating a filtering system\u003c/li\u003e\n\u003cli\u003eResearching salary data for positions and gathering average pay by company\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n","markdown":"\n## tl;dr\n\n### Goal\n_To understand and visualize the companies within my directly connected network on LinkedIn_\n\n### Process overview\n1. **LinkedIn data sources** - retrieving LinkedIn Network data from a \"Get a copy of your data\" CSV export\n2. **Diving into the data** - exploring, cleaning, and aggregating the data with [`Pandas`](https://pandas.pydata.org/)\n3. **Creating the network** - creating a network graph using [`NetworkX`](https://networkx.org/)\n4. **Visualization** - visualizing the network with [`pyvis`](https://pyvis.readthedocs.io/en/latest/)\n5. **Improving the output** - cleaning up the network graph with additional filtering\n\n### Results\n_Hover over the nodes for more details_\n- [The first network graph](/network/first-nx-graph.html)\n- [The second (more specific) network graph](/network/second-nx-graph.html)\n\n### Python dependencies\n```python\n# Python standard library\nfrom difflib import get_close_matches\n\n# 3rd party\nimport networkx as nx\nimport pandas as pd\nfrom pyvis.network import Network\n```\n\n---\n\nRecently, I was exploring [my LinkedIn](https://www.linkedin.com/in/bradley-schoeneweis/) network to see what some of my colleagues from high school and undergrad are currently up to.\n\nAs I was scrolling through the connections page, I noticed LinkedIn gives you options to filter and searching with ease, but it doesn't really provide tools to learn about your network as a whole.\n\nSo I decided to see if there was an easy way to export my network data to see what I could do with a few hours of exploring the data.\n\n\n## LinkedIn data sources\n\nMy first thought was to checkout out the [LinkedIn's Developer API](https://www.linkedin.com/developers/).\n\nSomething I do fairly frequently at my current job is integrating various 3rd-party REST APIs into our platform, so I wanted to see all the functionality and possibilities that this API would provide.\n\nAfter reading through some documentation, I decided this wasn't a direction I wanted to pursue. Most of their developer products require approval, so I decided to look into other options.\n\nAnother thought I had was to write a quick scraping script to pull down the HTML of my connections page and parse out names and companies, but I assumed there had to be a more simple way to get this data.\n\nFinally, after a bit of research, I found that there are various \"Get a copy of your data\" reports that you can run within LinkedIn.  In order to get to these reports, you can do the following:\n1. On the homepage toolbar, click the **Me** dropdown\n2. Under the _Account_ section, click **Settings \u0026 Privacy**\n3. Click on **Get a copy of your data**, and you can view the various reports\n4. Select the reports you're interested in, for this, I just checked **Connections**\n\nAfter requesting the report, it should only take a few minutes before you get an email saying your report is ready for export.\n\n\n## Diving into the data\n\nTo reiterate our goal, we want to get a broad understanding of the companies within the first layer of our network (direct connections). Now, let's load up Python and learn more about this data in this CSV.\n\n### Reading in the data\nOnce the CSV is downloaded, we can open it up with Pandas and take a look (_output will be commented below_).\n\n```python\nimport pandas as pd\n\n# We want to skip the first three rows because of Notes at the top\ndf = pd.read_csv('Connections.csv', skiprows=3)\n\ndf.columns\n# ['First Name', 'Last Name', 'Email Address', 'Company', 'Position', 'Connected On',]\n\ndf.info()\n\"\"\"\n\u003cclass 'pandas.core.frame.DataFrame'\u003e\nRangeIndex: 376 entries, 0 to 375\nData columns (total 6 columns):\n #   Column         Non-Null Count  Dtype \n---  ------         --------------  ----- \n 0   First Name     375 non-null    object\n 1   Last Name      375 non-null    object\n 2   Email Address  1 non-null      object\n 3   Company        371 non-null    object\n 4   Position       371 non-null    object\n 5   Connected On   376 non-null    object\ndtypes: object(6)\nmemory usage: 17.8+ KB\n\"\"\"\n```\n\nI won't post the name's of any individuals or full rows to respect the privacy of my connections, but when I searched through the my Connections CSV, I noticed a few initial patterns that would help clean up the data.\n\n### Cleaning up the data\n\nAt first glance, the first thing I notice is connections who don't list a current company, so let's get rid of those.\n\n```python\ndf = df[df['Company'].notna()].sort_values(by='Company')\n```\n\nAfter sorting, another thing I noticed was that some of these company names belong to the same company, but the individuals wrote them differently.\n\nAn example of this is `'IBM Global Solution Center'` and `'IBM'`; for our purposes, these should both be classified as `IBM`.\n\nLet's run through a fuzzy match run using [difflib's `get_close_matches`](https://docs.python.org/3/library/difflib.html#difflib.get_close_matches) to try and bucket some of these similar company names.\n```python\nfrom difflib import get_close_matches\n\ncompanies = df['Company'].drop_duplicates()\n\n# cutoff=0.7 is a similarity ranking, and n=10 just takes the top 10 values\nsimilar_companies = {x: get_close_matches(x, companies, n=10, cutoff=0.7)\n                     for x in companies}\n\n# We are only interested in the entries that had another match\nsimilar_companies = {x: [name for name in y if name != x]\n                     for x, y in similar_companies.items() if len(y) \u003e 1}\n```\n\nNow, this solution is not perfect, but it will help draw out some similar companies. You should still run a manual inspection of the data (the IBM example I gave above is one that doesn't show up in the fuzzy match results).\n\nBased upon the results, let's group together some of the companies that had matches.\n```python\ndf['Company'] = df['Company'].replace({\n    'KPMG US': similar_companies['KPMG US'],\n    'Self-employed': similar_companies['Self-employed'],\n    'IBM Global Solution Center': 'IBM',\n})\n```\n\nThe next thing you may have noticed is that in our `similar_companies` dictionary, we cleaned up a `Self-employed` entry.\n\nTo stay aligned with our goal, let's drop these entries, as well as your current company.\n```python\ncompanies_to_drop = ['self employed', 'your current company']\ndf = df[~df['Company'].str.lower().isin(companies_to_drop)]\n```\n\n### Aggregating the data\nNow that our data is cleaned up a bit, let's aggregate and sum the number of connections for each of the companies.\n\n```python\ndf_company_counts = df['Company'].value_counts().reset_index()\ndf_company_counts.columns = ['Company', 'Count']  # For ease of understanding\ndf_company_counts = df_company_counts.sort_values(by='Count', ascending=False)\n```\n\n## Creating the network\n\nWe have the numbers we want for each company, now let's jump into using `NetworkX` to recreate a network.\n\nThe first step will be to initialize our graph, and add yourself as the central node, as it is your network.\n\n```python\nimport networkx as nx\n\nG = nx.Graph()\nG.add_node('Me')\n```\n\nThen, we'll loop through our `df_company_counts` DataFrame and add each company as a node.\n\n_You'll notice some HTML tags in the title below, this is just to make it more readable for later_\n```python\nfor _, row in df_company_counts.iterrows():\n\t# The title will be for more information later on\n    title = '\u003cb\u003e{0}\u003c/b\u003e ({1})\u003cbr\u003e\u003chr\u003ePositions:\u003cbr\u003e'.format(row['Company'],\n    \t\t\t\t\t\t\t\t\t\t\t\t\t\trow['Count'])\n\n    # In addition to the full company name, let's add each position in a\n    # list to see the roles our connections have at these companies\n    position_list = ''.join('\u003cli\u003e{}\u003c/li\u003e'.format(x)\n    \t\t\t\t\t\tfor x in df[df['Company'] == row['Company']]['Position'])\n    title += '\u003cul\u003e{0}\u003c/ul\u003e'.format(position_list)\n\n    # For ease of viewing, limit company names to 15 letters\n    node_name = row['Company']\n    if len(node_name) \u003e 15:\n        node_name = node_name[:15] + '...'\n\n    # Add the node and an edge connection ourself to the new node\n    G.add_node(node_name, weight=row['Count'], size=row['Count'] * 2, title=title)\n    G.add_edge('Me', node_name)\n```\n\nAnd just like that, we've created our network of connections.\n\n\n## Visualization\n\nOur network graph is created, so let's get into visualizing the network.\n\nThere are a few options for visualizing networks including `matplotlib.pyplot`, but I found that `pyvis` was the easiest to use for several reasons:\n- `pyvis` generates an HTML file\n- Customization is made very easy\n- The graph is interactive by default\n\nLet's look into generating this HTML file.\n```python\nfrom pyvis.network import Network\n\nnt = Network('100%', '100%', bgcolor='#222222', font_color='white')\nnt.from_nx(G)\nnt.repulsion()  # Spaces out the nodes\nnt.show('nx.html')\n```\n\nAnd it's that simple! We specify a width and height, optional styling attributes, and then we can generate the network graph visual straight from what we created with NetworkX.\n\nNow we can see [the network we generated](/network/first-nx-graph.html).\n\nYou can hover over each node to see the total number of connections that work at the respective company, and below is a list of the positions held by your connections.\n\nAs you can see, this is a bit hard to read into since there are a lot of nodes. Try and imagine reading this with +1,000 connections.\n\n## Improving the output\n\nThere are a few ways that our network could be narrowed down.\n\nBeing a _Software Developer_, the thought that first occurred to me was to try and dial in on tech-related companies through known positions titles.\n\nTo do this, I thought of a list of buzzwords/common job titles that I've seen across LinkedIn, and filtered down the initial DataFrame.\n\nThen, we go through the same process we did in previous sections of generating and displaying the graph.\n\n_Again, this is not perfect, but it's a good starting point._\n```python\n# Filter down from a list of popular tech positions\npositions = [\n    'developer', 'engineer', 'ai', 'analytics', 'software', 'cloud', 'cto',\n    'sde', 'sre', 'saas', 'product', 'engineering', 'scientist', 'data',\n]\ndf = df[df['Position'].str.contains('|'.join(positions), case=False)]\ndf_company_counts = df['Company'].value_counts().reset_index()\ndf_company_counts.columns = ['Company', 'Count']\ndf_company_counts = df_company_counts.sort_values(by='Count', ascending=False)\n\n# Re-initialize the graph and add the nodes/edges again\nG = nx.Graph()\nG.add_node('Me')\n\nfor _, row in df_company_counts.iterrows():\n    title = '\u003cb\u003e{0}\u003c/b\u003e ({1})\u003cbr\u003e\u003chr\u003ePositions:\u003cbr\u003e'.format(row['Company'], row['Count'])\n    position_list = ''.join('\u003cli\u003e{}\u003c/li\u003e'.format(x)\n    \t\t\t\t\t\tfor x in df[df['Company'] == row['Company']]['Position'])\n    title += '\u003cul\u003e{0}\u003c/ul\u003e'.format(position_list)\n    node_name = row['Company']\n    if len(node_name) \u003e 15:\n        node_name = node_name[:15] + '...'\n\n    # Since there are less nodes, let's increase the sizes\n    G.add_node(node_name, weight=row['Count'], size=row['Count'] * 5, title=title)\n    G.add_edge('Me', node_name)\n\n# Generate the visualization\nnt = Network('100%', '100%', bgcolor='#222222', font_color='white')\nnt.from_nx(G)\nnt.repulsion()\nnt.show('nx.html')\n```\n\nNow, let's look at the [updated results](/network/second-nx-graph.html).\n\nMuch better! This is more readable and easier to interact with.\n\nAnd just like that, we achieved our goal of gaining a broader understanding of the companies in our LinkedIn network.\n\n---\n\n**_Possible improvements for those interested_**\n- Scraping the profile location of each of your connections to segment by location\n- Compiling a list of companies you'd like to work for/are interested in and creating a filtering system\n- Researching salary data for positions and gathering average pay by company\n\n---\n","title":"Visualizing your LinkedIn connections using Python","date":"2021-04-08","tags":["python","pandas","networkx","data-analysis"],"description":"Using Python's Pandas, NetworkX, and pyvis to understand and visualize companies within a directly connected LinkedIn network."}],"aws":[{"id":"converting-html-to-pdf","contentHtml":"\u003ch2\u003etl;dr\u003c/h2\u003e\n\u003ch3\u003eGoal\u003c/h3\u003e\n\u003cp\u003e\u003cem\u003eTo set up an easy to call HTML to PDF converter as an AWS Lambda function.\u003c/em\u003e\u003c/p\u003e\n\u003ch3\u003eProcess Overview\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eDownloading the \u003ccode\u003ewkhtmltopdf\u003c/code\u003e binary\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eCreating the AWS Lambda layer(s) and configuring our function\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eWriting the AWS Lambda function\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eWe will use Python's \u003ca href=\"https://docs.python.org/3/library/subprocess.html\"\u003e\u003ccode\u003esubprocess\u003c/code\u003e module\u003c/a\u003e to call the \u003ccode\u003ewkhtmltopdf\u003c/code\u003e command\u003c/li\u003e\n\u003cli\u003eFor more in-depth Python focused usage, also check out \u003ca href=\"https://pypi.org/project/pdfkit/\"\u003epdfkit\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3\u003ePrerequisites\u003c/h3\u003e\n\u003cp\u003eThis article assumes access to an AWS account (free-tier is acceptable) and basic knowledge of AWS Lambda/S3 and Python.\u003c/p\u003e\n\u003ch3\u003eFunctional Requirements\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003eAllow passing either an S3 file key or an HTML string\u003c/li\u003e\n\u003cli\u003eReturn a file key for the generated PDF\u003c/li\u003e\n\u003cli\u003eAccept a small set of options for the \u003ccode\u003ewkhtmltopdf\u003c/code\u003e command\n\u003cul\u003e\n\u003cli\u003eA full man page can be found \u003ca href=\"https://wkhtmltopdf.org/usage/wkhtmltopdf.txt\"\u003ehere\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003eMost of the ones we'd want anyways are the default (i.e. \u003ccode\u003e--images\u003c/code\u003e, \u003ccode\u003e--enable-external-links\u003c/code\u003e, etc.)\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eFunctionality for the following options\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003e--orientation \u0026#x3C;orientation\u003e\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003e--title \u0026#x3C;text\u003e\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003e--margin-bottom \u0026#x3C;unitreal\u003e\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003e--margin-left \u0026#x3C;unitreal\u003e\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003e--margin-right \u0026#x3C;unitreal\u003e\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003e--margin-top \u0026#x3C;unitreal\u003e\u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003eAssumptions\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003eThe HTML string or file will be valid and will include the necessary tags (\u003ccode\u003e\u0026#x3C;!DOCTYPE html\u003e\u003c/code\u003e, \u003ccode\u003e\u0026#x3C;html\u003e\u003c/code\u003e, \u003ccode\u003e\u0026#x3C;head\u003e\u003c/code\u003e, \u003ccode\u003e\u0026#x3C;body\u003e\u003c/code\u003e). \u003cstrong\u003eIt is very important that you check validity of this HTML prior to calling this function if you ever use something similar in production. It may be best to only accept S3 file keys instead of HTML strings, but this is simply to show our functions possibilities or be used as an internal tool.\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003eThe event payload will contain all valid values (S3 bucket name, file key, \u003ccode\u003ewkhtmltopdf\u003c/code\u003e options etc.)\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3\u003eNotes\u003c/h3\u003e\n\u003cp\u003eThis article will use \u003ccode\u003eus-east-2\u003c/code\u003e for the AWS region, changing this shouldn't effect functionality, just the links within the article.\u003c/p\u003e\n\u003cp\u003eA better way to do this is through \u003ca href=\"https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/what-is-sam.html\"\u003eAWS Serverless Application Model (SAM)\u003c/a\u003e, but this is more tailored for those looking for the basic setup through the AWS Management Console.\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003eA common task I've found myself undertaking recently is programmatically converting an HTML file/string to an embedded and stylized PDF file.\u003c/p\u003e\n\u003cp\u003eAn example use case for this might be exporting a self-managed customer invoice or generating a daily report from an existing HTML template. For those who have used template languages before, you can probably imagine the usefulness of a function like this in combination with \u003ca href=\"https://jinja.palletsprojects.com/en/2.11.x/\"\u003eJinja\u003c/a\u003e or template rendering engines commonly found in Web Frameworks (like \u003ca href=\"https://www.djangoproject.com/\"\u003eDjango\u003c/a\u003e).\u003c/p\u003e\n\u003cp\u003eAfter doing some research on third party libraries that could simplify our goal, I decided to use \u003ca href=\"https://wkhtmltopdf.org/\"\u003e\u003ccode\u003ewkhtmltopdf\u003c/code\u003e\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003ewkhtmltopdf\u003c/code\u003e is an open-source command line tool that enables you to easy convert an HTML file to a PDF file. This is exactly what we're looking for. We will call the \u003ccode\u003ewkhtmltopdf\u003c/code\u003e command using the \u003ca href=\"https://docs.python.org/3/library/subprocess.html\"\u003e\u003ccode\u003esubprocess\u003c/code\u003e\u003c/a\u003e Python library. For more in-depth Python usage, you can check out \u003ca href=\"https://pypi.org/project/pdfkit/\"\u003epdfkit\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eLet's dive into it.\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003eWhy AWS Lambda?\u003c/h2\u003e\n\u003cp\u003e\u003ca href=\"https://aws.amazon.com/lambda/\"\u003eAWS Lambda\u003c/a\u003e provides serverless computing functions where you don't need to manage any servers or containers, you can simply call your function synchronously or asynchronously, and it will be executed and scaled automatically.\u003c/p\u003e\n\u003cp\u003eLambda has a ton of use cases and is something I have personally used many times and am a big fan of.\u003c/p\u003e\n\u003cp\u003e\u003cem\u003eFor our goal, AWS Lambda is a powerful tool for the following reasons\u003c/em\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eIt allows us to offload processing away from the server\n\u003cul\u003e\n\u003cli\u003eThis is more of a general benefit, we won't actually be calling this function from a running server\u003c/li\u003e\n\u003cli\u003eThese calls will also be scaled automatically\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eOur dependencies, specifically the \u003ccode\u003ewkhtmltopdf\u003c/code\u003e binary, can be handled well through \u003ca href=\"https://docs.aws.amazon.com/lambda/latest/dg/configuration-layers.html\"\u003eAWS Lambda layers\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003eThis helps to avoid dealing with different Linux distributions or multiple installation locations\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eBelow is an explanation of why handling the dependencies through layers will avoid issues. For continued instruction, you can skip to the next section.\u003c/strong\u003e\u003c/p\u003e\n\u003ch3\u003eIssues with downloading the binary\u003c/h3\u003e\n\u003cp\u003eWhen I was first using this library, I was also using \u003ca href=\"https://pypi.org/project/pdfkit/\"\u003e\u003ccode\u003epdfkit\u003c/code\u003e\u003c/a\u003e to drive this interaction.  At the top of the installation instructions, you can see the following warning:\u003c/p\u003e\n\u003cp\u003eWhen I first installed \u003ccode\u003ewkhtmltopdf\u003c/code\u003e, I didn't heed the warning and just ran the following:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003esudo apt-get install wkhtmltopdf\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eOn initial inspection, I wasn't experiencing the problems they mentioned (\u003cem\u003eat least in my local environment\u003c/em\u003e). The issues came when I actually pushed up code using this library to a staging environment and I noticed the PDFs were no longer generating.\u003c/p\u003e\n\u003cp\u003eI was able to remedy this by installing in an alternative way:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003esudo apt-get remove --purge wkhtmltopdf\nwget https://github.com/wkhtmltopdf/packaging/releases/download/0.12.6-1/wkhtmltox_0.12.6-1.bionic_amd64.deb\nsudo dpkg -i wkhtmltox_0.12.6-1.bionic_amd64.deb\nrm wkhtmltox_0.12.6-1.bionic_amd64.deb\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThis isn't a big deal, but managing this dependency could get tedious if your architecture has multiple servers that need installed with different Linux distributions.\u003c/p\u003e\n\u003cp\u003ePutting this binary into an AWS Lambda Layer can help solve this by having a single point of installation and management.\u003c/p\u003e\n\u003ch2\u003eDownloading the \u003ccode\u003ewkhtmltopdf\u003c/code\u003e binary\u003c/h2\u003e\n\u003cp\u003eThe \u003ccode\u003ewkhtmltopdf\u003c/code\u003e site actually lists using this library with AWS Lambda as a \u003ca href=\"https://wkhtmltopdf.org/downloads.html#how-do-i-use-it-in-aws-lambda\"\u003eFAQ\u003c/a\u003e and gives the following response to this question:\u003c/p\u003e\n\u003cp\u003e\u003cem\u003e\"All files required for lambda layer are packed in one zip archive (Amazon Linux 2 / lambda zip)\"\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003eYou can download the binary on the releases page under the \u003ca href=\"https://wkhtmltopdf.org/downloads.html#stable\"\u003eStable releases\u003c/a\u003e. You'll see an entry under \u003ccode\u003eAmazon Linux\u003c/code\u003e with \u003ccode\u003elambda zip\u003c/code\u003e as the architecture.\u003c/p\u003e\n\u003cp\u003eOr, you can click \u003ca href=\"https://github.com/wkhtmltopdf/packaging/releases/download/0.12.6-4/wkhtmltox-0.12.6-4.amazonlinux2_lambda.zip\"\u003ehere\u003c/a\u003e (I likely won't update this link, so probably best to go directly to the release page).\u003c/p\u003e\n\u003cp\u003e\u003cem\u003eRandom note:\u003c/em\u003e If you need more fonts for future usage, I've found that \u003ca href=\"https://github.com/brandonlim-hs/fonts-aws-lambda-layer\"\u003ethis is a good resource\u003c/a\u003e. You may need to include one of these fonts as a layer in your lambda function (via ARN) if your function has issues in the beginning.\u003c/p\u003e\n\u003ch2\u003eCreating the AWS Lambda layers\u003c/h2\u003e\n\u003cp\u003e\u003ca href=\"https://docs.aws.amazon.com/lambda/latest/dg/configuration-layers.html\"\u003eAWS Lambda layers\u003c/a\u003e allow us to add in \"layers\" of dependencies for our functions. An alternative to this is uploading your lambda function as a deployment package or using AWS SAM (Serverless Application Model), but that is out of the scope of this post.\u003c/p\u003e\n\u003ch3\u003e\u003ccode\u003ewkhtmltopdf\u003c/code\u003e\u003c/h3\u003e\n\u003cp\u003eNow that we have the zip file downloaded, let's add our file as a layer in the \u003ca href=\"https://us-east-2.console.aws.amazon.com/console/home?region=us-east-2\"\u003eAWS Management Console\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eGo to the \u003ca href=\"https://us-east-2.console.aws.amazon.com/lambda/home?region=us-east-2#/layers\"\u003eLayers section\u003c/a\u003e on the AWS Lambda page and click \u003ccode\u003eCreate layer\u003c/code\u003e.\u003c/p\u003e\n\u003cp\u003eThen, add the following Layer configuration.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/converting-html-to-pdf/layer-configuration.jpg\" alt=\"AWS Lambda layer configuration {priority}{680x488}\"\u003e\u003c/p\u003e\n\u003cp\u003eNotice that we don't add a runtime here, this is intentional since our layer is a binary.\u003c/p\u003e\n\u003cp\u003eClick Create and take note of your new layer's Version ARN as we are about to use it to add to our function.\u003c/p\u003e\n\u003cp\u003eNow we're set up to create our function!\u003c/p\u003e\n\u003ch2\u003eWriting the AWS Lambda function\u003c/h2\u003e\n\u003cp\u003eNavigate to the \u003ca href=\"https://us-east-2.console.aws.amazon.com/lambda/home?region=us-east-2#/functions\"\u003eFunctions page\u003c/a\u003e within the AWS Lambda service and click \u003ccode\u003eCreate function\u003c/code\u003e.\u003c/p\u003e\n\u003cp\u003eSelect \u003ccode\u003eAuthor from scratch\u003c/code\u003e, and add the following configuration.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/converting-html-to-pdf/function-configuration.jpg\" alt=\"AWS Lambda function configuration {1004x475}\"\u003e\u003c/p\u003e\n\u003cp\u003eYou can ignore the \u003ccode\u003eAdvanced settings\u003c/code\u003e for our use case.\u003c/p\u003e\n\u003cp\u003eOnce the function is created, we have just a few configuration additions to make.\u003c/p\u003e\n\u003ch3\u003eAdding the layer to our Lambda function\u003c/h3\u003e\n\u003cp\u003eNow that our function is created, the first thing we want to do is add our \u003ccode\u003ewkhtmltopdf\u003c/code\u003e layer.\u003c/p\u003e\n\u003cp\u003eAt the top of the Function Overview panel, click the \u003ccode\u003eLayers\u003c/code\u003e button right below your function name. This will bring you down to the layers section. Now click Add a layer.\u003c/p\u003e\n\u003cp\u003eClick on \u003ccode\u003eSpecify an ARN\u003c/code\u003e and copy your Layer Version ARN from earlier.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/converting-html-to-pdf/add-layer.jpg\" alt=\"AWS Lambda add layer {680x316}\"\u003e\u003c/p\u003e\n\u003cp\u003eThe reason why we need to specify our layer by ARN is because we didn't define a runtime above.\u003c/p\u003e\n\u003ch3\u003eAdd permission to access your S3 bucket\u003c/h3\u003e\n\u003cp\u003eOne final function configuration that we need to add is permission for our function to access Amazon S3.  To do this, navigate to the Configuration tab below your Function Overview.\u003c/p\u003e\n\u003cp\u003eUnder Configuration, go to the Permissions section. Here, you will see your generated Execution Role. Click this link to go to the IAM Console.\u003c/p\u003e\n\u003cp\u003eFrom here, click Attach policies, and add the \u003cstrong\u003eAmazonS3FullAccess\u003c/strong\u003e policy like so\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/converting-html-to-pdf/iam-policy.jpg\" alt=\"AWS Lambda IAM policy {1004x461}\"\u003e\u003c/p\u003e\n\u003cp\u003eNow that our function is configured, we can dive into the actual requirements and code!\u003c/p\u003e\n\u003ch3\u003eRequirements\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003eAllow passing either an S3 file key or an HTML string\u003c/li\u003e\n\u003cli\u003eReturn a file key for the generated PDF\u003c/li\u003e\n\u003cli\u003eAccept a small set of options for the \u003ccode\u003ewkhtmltopdf\u003c/code\u003e command\n\u003cul\u003e\n\u003cli\u003eA full man page can be found \u003ca href=\"https://wkhtmltopdf.org/usage/wkhtmltopdf.txt\"\u003ehere\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003eMost of the ones we'd want anyways are the default (i.e. \u003ccode\u003e--images\u003c/code\u003e, \u003ccode\u003e--enable-external-links\u003c/code\u003e, etc.)\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eLet's allow the user to pass the following options\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003e--orientation \u0026#x3C;orientation\u003e\u003c/code\u003e - the common page orientation for the PDF file.\n\u003cul\u003e\n\u003cli\u003eValid values are \u003ccode\u003eLandscape\u003c/code\u003e or \u003ccode\u003ePortrait\u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003e--title \u0026#x3C;text\u003e\u003c/code\u003e - the title of the generated file.\u003c/li\u003e\n\u003cli\u003eThe margins of the file\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003e--margin-bottom \u0026#x3C;unitreal\u003e\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003e--margin-left \u0026#x3C;unitreal\u003e\u003c/code\u003e (default is 10mm)\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003e--margin-right \u0026#x3C;unitreal\u003e\u003c/code\u003e  (default is 10mm)\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003e--margin-top \u0026#x3C;unitreal\u003e\u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003eAssumptions\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003eThe HTML string or file will be valid and will include the necessary tags (\u003ccode\u003e\u0026#x3C;!DOCTYPE html\u003e\u003c/code\u003e, \u003ccode\u003e\u0026#x3C;html\u003e\u003c/code\u003e, \u003ccode\u003e\u0026#x3C;head\u003e\u003c/code\u003e, \u003ccode\u003e\u0026#x3C;body\u003e\u003c/code\u003e)\u003c/li\u003e\n\u003cli\u003eThe event payload will contain all valid values (S3 bucket name, file key, \u003ccode\u003ewkhtmltopdf\u003c/code\u003e options etc.)\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3\u003eThe function code\u003c/h3\u003e\n\u003cp\u003eBy default, you will see the following handler.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003edef lambda_handler(event, context):\n    # TODO implement\n    return {\n        'statusCode': 200,\n        'body': json.dumps('Hello from Lambda!')\n    }\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThis is the code that will be executed when your function is called. We'll come back to this in a bit.\u003c/p\u003e\n\u003ch4\u003eThe imports\u003c/h4\u003e\n\u003cp\u003eFirst, let's go ahead and import all of the Python libraries that we'll need and set up some basic tools like the \u003ccode\u003eS3 client\u003c/code\u003e and our \u003ccode\u003elogger\u003c/code\u003e.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003efrom datetime import datetime\nimport json\nimport logging\nimport os\nimport subprocess\nfrom typing import Optional\n\nimport boto3\nfrom botocore.exceptions import ClientError\n\n\n# Set up logging\nlogger = logging.getLogger()\nlogger.setLevel(logging.INFO)\n\n# Get the s3 client\ns3 = boto3.client('s3')\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eNow based upon our requirements, we'll need helper functions to\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eDownload an HTML file from S3\u003c/li\u003e\n\u003cli\u003eUpload a file to S3\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eLet's start with those, and then we'll return to our lambda handler.\u003c/p\u003e\n\u003ch4\u003eDownloading/uploading the file\u003c/h4\u003e\n\u003cp\u003e\u003ca href=\"https://boto3.amazonaws.com/v1/documentation/api/latest/index.html\"\u003e\u003ccode\u003eboto3\u003c/code\u003e\u003c/a\u003e makes it really easy to interact with S3.  Using \u003ccode\u003eboto3\u003c/code\u003e, we can add the following helper functions.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003edef download_s3_file(bucket: str, file_key: str) -\u003e str:\n    \"\"\"Downloads a file from s3 to `/tmp/[File Key]`.\n    \n    Args:\n        bucket (str): Name of the bucket where the file lives.\n        file_key (str): The file key of the file in the bucket.\n\n    Returns:\n        The local file name as a string.\n    \"\"\"\n    local_filename = f'/tmp/{file_key}'\n    s3.download_file(Bucket=bucket, Key=file_key, Filename=local_filename)\n    logger.info('Downloaded HTML file to %s' % local_filename)\n\n    return local_filename\n    \n    \ndef upload_file_to_s3(bucket: str, filename: str) -\u003e Optional[str]:\n    \"\"\"Uploads the generated PDF to s3.\n    \n    Args:\n        bucket (str): Name of the s3 bucket to upload the PDF to.\n        filename (str): Location of the file to upload to s3.\n        \n    Returns:\n        The file key of the file in s3 if the upload was successful.\n        If the upload failed, then `None` will be returned.\n    \"\"\"\n    file_key = None\n    try:\n        file_key = filename.replace('/tmp/', '')\n        s3.upload_file(Filename=filename, Bucket=bucket, Key=file_key)\n        logger.info('Successfully uploaded the PDF to %s as %s'\n                    % (bucket, file_key))\n    except ClientError as e:\n        logger.error('Failed to upload file to s3.')\n        logger.error(e)\n        file_key = None\n        \n    return file_key\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch4\u003eParsing the event\u003c/h4\u003e\n\u003cp\u003eOne thing we haven't talked about yet is the data that we'll need to pass our function.\u003c/p\u003e\n\u003cp\u003eLet's define our JSON event schema as the following.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e{\n    \"bucket\": \"\u0026#x3C;Name of the bucket where the file is stored currently and will be stored after processing\u003e [Required]\",\n    \"file_key\": \"\u0026#x3C;File key where the file is store in S3\u003e [Required if `html_string` is not defined]\",\n    \"html_string\": \"\u0026#x3C;HTML string to convert to a PDF\u003e [Required if `file_key` is not defined]\",\n    \"wkhtmltopdf_options\": {\n        \"orientation\": \"\u0026#x3C;`landscape` or `portrait`\u003e [Optional: Default is `portrait`]\",\n        \"title\": \"\u0026#x3C;Title of the PDF\u003e [Optional]\",\n        \"margin\": \"\u0026#x3C;Margin of the PDF (same format as css [\u0026#x3C;top\u003e \u0026#x3C;right\u003e \u0026#x3C;bottom\u003e \u0026#x3C;left\u003e] (all must be included)).\u003e [Optional]\"\n    }\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003ccode\u003ewkhtmltopdf_options\u003c/code\u003e is an optional object. If the included options are not valid, they will not be included.\u003c/p\u003e\n\u003cp\u003eWe can access all of the data passed to our function from the \u003ccode\u003eevent\u003c/code\u003e parameter in the \u003ccode\u003elambda_handler\u003c/code\u003e function.\u003c/p\u003e\n\u003cp\u003eNow, let's jump back to the \u003ccode\u003elambda_handler\u003c/code\u003e function and add some code to pull out the data from our event and put together the remaining pieces of actually calling the \u003ccode\u003ewkhtmltopdf\u003c/code\u003e executable to finish our lambda function.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003edef lambda_handler(event, context):\n    logger.info(event)\n\n    # bucket is always required\n    try:\n        bucket = event['bucket']\n    except KeyError:\n        error_message = 'Missing required \"bucket\" parameter from request payload.'\n        logger.error(error_message)\n        return {\n            'status': 400,\n            'body': json.dumps(error_message),\n        }\n\n    # html_string and file_key are conditionally required, so let's try to get both\n    try:\n        file_key = event['file_key']\n    except KeyError:\n        file_key = None\n\n    try:\n        html_string = event['html_string']\n    except KeyError:\n        html_string = None\n\n    if file_key is None and html_string is None:\n        error_message = (\n            'Missing both a \"file_key\" and \"html_string\" '\n            'from request payload. One of these must be '\n            'included.'\n        )\n        logger.error(error_message)\n        return {\n            'status': 400,\n            'body': json.dumps(error_message),\n        }\n\n    # Now we can check for the option wkhtmltopdf_options and map them to values\n    # Again, part of our assumptions are that these are valid\n    wkhtmltopdf_options = {}\n    if 'wkhtmltopdf_options' in event:\n        # Margin is \u0026#x3C;top\u003e \u0026#x3C;right\u003e \u0026#x3C;bottom\u003e \u0026#x3C;left\u003e\n        if 'margin' in event['wkhtmltopdf_options']:\n            margins = event['wkhtmltopdf_options']['margin'].split(' ')\n            if len(margins) == 4:\n                wkhtmltopdf_options['margin-top'] = margins[0]\n                wkhtmltopdf_options['margin-right'] = margins[1]\n                wkhtmltopdf_options['margin-bottom'] = margins[2]\n                wkhtmltopdf_options['margin-left'] = margins[3]\n\n        if 'orientation' in event['wkhtmltopdf_options']:\n            wkhtmltopdf_options['orientation'] = 'portrait' \\\n                if event['wkhtmltopdf_options']['orientation'].lower() not in ['portrait', 'landscape'] \\\n                else event['wkhtmltopdf_options']['orientation'].lower()\n\n        if 'title' in event['wkhtmltopdf_options']:\n            wkhtmltopdf_options['title'] = event['wkhtmltopdf_options']['title']\n\n    # If we got a file_key in the request, let's download our file\n    # If not, we'll write the HTML string to a file\n    if file_key is not None:\n        local_filename = download_s3_file(bucket, file_key)\n    else:\n        timestamp = str(datetime.now()).replace('.', '').replace(' ', '_')\n        local_filename = f'/tmp/{timestamp}-html-string.html'\n\n        # Delete any existing files with that name\n        try:\n            os.unlink(local_filename)\n        except FileNotFoundError:\n            pass\n\n        with open(local_filename, 'w') as f:\n            f.write(html_string)\n\n    # Now we can create our command string to execute and upload the result to s3\n    command = 'wkhtmltopdf  --load-error-handling ignore'  # ignore unecessary errors\n    for key, value in wkhtmltopdf_options.items():\n        if key == 'title':\n            value = f'\"{value}\"'\n        command += ' --{0} {1}'.format(key, value)\n    command += ' {0} {1}'.format(local_filename, local_filename.replace('.html', '.pdf'))\n\n    # Important! Remember, we said that we are assuming we're accepting valid HTML\n    # this should always be checked to avoid allowing any string to be executed\n    # from this command. The reason we use shell=True here is because our title\n    # can be multiple words.\n    subprocess.run(command, shell=True)\n    logger.info('Successfully generated the PDF.')\n    file_key = upload_file_to_s3(bucket, local_filename.replace('.html', '.pdf'))\n\n    if file_key is None:\n        error_message = (\n            'Failed to generate PDF from the given HTML file.'\n            ' Please check to make sure the file is valid HTML.'\n        )\n        logger.error(error_message)\n        return {\n            'status': 400,\n            'body': json.dumps(error_message),\n        }\n\n    return {\n        'status': 200,\n        'file_key': file_key,\n    }\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eNow you can go to the \u003cstrong\u003eTest\u003c/strong\u003e tab and create the following test event (change your bucket name as necessary)\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e{\n    \"bucket\": \"bucket-for-articles\",\n    \"html_string\": \"\u0026#x3C;!DOCTYPE html\u003e\u0026#x3C;html\u003e\u0026#x3C;head\u003e\u0026#x3C;/head\u003e\u0026#x3C;body\u003eThis is an example of a simple HTML page.\u0026#x3C;/body\u003e\u0026#x3C;/html\u003e\",\n    \"wkhtmltopdf_options\": {\n        \"orientation\": \"portrait\",\n        \"title\": \"Test PDF Generation\",\n        \"margin\": \"10mm 10mm 10mm 10mm\"\n    }\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eYou should get a return event with a \u003ccode\u003estatus\u003c/code\u003e of \u003ccode\u003e200\u003c/code\u003e, and a \u003ccode\u003efile_key\u003c/code\u003e of your converted file, thus achieving our goal! üéâ\u003c/p\u003e\n\u003chr\u003e\n","markdown":"\n## tl;dr\n\n### Goal\n_To set up an easy to call HTML to PDF converter as an AWS Lambda function._\n\n### Process Overview\n1. **Downloading the `wkhtmltopdf` binary**\n2. **Creating the AWS Lambda layer(s) and configuring our function**\n3. **Writing the AWS Lambda function**\n    - We will use Python's [`subprocess` module](https://docs.python.org/3/library/subprocess.html) to call the `wkhtmltopdf` command\n    - For more in-depth Python focused usage, also check out [pdfkit](https://pypi.org/project/pdfkit/)\n\n### Prerequisites\nThis article assumes access to an AWS account (free-tier is acceptable) and basic knowledge of AWS Lambda/S3 and Python.\n\n### Functional Requirements\n\n1. Allow passing either an S3 file key or an HTML string\n2. Return a file key for the generated PDF\n3. Accept a small set of options for the `wkhtmltopdf` command\n    - A full man page can be found [here](https://wkhtmltopdf.org/usage/wkhtmltopdf.txt)\n    - Most of the ones we'd want anyways are the default (i.e. `--images`, `--enable-external-links`, etc.)\n\nFunctionality for the following options\n- `--orientation \u003corientation\u003e`\n- `--title \u003ctext\u003e`\n- `--margin-bottom \u003cunitreal\u003e`\n- `--margin-left \u003cunitreal\u003e`\n- `--margin-right \u003cunitreal\u003e`\n- `--margin-top \u003cunitreal\u003e`\n\n### Assumptions\n\n1. The HTML string or file will be valid and will include the necessary tags (`\u003c!DOCTYPE html\u003e`, `\u003chtml\u003e`, `\u003chead\u003e`, `\u003cbody\u003e`). **It is very important that you check validity of this HTML prior to calling this function if you ever use something similar in production. It may be best to only accept S3 file keys instead of HTML strings, but this is simply to show our functions possibilities or be used as an internal tool.**\n2. The event payload will contain all valid values (S3 bucket name, file key, `wkhtmltopdf` options etc.)\n\n### Notes\nThis article will use `us-east-2` for the AWS region, changing this shouldn't effect functionality, just the links within the article.\n\nA better way to do this is through [AWS Serverless Application Model (SAM)](https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/what-is-sam.html), but this is more tailored for those looking for the basic setup through the AWS Management Console.\n\n---\nA common task I've found myself undertaking recently is programmatically converting an HTML file/string to an embedded and stylized PDF file.\n\nAn example use case for this might be exporting a self-managed customer invoice or generating a daily report from an existing HTML template. For those who have used template languages before, you can probably imagine the usefulness of a function like this in combination with [Jinja](https://jinja.palletsprojects.com/en/2.11.x/) or template rendering engines commonly found in Web Frameworks (like [Django](https://www.djangoproject.com/)).\n\nAfter doing some research on third party libraries that could simplify our goal, I decided to use [`wkhtmltopdf`](https://wkhtmltopdf.org/).\n\n`wkhtmltopdf` is an open-source command line tool that enables you to easy convert an HTML file to a PDF file. This is exactly what we're looking for. We will call the `wkhtmltopdf` command using the [`subprocess`](https://docs.python.org/3/library/subprocess.html) Python library. For more in-depth Python usage, you can check out [pdfkit](https://pypi.org/project/pdfkit/).\n\nLet's dive into it.\n\n---\n\n## Why AWS Lambda?\n[AWS Lambda](https://aws.amazon.com/lambda/) provides serverless computing functions where you don't need to manage any servers or containers, you can simply call your function synchronously or asynchronously, and it will be executed and scaled automatically.\n\nLambda has a ton of use cases and is something I have personally used many times and am a big fan of.\n\n_For our goal, AWS Lambda is a powerful tool for the following reasons_\n- It allows us to offload processing away from the server\n    - This is more of a general benefit, we won't actually be calling this function from a running server\n    - These calls will also be scaled automatically\n- Our dependencies, specifically the `wkhtmltopdf` binary, can be handled well through [AWS Lambda layers](https://docs.aws.amazon.com/lambda/latest/dg/configuration-layers.html)\n    - This helps to avoid dealing with different Linux distributions or multiple installation locations\n\n**Below is an explanation of why handling the dependencies through layers will avoid issues. For continued instruction, you can skip to the next section.**\n\n### Issues with downloading the binary\nWhen I was first using this library, I was also using [`pdfkit`](https://pypi.org/project/pdfkit/) to drive this interaction.  At the top of the installation instructions, you can see the following warning:\n\n\u003cp style=\"background-color: orange; padding: 7px 20px; text-align: center; border-radius: 6px;\"\u003e\n\u003ci\u003e\"\u003cb\u003eWarning!\u003c/b\u003e\u0026nbsp;Version in debian/ubuntu repos have reduced functionality (because it compiled without the wkhtmltopdf QT patches), such as adding outlines, headers, footers, TOC etc. To use this options you should install static binary from wkhtmltopdf site\"\u003c/i\u003e\n\u003c/p\u003e\n\nWhen I first installed `wkhtmltopdf`, I didn't heed the warning and just ran the following:\n```bash\nsudo apt-get install wkhtmltopdf\n```\n\nOn initial inspection, I wasn't experiencing the problems they mentioned (_at least in my local environment_). The issues came when I actually pushed up code using this library to a staging environment and I noticed the PDFs were no longer generating.\n\nI was able to remedy this by installing in an alternative way:\n```bash\nsudo apt-get remove --purge wkhtmltopdf\nwget https://github.com/wkhtmltopdf/packaging/releases/download/0.12.6-1/wkhtmltox_0.12.6-1.bionic_amd64.deb\nsudo dpkg -i wkhtmltox_0.12.6-1.bionic_amd64.deb\nrm wkhtmltox_0.12.6-1.bionic_amd64.deb\n```\n\nThis isn't a big deal, but managing this dependency could get tedious if your architecture has multiple servers that need installed with different Linux distributions.\n\nPutting this binary into an AWS Lambda Layer can help solve this by having a single point of installation and management.\n\n## Downloading the `wkhtmltopdf` binary\nThe `wkhtmltopdf` site actually lists using this library with AWS Lambda as a [FAQ](https://wkhtmltopdf.org/downloads.html#how-do-i-use-it-in-aws-lambda) and gives the following response to this question:\n\n_\"All files required for lambda layer are packed in one zip archive (Amazon Linux 2 / lambda zip)\"_\n\nYou can download the binary on the releases page under the [Stable releases](https://wkhtmltopdf.org/downloads.html#stable). You'll see an entry under `Amazon Linux` with `lambda zip` as the architecture.\n\nOr, you can click [here](https://github.com/wkhtmltopdf/packaging/releases/download/0.12.6-4/wkhtmltox-0.12.6-4.amazonlinux2_lambda.zip) (I likely won't update this link, so probably best to go directly to the release page).\n\n_Random note:_ If you need more fonts for future usage, I've found that [this is a good resource](https://github.com/brandonlim-hs/fonts-aws-lambda-layer). You may need to include one of these fonts as a layer in your lambda function (via ARN) if your function has issues in the beginning.\n\n## Creating the AWS Lambda layers\n\n[AWS Lambda layers](https://docs.aws.amazon.com/lambda/latest/dg/configuration-layers.html) allow us to add in \"layers\" of dependencies for our functions. An alternative to this is uploading your lambda function as a deployment package or using AWS SAM (Serverless Application Model), but that is out of the scope of this post.\n\n### `wkhtmltopdf`\nNow that we have the zip file downloaded, let's add our file as a layer in the [AWS Management Console](https://us-east-2.console.aws.amazon.com/console/home?region=us-east-2).\n\nGo to the [Layers section](https://us-east-2.console.aws.amazon.com/lambda/home?region=us-east-2#/layers) on the AWS Lambda page and click `Create layer`.\n\nThen, add the following Layer configuration.\n\n![AWS Lambda layer configuration {priority}{680x488}](/images/converting-html-to-pdf/layer-configuration.jpg)\n\nNotice that we don't add a runtime here, this is intentional since our layer is a binary.\n\nClick Create and take note of your new layer's Version ARN as we are about to use it to add to our function.\n\nNow we're set up to create our function!\n\n\n## Writing the AWS Lambda function\nNavigate to the [Functions page](https://us-east-2.console.aws.amazon.com/lambda/home?region=us-east-2#/functions) within the AWS Lambda service and click `Create function`.\n\nSelect `Author from scratch`, and add the following configuration.\n\n![AWS Lambda function configuration {1004x475}](/images/converting-html-to-pdf/function-configuration.jpg)\n\nYou can ignore the `Advanced settings` for our use case.\n\nOnce the function is created, we have just a few configuration additions to make.\n\n### Adding the layer to our Lambda function\n\nNow that our function is created, the first thing we want to do is add our `wkhtmltopdf` layer.\n\nAt the top of the Function Overview panel, click the `Layers` button right below your function name. This will bring you down to the layers section. Now click Add a layer.\n\nClick on `Specify an ARN` and copy your Layer Version ARN from earlier.\n\n![AWS Lambda add layer {680x316}](/images/converting-html-to-pdf/add-layer.jpg)\n\nThe reason why we need to specify our layer by ARN is because we didn't define a runtime above.\n\n\u003cp style=\"background-color: #9bc2cf; padding: 7px 20px; text-align: center; border-radius: 6px;\"\u003e\n\u003cb\u003eImportant!\u003c/b\u003e If your function generates a PDF with a bunch of black squares, this is likely because there is no font configuration within Lambda. To solve this, you can go to [this link](https://github.com/brandonlim-hs/fonts-aws-lambda-layer\") that I mentioned earlier, and copy one of the AWS Linux Fonts ARNs for your region (or build from scratch), add the environment variable in the README, and repeat these steps to add a font layer.\n\u003c/p\u003e\n\n### Add permission to access your S3 bucket\n\nOne final function configuration that we need to add is permission for our function to access Amazon S3.  To do this, navigate to the Configuration tab below your Function Overview.\n\nUnder Configuration, go to the Permissions section. Here, you will see your generated Execution Role. Click this link to go to the IAM Console.\n\nFrom here, click Attach policies, and add the **AmazonS3FullAccess** policy like so\n\n![AWS Lambda IAM policy {1004x461}](/images/converting-html-to-pdf/iam-policy.jpg)\n\nNow that our function is configured, we can dive into the actual requirements and code!\n\n### Requirements\n\n1. Allow passing either an S3 file key or an HTML string\n2. Return a file key for the generated PDF\n3. Accept a small set of options for the `wkhtmltopdf` command\n    - A full man page can be found [here](https://wkhtmltopdf.org/usage/wkhtmltopdf.txt)\n    - Most of the ones we'd want anyways are the default (i.e. `--images`, `--enable-external-links`, etc.)\n\nLet's allow the user to pass the following options\n- `--orientation \u003corientation\u003e` - the common page orientation for the PDF file.\n    - Valid values are `Landscape` or `Portrait`\n- `--title \u003ctext\u003e` - the title of the generated file.\n- The margins of the file\n    - `--margin-bottom \u003cunitreal\u003e`\n    - `--margin-left \u003cunitreal\u003e` (default is 10mm)\n    - `--margin-right \u003cunitreal\u003e`  (default is 10mm)\n    - `--margin-top \u003cunitreal\u003e`\n\n### Assumptions\n\n1. The HTML string or file will be valid and will include the necessary tags (`\u003c!DOCTYPE html\u003e`, `\u003chtml\u003e`, `\u003chead\u003e`, `\u003cbody\u003e`)\n2. The event payload will contain all valid values (S3 bucket name, file key, `wkhtmltopdf` options etc.)\n\n### The function code\nBy default, you will see the following handler.\n```python\ndef lambda_handler(event, context):\n    # TODO implement\n    return {\n        'statusCode': 200,\n        'body': json.dumps('Hello from Lambda!')\n    }\n```\nThis is the code that will be executed when your function is called. We'll come back to this in a bit.\n\n#### The imports\nFirst, let's go ahead and import all of the Python libraries that we'll need and set up some basic tools like the `S3 client` and our `logger`.\n```python\nfrom datetime import datetime\nimport json\nimport logging\nimport os\nimport subprocess\nfrom typing import Optional\n\nimport boto3\nfrom botocore.exceptions import ClientError\n\n\n# Set up logging\nlogger = logging.getLogger()\nlogger.setLevel(logging.INFO)\n\n# Get the s3 client\ns3 = boto3.client('s3')\n```\n\nNow based upon our requirements, we'll need helper functions to\n1. Download an HTML file from S3\n2. Upload a file to S3\n\nLet's start with those, and then we'll return to our lambda handler.\n\n#### Downloading/uploading the file\n[`boto3`](https://boto3.amazonaws.com/v1/documentation/api/latest/index.html) makes it really easy to interact with S3.  Using `boto3`, we can add the following helper functions.\n\n```python\ndef download_s3_file(bucket: str, file_key: str) -\u003e str:\n    \"\"\"Downloads a file from s3 to `/tmp/[File Key]`.\n    \n    Args:\n        bucket (str): Name of the bucket where the file lives.\n        file_key (str): The file key of the file in the bucket.\n\n    Returns:\n        The local file name as a string.\n    \"\"\"\n    local_filename = f'/tmp/{file_key}'\n    s3.download_file(Bucket=bucket, Key=file_key, Filename=local_filename)\n    logger.info('Downloaded HTML file to %s' % local_filename)\n\n    return local_filename\n    \n    \ndef upload_file_to_s3(bucket: str, filename: str) -\u003e Optional[str]:\n    \"\"\"Uploads the generated PDF to s3.\n    \n    Args:\n        bucket (str): Name of the s3 bucket to upload the PDF to.\n        filename (str): Location of the file to upload to s3.\n        \n    Returns:\n        The file key of the file in s3 if the upload was successful.\n        If the upload failed, then `None` will be returned.\n    \"\"\"\n    file_key = None\n    try:\n        file_key = filename.replace('/tmp/', '')\n        s3.upload_file(Filename=filename, Bucket=bucket, Key=file_key)\n        logger.info('Successfully uploaded the PDF to %s as %s'\n                    % (bucket, file_key))\n    except ClientError as e:\n        logger.error('Failed to upload file to s3.')\n        logger.error(e)\n        file_key = None\n        \n    return file_key\n```\n\n#### Parsing the event\nOne thing we haven't talked about yet is the data that we'll need to pass our function.\n\nLet's define our JSON event schema as the following.\n```json\n{\n    \"bucket\": \"\u003cName of the bucket where the file is stored currently and will be stored after processing\u003e [Required]\",\n    \"file_key\": \"\u003cFile key where the file is store in S3\u003e [Required if `html_string` is not defined]\",\n    \"html_string\": \"\u003cHTML string to convert to a PDF\u003e [Required if `file_key` is not defined]\",\n    \"wkhtmltopdf_options\": {\n        \"orientation\": \"\u003c`landscape` or `portrait`\u003e [Optional: Default is `portrait`]\",\n        \"title\": \"\u003cTitle of the PDF\u003e [Optional]\",\n        \"margin\": \"\u003cMargin of the PDF (same format as css [\u003ctop\u003e \u003cright\u003e \u003cbottom\u003e \u003cleft\u003e] (all must be included)).\u003e [Optional]\"\n    }\n}\n```\n`wkhtmltopdf_options` is an optional object. If the included options are not valid, they will not be included.\n\nWe can access all of the data passed to our function from the `event` parameter in the `lambda_handler` function.\n\nNow, let's jump back to the `lambda_handler` function and add some code to pull out the data from our event and put together the remaining pieces of actually calling the `wkhtmltopdf` executable to finish our lambda function.\n\n```python\ndef lambda_handler(event, context):\n    logger.info(event)\n\n    # bucket is always required\n    try:\n        bucket = event['bucket']\n    except KeyError:\n        error_message = 'Missing required \"bucket\" parameter from request payload.'\n        logger.error(error_message)\n        return {\n            'status': 400,\n            'body': json.dumps(error_message),\n        }\n\n    # html_string and file_key are conditionally required, so let's try to get both\n    try:\n        file_key = event['file_key']\n    except KeyError:\n        file_key = None\n\n    try:\n        html_string = event['html_string']\n    except KeyError:\n        html_string = None\n\n    if file_key is None and html_string is None:\n        error_message = (\n            'Missing both a \"file_key\" and \"html_string\" '\n            'from request payload. One of these must be '\n            'included.'\n        )\n        logger.error(error_message)\n        return {\n            'status': 400,\n            'body': json.dumps(error_message),\n        }\n\n    # Now we can check for the option wkhtmltopdf_options and map them to values\n    # Again, part of our assumptions are that these are valid\n    wkhtmltopdf_options = {}\n    if 'wkhtmltopdf_options' in event:\n        # Margin is \u003ctop\u003e \u003cright\u003e \u003cbottom\u003e \u003cleft\u003e\n        if 'margin' in event['wkhtmltopdf_options']:\n            margins = event['wkhtmltopdf_options']['margin'].split(' ')\n            if len(margins) == 4:\n                wkhtmltopdf_options['margin-top'] = margins[0]\n                wkhtmltopdf_options['margin-right'] = margins[1]\n                wkhtmltopdf_options['margin-bottom'] = margins[2]\n                wkhtmltopdf_options['margin-left'] = margins[3]\n\n        if 'orientation' in event['wkhtmltopdf_options']:\n            wkhtmltopdf_options['orientation'] = 'portrait' \\\n                if event['wkhtmltopdf_options']['orientation'].lower() not in ['portrait', 'landscape'] \\\n                else event['wkhtmltopdf_options']['orientation'].lower()\n\n        if 'title' in event['wkhtmltopdf_options']:\n            wkhtmltopdf_options['title'] = event['wkhtmltopdf_options']['title']\n\n    # If we got a file_key in the request, let's download our file\n    # If not, we'll write the HTML string to a file\n    if file_key is not None:\n        local_filename = download_s3_file(bucket, file_key)\n    else:\n        timestamp = str(datetime.now()).replace('.', '').replace(' ', '_')\n        local_filename = f'/tmp/{timestamp}-html-string.html'\n\n        # Delete any existing files with that name\n        try:\n            os.unlink(local_filename)\n        except FileNotFoundError:\n            pass\n\n        with open(local_filename, 'w') as f:\n            f.write(html_string)\n\n    # Now we can create our command string to execute and upload the result to s3\n    command = 'wkhtmltopdf  --load-error-handling ignore'  # ignore unecessary errors\n    for key, value in wkhtmltopdf_options.items():\n        if key == 'title':\n            value = f'\"{value}\"'\n        command += ' --{0} {1}'.format(key, value)\n    command += ' {0} {1}'.format(local_filename, local_filename.replace('.html', '.pdf'))\n\n    # Important! Remember, we said that we are assuming we're accepting valid HTML\n    # this should always be checked to avoid allowing any string to be executed\n    # from this command. The reason we use shell=True here is because our title\n    # can be multiple words.\n    subprocess.run(command, shell=True)\n    logger.info('Successfully generated the PDF.')\n    file_key = upload_file_to_s3(bucket, local_filename.replace('.html', '.pdf'))\n\n    if file_key is None:\n        error_message = (\n            'Failed to generate PDF from the given HTML file.'\n            ' Please check to make sure the file is valid HTML.'\n        )\n        logger.error(error_message)\n        return {\n            'status': 400,\n            'body': json.dumps(error_message),\n        }\n\n    return {\n        'status': 200,\n        'file_key': file_key,\n    }\n```\n\nNow you can go to the **Test** tab and create the following test event (change your bucket name as necessary)\n```json\n{\n    \"bucket\": \"bucket-for-articles\",\n    \"html_string\": \"\u003c!DOCTYPE html\u003e\u003chtml\u003e\u003chead\u003e\u003c/head\u003e\u003cbody\u003eThis is an example of a simple HTML page.\u003c/body\u003e\u003c/html\u003e\",\n    \"wkhtmltopdf_options\": {\n        \"orientation\": \"portrait\",\n        \"title\": \"Test PDF Generation\",\n        \"margin\": \"10mm 10mm 10mm 10mm\"\n    }\n}\n```\n\nYou should get a return event with a `status` of `200`, and a `file_key` of your converted file, thus achieving our goal! üéâ\n\n---\n\n","title":"Converting HTML to a PDF using Python, AWS Lambda, and wkhtmltopdf","date":"2021-04-29","tags":["python","aws"],"description":"Building an AWS lambda function that uses Python and wkhtmltopdf to convert an HTML file to a PDF file."}],"pandas":[{"id":"forecasting-spy-prices","contentHtml":"\u003ch2\u003etl;dr\u003c/h2\u003e\n\u003ch3\u003eGoal\u003c/h3\u003e\n\u003cp\u003e\u003cem\u003eTo apply Facebook's Prophet forecasting procedure to historical SPY (SPDR S\u0026#x26;P 500 ETF Trust) market data to gather future pricing predictions.\u003c/em\u003e\u003c/p\u003e\n\u003ch3\u003eA few notes\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eI'm by no means a data scientist, so this is more of an exploratory analysis than an accurate one\u003c/li\u003e\n\u003cli\u003eFor sake of brevity, I won't be using a training/test split or measuring the error of the model, I will just train the model on the entire dataset and then make a prediction\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003eProcess overview\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eDownloading the data\u003c/strong\u003e - exporting the data from Yahoo Finance as a CSV\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eExploring the data\u003c/strong\u003e - loading and exploring the data using Pandas\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eFitting the model\u003c/strong\u003e - reading in the data and applying a basic fit of the Prophet model to the data\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eVisualizing the forecast\u003c/strong\u003e - visualizing the forecasted pricing data\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3\u003ePython dependencies\u003c/h3\u003e\n\u003cpre\u003e\u003ccode\u003eimport pandas as pd\nfrom prophet import Prophet\n\u003c/code\u003e\u003c/pre\u003e\n\u003chr\u003e\n\u003cp\u003eBefore we jump in, let's give a little background on SPY and on Facebook's Prophet.\u003c/p\u003e\n\u003cp\u003eThe \u003cem\u003eSPDR S\u0026#x26;P 500 ETF Trust\u003c/em\u003e (SPY) is an ETF (\u003cem\u003eExchange Traded Fund\u003c/em\u003e) that tracks the performance of the S\u0026#x26;P 500 index.  SPY is also the largest ETF in the world, and is popular compared to other ETFs that track the S\u0026#x26;P 500 because of the high volume, or the number of shares that trade on a given day (we'll be able to see the volume per day in the CSV we export from Yahoo Finance).\u003c/p\u003e\n\u003cp\u003eFor more information on ETFs, \u003ca href=\"https://www.investopedia.com/terms/e/etf.asp\"\u003eInvestopedia gives a good overview\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://facebook.github.io/prophet/\"\u003eFacebook Prophet\u003c/a\u003e is an open source, automated forecasting procedure for time series data.  I'm not going to dive too much into the mathematics or implementation details of Prophet, but if you are more interested, you can read the \u003ca href=\"https://peerj.com/preprints/3190/\"\u003eresearch paper\u003c/a\u003e.  Prophet makes it easy to handle outliers, adjust to different time intervals, deal with holidays, and leaves the ability to easily tune the forecasting model.\u003c/p\u003e\n\u003cp\u003eNow that we have a general idea of what we're trying to predict and the tool we'll use to forecast, let's dive into the actual data.\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003eDownloading the data\u003c/h2\u003e\n\u003cp\u003eThanks to Yahoo Finance, we can download historical pricing data for free. You can click \u003ca href=\"https://finance.yahoo.com/quote/SPY/history?p=SPY\"\u003ehere\u003c/a\u003e to view the SPY historical pricing data.\u003c/p\u003e\n\u003cp\u003eClick on the \u003ccode\u003eHistorical Data\u003c/code\u003e tab, and then we can adjust our \u003ccode\u003eTime Period\u003c/code\u003e to the Max as seen below (back to January 1993).\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/forecasting-spy/export-data.jpg\" alt=\"Historical pricing data {priority}{680x243}\"\u003e\u003c/p\u003e\n\u003cp\u003eNow we can click download to get our CSV and start diving into the data.\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003eExploring the data\u003c/h2\u003e\n\u003cp\u003eLet's fire up Pandas and load our data into a DataFrame to see what general insights we can extract.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003edf = pd.read_csv('SPY.csv')\n\n# Columns and row count\ndf.info()\n\"\"\"\n\u0026#x3C;class 'pandas.core.frame.DataFrame'\u003e\nRangeIndex: 7125 entries, 0 to 7124\nData columns (total 7 columns):\n #   Column     Non-Null Count  Dtype  \n---  ------     --------------  -----  \n 0   Date       7125 non-null   object \n 1   Open       7125 non-null   float64\n 2   High       7125 non-null   float64\n 3   Low        7125 non-null   float64\n 4   Close      7125 non-null   float64\n 5   Adj Close  7125 non-null   float64\n 6   Volume     7125 non-null   int64  \ndtypes: float64(5), int64(1), object(1)\nmemory usage: 389.8+ KB\n\"\"\"\n\n# Preview of the data\ndf.head()\n\"\"\"\n         Date      Open      High       Low     Close  Adj Close   Volume\n0  1993-01-29  43.96875  43.96875  43.75000  43.93750  25.884184  1003200\n1  1993-02-01  43.96875  44.25000  43.96875  44.25000  26.068277   480500\n2  1993-02-02  44.21875  44.37500  44.12500  44.34375  26.123499   201300\n3  1993-02-03  44.40625  44.84375  44.37500  44.81250  26.399649   529400\n4  1993-02-04  44.96875  45.09375  44.46875  45.00000  26.510111   531500\n\"\"\"\n\n# General statistics\ndf.describe().loc[['mean', 'min', 'max']]\n\"\"\"\n            Open        High         Low       Close   Adj Close        Volume\nmean  146.896395  147.766581  145.928716  146.896373  121.611954  8.453727e+07\nmin    43.343750   43.531250   42.812500   43.406250   25.571209  5.200000e+03\nmax   422.500000  422.820007  419.160004  422.119995  422.119995  8.710263e+08\n\"\"\"\n\n# Day to day percent changes of Highs\ndf[['Date', 'High']].set_index('Date').pct_change().reset_index()\n\"\"\"\n            Date      High\n0     1993-01-29       NaN\n1     1993-02-01  0.006397\n2     1993-02-02  0.002825\n3     1993-02-03  0.010563\n4     1993-02-04  0.005575\n         ...       ...\n7120  2021-05-10 -0.000189\n7121  2021-05-11 -0.017670\n7122  2021-05-12 -0.006454\n7123  2021-05-13 -0.000582\n7124  2021-05-14  0.012465\n\n[7125 rows x 2 columns]\n\"\"\"\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eNow that we know a bit more about our data in general, we can create a model using Prophet.\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003eFitting the model\u003c/h2\u003e\n\u003cp\u003eSince we're not concerned in this post about making our model the best it can be, we can train our model on the entire dataset.\u003c/p\u003e\n\u003cp\u003eThis typically isn't a good practice.  When trying to make an accurate prediction, you should use training and test subsets of the data and calculate errors within your model and use those results to tune hyperparameters.\u003c/p\u003e\n\u003cp\u003eNevertheless, let's continue.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e# The prophet model fits to a DataFrame with a date column (ds)\n# and a value to predict (y)\ndf_predict = df[['Date', 'Close']]\ndf_predict.columns = ['ds', 'y']\n\n# We can find all of the missing days within our dataset\n# and mark those as \"holidays\"\ndate_series = pd.to_datetime(df['Date'])\ndf_missing_dates = pd\\\n    .date_range(start=date_series.min(), end=date_series.max())\\\n    .difference(date_series)\\\n    .to_frame()\\\n    .reset_index()\ndf_missing_dates.columns = ['holiday', 'ds']\ndf_missing_dates['holiday'] = 'Stock Market Closed'\n\n# Fitting our model is incredibly simple and can be done in the\n# most basic sense in just two lines of code\nm = Prophet(daily_seasonality=True, holidays=df_missing_dates)\nm.fit(df_predict)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eJust like that, we have built our model for a forecast.  All we have left to do is generate dates to predict values for, and run the actual prediction.\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003eVisualizing the forecast\u003c/h2\u003e\n\u003cp\u003eNow let's forecast with our model and visualize the results.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e# Create a DataFrame with past and future dates (only weekdays)\nfuture = m.make_future_dataframe(periods=365)\nfuture = future[pd.to_datetime(future['ds']).dt.weekday \u0026#x3C; 5]\n\n# Now we can forecast and visualize in just two more lines of code\nforecast = m.predict(future)\nm.plot(forecast, xlabel='Date', ylabel='Daily Closing Price')\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cimg src=\"/images/forecasting-spy/first-prediction.jpg\" alt=\"First SPY forecast {800x480}\"\u003e\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003eA few things to notice\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eThe black dots are the training data points\u003c/li\u003e\n\u003cli\u003eThe blue outline is the confidence interval\u003c/li\u003e\n\u003cli\u003eThe line within the confidence interval is the actual forecast\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eBased on our results, we can see the forecast is fairly linear and the confidence interval is relatively narrow (due to the volume of date).  The behavior of the stock market since Covid-19 started back around February 2020 has be a little unorthodox, so let's narrow our model to be trained back to data starting in 2017 to see if there is an effect.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e# Narrow down to start at 2017\ndf_recent_predict = df_predict.iloc[date_series[date_series.dt.year \u003e 2016].index]\ndate_series = pd.to_datetime(df_recent_predict['ds'])\ndf_recent_missing_dates =  pd\\\n    .date_range(start=date_series.min(), end=date_series.max())\\\n    .difference(date_series)\\\n    .to_frame()\\\n    .reset_index()\ndf_recent_missing_dates.columns = ['holiday', 'ds']\ndf_recent_missing_dates['holiday'] = 'Stock Market Closed'\n\n# Create and fit our new model\nm = Prophet(daily_seasonality=True, holidays=df_recent_missing_dates)\nm.fit(df_recent_predict)\n\n# Recreate our future predictions\nfuture = m.make_future_dataframe(periods=365)\nfuture = future[pd.to_datetime(future['ds']).dt.weekday \u0026#x3C; 5]\n\n# Forecast and visualize\nforecast = m.predict(future)\nm.plot(forecast, xlabel='Date', ylabel='Daily Closing Price')\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cimg src=\"/images/forecasting-spy/second-prediction.jpg\" alt=\"Second SPY forecast {800x480}\"\u003e\u003c/p\u003e\n\u003cp\u003eNow we can see a much wider confidence interval and a bit more of a bumpy forecast line; however, this looks much more realistic in terms of stock market prediction.\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003eConclusion\u003c/h2\u003e\n\u003cp\u003eAll in all, Facebook's Prophet is a very fast, impressive, and strongly abstracted library.  The entire script, including reading in the data, training and forecasting two models, and plotting both of the forecasts took right around \u003cstrong\u003e25 seconds\u003c/strong\u003e.\u003c/p\u003e\n\u003cp\u003eI would love to see this tool in the hands of an actual data scientist to see the accuracy of the models they'd be able to create using Prophet.\u003c/p\u003e\n\u003chr\u003e\n","markdown":"\n## tl;dr\n\n### Goal\n_To apply Facebook's Prophet forecasting procedure to historical SPY (SPDR S\u0026P 500 ETF Trust) market data to gather future pricing predictions._\n\n### A few notes\n- I'm by no means a data scientist, so this is more of an exploratory analysis than an accurate one\n- For sake of brevity, I won't be using a training/test split or measuring the error of the model, I will just train the model on the entire dataset and then make a prediction\n\n### Process overview\n1. **Downloading the data** - exporting the data from Yahoo Finance as a CSV\n2. **Exploring the data** - loading and exploring the data using Pandas\n3. **Fitting the model** - reading in the data and applying a basic fit of the Prophet model to the data\n4. **Visualizing the forecast** - visualizing the forecasted pricing data\n\n### Python dependencies\n```python\nimport pandas as pd\nfrom prophet import Prophet\n```\n\n\u003cp style=\"background-color: orange; padding: 7px 20px; border-radius: 6px;\"\u003e\n    \u003cb\u003eImportant\u003c/b\u003e This article is not investment advice, please conduct your own due diligence. This is merely a simple analysis.\n\u003c/p\u003e\n\n---\n\nBefore we jump in, let's give a little background on SPY and on Facebook's Prophet.\n\nThe _SPDR S\u0026P 500 ETF Trust_ (SPY) is an ETF (_Exchange Traded Fund_) that tracks the performance of the S\u0026P 500 index.  SPY is also the largest ETF in the world, and is popular compared to other ETFs that track the S\u0026P 500 because of the high volume, or the number of shares that trade on a given day (we'll be able to see the volume per day in the CSV we export from Yahoo Finance).\n\nFor more information on ETFs, [Investopedia gives a good overview](https://www.investopedia.com/terms/e/etf.asp).\n\n[Facebook Prophet](https://facebook.github.io/prophet/) is an open source, automated forecasting procedure for time series data.  I'm not going to dive too much into the mathematics or implementation details of Prophet, but if you are more interested, you can read the [research paper](https://peerj.com/preprints/3190/).  Prophet makes it easy to handle outliers, adjust to different time intervals, deal with holidays, and leaves the ability to easily tune the forecasting model.\n\nNow that we have a general idea of what we're trying to predict and the tool we'll use to forecast, let's dive into the actual data.\n\n---\n\n## Downloading the data\nThanks to Yahoo Finance, we can download historical pricing data for free. You can click [here](https://finance.yahoo.com/quote/SPY/history?p=SPY) to view the SPY historical pricing data.\n\nClick on the `Historical Data` tab, and then we can adjust our `Time Period` to the Max as seen below (back to January 1993).\n\n![Historical pricing data {priority}{680x243}](/images/forecasting-spy/export-data.jpg)\n\nNow we can click download to get our CSV and start diving into the data.\n\n---\n\n## Exploring the data\nLet's fire up Pandas and load our data into a DataFrame to see what general insights we can extract.\n\n```python\ndf = pd.read_csv('SPY.csv')\n\n# Columns and row count\ndf.info()\n\"\"\"\n\u003cclass 'pandas.core.frame.DataFrame'\u003e\nRangeIndex: 7125 entries, 0 to 7124\nData columns (total 7 columns):\n #   Column     Non-Null Count  Dtype  \n---  ------     --------------  -----  \n 0   Date       7125 non-null   object \n 1   Open       7125 non-null   float64\n 2   High       7125 non-null   float64\n 3   Low        7125 non-null   float64\n 4   Close      7125 non-null   float64\n 5   Adj Close  7125 non-null   float64\n 6   Volume     7125 non-null   int64  \ndtypes: float64(5), int64(1), object(1)\nmemory usage: 389.8+ KB\n\"\"\"\n\n# Preview of the data\ndf.head()\n\"\"\"\n         Date      Open      High       Low     Close  Adj Close   Volume\n0  1993-01-29  43.96875  43.96875  43.75000  43.93750  25.884184  1003200\n1  1993-02-01  43.96875  44.25000  43.96875  44.25000  26.068277   480500\n2  1993-02-02  44.21875  44.37500  44.12500  44.34375  26.123499   201300\n3  1993-02-03  44.40625  44.84375  44.37500  44.81250  26.399649   529400\n4  1993-02-04  44.96875  45.09375  44.46875  45.00000  26.510111   531500\n\"\"\"\n\n# General statistics\ndf.describe().loc[['mean', 'min', 'max']]\n\"\"\"\n            Open        High         Low       Close   Adj Close        Volume\nmean  146.896395  147.766581  145.928716  146.896373  121.611954  8.453727e+07\nmin    43.343750   43.531250   42.812500   43.406250   25.571209  5.200000e+03\nmax   422.500000  422.820007  419.160004  422.119995  422.119995  8.710263e+08\n\"\"\"\n\n# Day to day percent changes of Highs\ndf[['Date', 'High']].set_index('Date').pct_change().reset_index()\n\"\"\"\n            Date      High\n0     1993-01-29       NaN\n1     1993-02-01  0.006397\n2     1993-02-02  0.002825\n3     1993-02-03  0.010563\n4     1993-02-04  0.005575\n         ...       ...\n7120  2021-05-10 -0.000189\n7121  2021-05-11 -0.017670\n7122  2021-05-12 -0.006454\n7123  2021-05-13 -0.000582\n7124  2021-05-14  0.012465\n\n[7125 rows x 2 columns]\n\"\"\"\n```\n\nNow that we know a bit more about our data in general, we can create a model using Prophet.\n\n---\n\n## Fitting the model\n\nSince we're not concerned in this post about making our model the best it can be, we can train our model on the entire dataset.\n\nThis typically isn't a good practice.  When trying to make an accurate prediction, you should use training and test subsets of the data and calculate errors within your model and use those results to tune hyperparameters.\n\nNevertheless, let's continue.\n\n```python\n# The prophet model fits to a DataFrame with a date column (ds)\n# and a value to predict (y)\ndf_predict = df[['Date', 'Close']]\ndf_predict.columns = ['ds', 'y']\n\n# We can find all of the missing days within our dataset\n# and mark those as \"holidays\"\ndate_series = pd.to_datetime(df['Date'])\ndf_missing_dates = pd\\\n    .date_range(start=date_series.min(), end=date_series.max())\\\n    .difference(date_series)\\\n    .to_frame()\\\n    .reset_index()\ndf_missing_dates.columns = ['holiday', 'ds']\ndf_missing_dates['holiday'] = 'Stock Market Closed'\n\n# Fitting our model is incredibly simple and can be done in the\n# most basic sense in just two lines of code\nm = Prophet(daily_seasonality=True, holidays=df_missing_dates)\nm.fit(df_predict)\n```\n\nJust like that, we have built our model for a forecast.  All we have left to do is generate dates to predict values for, and run the actual prediction.\n\n---\n\n## Visualizing the forecast\nNow let's forecast with our model and visualize the results.\n\n```python\n# Create a DataFrame with past and future dates (only weekdays)\nfuture = m.make_future_dataframe(periods=365)\nfuture = future[pd.to_datetime(future['ds']).dt.weekday \u003c 5]\n\n# Now we can forecast and visualize in just two more lines of code\nforecast = m.predict(future)\nm.plot(forecast, xlabel='Date', ylabel='Daily Closing Price')\n```\n\n![First SPY forecast {800x480}](/images/forecasting-spy/first-prediction.jpg)\n\n\u003e **A few things to notice**\n\u003e - The black dots are the training data points\n\u003e - The blue outline is the confidence interval\n\u003e - The line within the confidence interval is the actual forecast\n\nBased on our results, we can see the forecast is fairly linear and the confidence interval is relatively narrow (due to the volume of date).  The behavior of the stock market since Covid-19 started back around February 2020 has be a little unorthodox, so let's narrow our model to be trained back to data starting in 2017 to see if there is an effect.\n\n```python\n# Narrow down to start at 2017\ndf_recent_predict = df_predict.iloc[date_series[date_series.dt.year \u003e 2016].index]\ndate_series = pd.to_datetime(df_recent_predict['ds'])\ndf_recent_missing_dates =  pd\\\n    .date_range(start=date_series.min(), end=date_series.max())\\\n    .difference(date_series)\\\n    .to_frame()\\\n    .reset_index()\ndf_recent_missing_dates.columns = ['holiday', 'ds']\ndf_recent_missing_dates['holiday'] = 'Stock Market Closed'\n\n# Create and fit our new model\nm = Prophet(daily_seasonality=True, holidays=df_recent_missing_dates)\nm.fit(df_recent_predict)\n\n# Recreate our future predictions\nfuture = m.make_future_dataframe(periods=365)\nfuture = future[pd.to_datetime(future['ds']).dt.weekday \u003c 5]\n\n# Forecast and visualize\nforecast = m.predict(future)\nm.plot(forecast, xlabel='Date', ylabel='Daily Closing Price')\n```\n\n![Second SPY forecast {800x480}](/images/forecasting-spy/second-prediction.jpg)\n\nNow we can see a much wider confidence interval and a bit more of a bumpy forecast line; however, this looks much more realistic in terms of stock market prediction.\n\n---\n\n## Conclusion\n\nAll in all, Facebook's Prophet is a very fast, impressive, and strongly abstracted library.  The entire script, including reading in the data, training and forecasting two models, and plotting both of the forecasts took right around **25 seconds**.\n\nI would love to see this tool in the hands of an actual data scientist to see the accuracy of the models they'd be able to create using Prophet.\n\n---\n","title":"Forecasting SPY prices using Facebook's Prophet","date":"2021-05-19","tags":["python","pandas","data-analysis"],"description":"Using Facebook‚Äôs Prophet, an open-source, time series forecasting procedure to predict SPY (SPDR S\u0026P 500 ETF Trust) closing prices."},{"id":"visualizing-your-linkedin-connections","contentHtml":"\u003ch2\u003etl;dr\u003c/h2\u003e\n\u003ch3\u003eGoal\u003c/h3\u003e\n\u003cp\u003e\u003cem\u003eTo understand and visualize the companies within my directly connected network on LinkedIn\u003c/em\u003e\u003c/p\u003e\n\u003ch3\u003eProcess overview\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eLinkedIn data sources\u003c/strong\u003e - retrieving LinkedIn Network data from a \"Get a copy of your data\" CSV export\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eDiving into the data\u003c/strong\u003e - exploring, cleaning, and aggregating the data with \u003ca href=\"https://pandas.pydata.org/\"\u003e\u003ccode\u003ePandas\u003c/code\u003e\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eCreating the network\u003c/strong\u003e - creating a network graph using \u003ca href=\"https://networkx.org/\"\u003e\u003ccode\u003eNetworkX\u003c/code\u003e\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eVisualization\u003c/strong\u003e - visualizing the network with \u003ca href=\"https://pyvis.readthedocs.io/en/latest/\"\u003e\u003ccode\u003epyvis\u003c/code\u003e\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eImproving the output\u003c/strong\u003e - cleaning up the network graph with additional filtering\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3\u003eResults\u003c/h3\u003e\n\u003cp\u003e\u003cem\u003eHover over the nodes for more details\u003c/em\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"/network/first-nx-graph.html\"\u003eThe first network graph\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/network/second-nx-graph.html\"\u003eThe second (more specific) network graph\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003ePython dependencies\u003c/h3\u003e\n\u003cpre\u003e\u003ccode\u003e# Python standard library\nfrom difflib import get_close_matches\n\n# 3rd party\nimport networkx as nx\nimport pandas as pd\nfrom pyvis.network import Network\n\u003c/code\u003e\u003c/pre\u003e\n\u003chr\u003e\n\u003cp\u003eRecently, I was exploring \u003ca href=\"https://www.linkedin.com/in/bradley-schoeneweis/\"\u003emy LinkedIn\u003c/a\u003e network to see what some of my colleagues from high school and undergrad are currently up to.\u003c/p\u003e\n\u003cp\u003eAs I was scrolling through the connections page, I noticed LinkedIn gives you options to filter and searching with ease, but it doesn't really provide tools to learn about your network as a whole.\u003c/p\u003e\n\u003cp\u003eSo I decided to see if there was an easy way to export my network data to see what I could do with a few hours of exploring the data.\u003c/p\u003e\n\u003ch2\u003eLinkedIn data sources\u003c/h2\u003e\n\u003cp\u003eMy first thought was to checkout out the \u003ca href=\"https://www.linkedin.com/developers/\"\u003eLinkedIn's Developer API\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eSomething I do fairly frequently at my current job is integrating various 3rd-party REST APIs into our platform, so I wanted to see all the functionality and possibilities that this API would provide.\u003c/p\u003e\n\u003cp\u003eAfter reading through some documentation, I decided this wasn't a direction I wanted to pursue. Most of their developer products require approval, so I decided to look into other options.\u003c/p\u003e\n\u003cp\u003eAnother thought I had was to write a quick scraping script to pull down the HTML of my connections page and parse out names and companies, but I assumed there had to be a more simple way to get this data.\u003c/p\u003e\n\u003cp\u003eFinally, after a bit of research, I found that there are various \"Get a copy of your data\" reports that you can run within LinkedIn.  In order to get to these reports, you can do the following:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eOn the homepage toolbar, click the \u003cstrong\u003eMe\u003c/strong\u003e dropdown\u003c/li\u003e\n\u003cli\u003eUnder the \u003cem\u003eAccount\u003c/em\u003e section, click \u003cstrong\u003eSettings \u0026#x26; Privacy\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003eClick on \u003cstrong\u003eGet a copy of your data\u003c/strong\u003e, and you can view the various reports\u003c/li\u003e\n\u003cli\u003eSelect the reports you're interested in, for this, I just checked \u003cstrong\u003eConnections\u003c/strong\u003e\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eAfter requesting the report, it should only take a few minutes before you get an email saying your report is ready for export.\u003c/p\u003e\n\u003ch2\u003eDiving into the data\u003c/h2\u003e\n\u003cp\u003eTo reiterate our goal, we want to get a broad understanding of the companies within the first layer of our network (direct connections). Now, let's load up Python and learn more about this data in this CSV.\u003c/p\u003e\n\u003ch3\u003eReading in the data\u003c/h3\u003e\n\u003cp\u003eOnce the CSV is downloaded, we can open it up with Pandas and take a look (\u003cem\u003eoutput will be commented below\u003c/em\u003e).\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eimport pandas as pd\n\n# We want to skip the first three rows because of Notes at the top\ndf = pd.read_csv('Connections.csv', skiprows=3)\n\ndf.columns\n# ['First Name', 'Last Name', 'Email Address', 'Company', 'Position', 'Connected On',]\n\ndf.info()\n\"\"\"\n\u0026#x3C;class 'pandas.core.frame.DataFrame'\u003e\nRangeIndex: 376 entries, 0 to 375\nData columns (total 6 columns):\n #   Column         Non-Null Count  Dtype \n---  ------         --------------  ----- \n 0   First Name     375 non-null    object\n 1   Last Name      375 non-null    object\n 2   Email Address  1 non-null      object\n 3   Company        371 non-null    object\n 4   Position       371 non-null    object\n 5   Connected On   376 non-null    object\ndtypes: object(6)\nmemory usage: 17.8+ KB\n\"\"\"\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eI won't post the name's of any individuals or full rows to respect the privacy of my connections, but when I searched through the my Connections CSV, I noticed a few initial patterns that would help clean up the data.\u003c/p\u003e\n\u003ch3\u003eCleaning up the data\u003c/h3\u003e\n\u003cp\u003eAt first glance, the first thing I notice is connections who don't list a current company, so let's get rid of those.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003edf = df[df['Company'].notna()].sort_values(by='Company')\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eAfter sorting, another thing I noticed was that some of these company names belong to the same company, but the individuals wrote them differently.\u003c/p\u003e\n\u003cp\u003eAn example of this is \u003ccode\u003e'IBM Global Solution Center'\u003c/code\u003e and \u003ccode\u003e'IBM'\u003c/code\u003e; for our purposes, these should both be classified as \u003ccode\u003eIBM\u003c/code\u003e.\u003c/p\u003e\n\u003cp\u003eLet's run through a fuzzy match run using \u003ca href=\"https://docs.python.org/3/library/difflib.html#difflib.get_close_matches\"\u003edifflib's \u003ccode\u003eget_close_matches\u003c/code\u003e\u003c/a\u003e to try and bucket some of these similar company names.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003efrom difflib import get_close_matches\n\ncompanies = df['Company'].drop_duplicates()\n\n# cutoff=0.7 is a similarity ranking, and n=10 just takes the top 10 values\nsimilar_companies = {x: get_close_matches(x, companies, n=10, cutoff=0.7)\n                     for x in companies}\n\n# We are only interested in the entries that had another match\nsimilar_companies = {x: [name for name in y if name != x]\n                     for x, y in similar_companies.items() if len(y) \u003e 1}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eNow, this solution is not perfect, but it will help draw out some similar companies. You should still run a manual inspection of the data (the IBM example I gave above is one that doesn't show up in the fuzzy match results).\u003c/p\u003e\n\u003cp\u003eBased upon the results, let's group together some of the companies that had matches.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003edf['Company'] = df['Company'].replace({\n    'KPMG US': similar_companies['KPMG US'],\n    'Self-employed': similar_companies['Self-employed'],\n    'IBM Global Solution Center': 'IBM',\n})\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe next thing you may have noticed is that in our \u003ccode\u003esimilar_companies\u003c/code\u003e dictionary, we cleaned up a \u003ccode\u003eSelf-employed\u003c/code\u003e entry.\u003c/p\u003e\n\u003cp\u003eTo stay aligned with our goal, let's drop these entries, as well as your current company.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ecompanies_to_drop = ['self employed', 'your current company']\ndf = df[~df['Company'].str.lower().isin(companies_to_drop)]\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003eAggregating the data\u003c/h3\u003e\n\u003cp\u003eNow that our data is cleaned up a bit, let's aggregate and sum the number of connections for each of the companies.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003edf_company_counts = df['Company'].value_counts().reset_index()\ndf_company_counts.columns = ['Company', 'Count']  # For ease of understanding\ndf_company_counts = df_company_counts.sort_values(by='Count', ascending=False)\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2\u003eCreating the network\u003c/h2\u003e\n\u003cp\u003eWe have the numbers we want for each company, now let's jump into using \u003ccode\u003eNetworkX\u003c/code\u003e to recreate a network.\u003c/p\u003e\n\u003cp\u003eThe first step will be to initialize our graph, and add yourself as the central node, as it is your network.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eimport networkx as nx\n\nG = nx.Graph()\nG.add_node('Me')\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThen, we'll loop through our \u003ccode\u003edf_company_counts\u003c/code\u003e DataFrame and add each company as a node.\u003c/p\u003e\n\u003cp\u003e\u003cem\u003eYou'll notice some HTML tags in the title below, this is just to make it more readable for later\u003c/em\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003efor _, row in df_company_counts.iterrows():\n\t# The title will be for more information later on\n    title = '\u0026#x3C;b\u003e{0}\u0026#x3C;/b\u003e ({1})\u0026#x3C;br\u003e\u0026#x3C;hr\u003ePositions:\u0026#x3C;br\u003e'.format(row['Company'],\n    \t\t\t\t\t\t\t\t\t\t\t\t\t\trow['Count'])\n\n    # In addition to the full company name, let's add each position in a\n    # list to see the roles our connections have at these companies\n    position_list = ''.join('\u0026#x3C;li\u003e{}\u0026#x3C;/li\u003e'.format(x)\n    \t\t\t\t\t\tfor x in df[df['Company'] == row['Company']]['Position'])\n    title += '\u0026#x3C;ul\u003e{0}\u0026#x3C;/ul\u003e'.format(position_list)\n\n    # For ease of viewing, limit company names to 15 letters\n    node_name = row['Company']\n    if len(node_name) \u003e 15:\n        node_name = node_name[:15] + '...'\n\n    # Add the node and an edge connection ourself to the new node\n    G.add_node(node_name, weight=row['Count'], size=row['Count'] * 2, title=title)\n    G.add_edge('Me', node_name)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eAnd just like that, we've created our network of connections.\u003c/p\u003e\n\u003ch2\u003eVisualization\u003c/h2\u003e\n\u003cp\u003eOur network graph is created, so let's get into visualizing the network.\u003c/p\u003e\n\u003cp\u003eThere are a few options for visualizing networks including \u003ccode\u003ematplotlib.pyplot\u003c/code\u003e, but I found that \u003ccode\u003epyvis\u003c/code\u003e was the easiest to use for several reasons:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003epyvis\u003c/code\u003e generates an HTML file\u003c/li\u003e\n\u003cli\u003eCustomization is made very easy\u003c/li\u003e\n\u003cli\u003eThe graph is interactive by default\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eLet's look into generating this HTML file.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003efrom pyvis.network import Network\n\nnt = Network('100%', '100%', bgcolor='#222222', font_color='white')\nnt.from_nx(G)\nnt.repulsion()  # Spaces out the nodes\nnt.show('nx.html')\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eAnd it's that simple! We specify a width and height, optional styling attributes, and then we can generate the network graph visual straight from what we created with NetworkX.\u003c/p\u003e\n\u003cp\u003eNow we can see \u003ca href=\"/network/first-nx-graph.html\"\u003ethe network we generated\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eYou can hover over each node to see the total number of connections that work at the respective company, and below is a list of the positions held by your connections.\u003c/p\u003e\n\u003cp\u003eAs you can see, this is a bit hard to read into since there are a lot of nodes. Try and imagine reading this with +1,000 connections.\u003c/p\u003e\n\u003ch2\u003eImproving the output\u003c/h2\u003e\n\u003cp\u003eThere are a few ways that our network could be narrowed down.\u003c/p\u003e\n\u003cp\u003eBeing a \u003cem\u003eSoftware Developer\u003c/em\u003e, the thought that first occurred to me was to try and dial in on tech-related companies through known positions titles.\u003c/p\u003e\n\u003cp\u003eTo do this, I thought of a list of buzzwords/common job titles that I've seen across LinkedIn, and filtered down the initial DataFrame.\u003c/p\u003e\n\u003cp\u003eThen, we go through the same process we did in previous sections of generating and displaying the graph.\u003c/p\u003e\n\u003cp\u003e\u003cem\u003eAgain, this is not perfect, but it's a good starting point.\u003c/em\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e# Filter down from a list of popular tech positions\npositions = [\n    'developer', 'engineer', 'ai', 'analytics', 'software', 'cloud', 'cto',\n    'sde', 'sre', 'saas', 'product', 'engineering', 'scientist', 'data',\n]\ndf = df[df['Position'].str.contains('|'.join(positions), case=False)]\ndf_company_counts = df['Company'].value_counts().reset_index()\ndf_company_counts.columns = ['Company', 'Count']\ndf_company_counts = df_company_counts.sort_values(by='Count', ascending=False)\n\n# Re-initialize the graph and add the nodes/edges again\nG = nx.Graph()\nG.add_node('Me')\n\nfor _, row in df_company_counts.iterrows():\n    title = '\u0026#x3C;b\u003e{0}\u0026#x3C;/b\u003e ({1})\u0026#x3C;br\u003e\u0026#x3C;hr\u003ePositions:\u0026#x3C;br\u003e'.format(row['Company'], row['Count'])\n    position_list = ''.join('\u0026#x3C;li\u003e{}\u0026#x3C;/li\u003e'.format(x)\n    \t\t\t\t\t\tfor x in df[df['Company'] == row['Company']]['Position'])\n    title += '\u0026#x3C;ul\u003e{0}\u0026#x3C;/ul\u003e'.format(position_list)\n    node_name = row['Company']\n    if len(node_name) \u003e 15:\n        node_name = node_name[:15] + '...'\n\n    # Since there are less nodes, let's increase the sizes\n    G.add_node(node_name, weight=row['Count'], size=row['Count'] * 5, title=title)\n    G.add_edge('Me', node_name)\n\n# Generate the visualization\nnt = Network('100%', '100%', bgcolor='#222222', font_color='white')\nnt.from_nx(G)\nnt.repulsion()\nnt.show('nx.html')\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eNow, let's look at the \u003ca href=\"/network/second-nx-graph.html\"\u003eupdated results\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eMuch better! This is more readable and easier to interact with.\u003c/p\u003e\n\u003cp\u003eAnd just like that, we achieved our goal of gaining a broader understanding of the companies in our LinkedIn network.\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003e\u003cstrong\u003e\u003cem\u003ePossible improvements for those interested\u003c/em\u003e\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eScraping the profile location of each of your connections to segment by location\u003c/li\u003e\n\u003cli\u003eCompiling a list of companies you'd like to work for/are interested in and creating a filtering system\u003c/li\u003e\n\u003cli\u003eResearching salary data for positions and gathering average pay by company\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n","markdown":"\n## tl;dr\n\n### Goal\n_To understand and visualize the companies within my directly connected network on LinkedIn_\n\n### Process overview\n1. **LinkedIn data sources** - retrieving LinkedIn Network data from a \"Get a copy of your data\" CSV export\n2. **Diving into the data** - exploring, cleaning, and aggregating the data with [`Pandas`](https://pandas.pydata.org/)\n3. **Creating the network** - creating a network graph using [`NetworkX`](https://networkx.org/)\n4. **Visualization** - visualizing the network with [`pyvis`](https://pyvis.readthedocs.io/en/latest/)\n5. **Improving the output** - cleaning up the network graph with additional filtering\n\n### Results\n_Hover over the nodes for more details_\n- [The first network graph](/network/first-nx-graph.html)\n- [The second (more specific) network graph](/network/second-nx-graph.html)\n\n### Python dependencies\n```python\n# Python standard library\nfrom difflib import get_close_matches\n\n# 3rd party\nimport networkx as nx\nimport pandas as pd\nfrom pyvis.network import Network\n```\n\n---\n\nRecently, I was exploring [my LinkedIn](https://www.linkedin.com/in/bradley-schoeneweis/) network to see what some of my colleagues from high school and undergrad are currently up to.\n\nAs I was scrolling through the connections page, I noticed LinkedIn gives you options to filter and searching with ease, but it doesn't really provide tools to learn about your network as a whole.\n\nSo I decided to see if there was an easy way to export my network data to see what I could do with a few hours of exploring the data.\n\n\n## LinkedIn data sources\n\nMy first thought was to checkout out the [LinkedIn's Developer API](https://www.linkedin.com/developers/).\n\nSomething I do fairly frequently at my current job is integrating various 3rd-party REST APIs into our platform, so I wanted to see all the functionality and possibilities that this API would provide.\n\nAfter reading through some documentation, I decided this wasn't a direction I wanted to pursue. Most of their developer products require approval, so I decided to look into other options.\n\nAnother thought I had was to write a quick scraping script to pull down the HTML of my connections page and parse out names and companies, but I assumed there had to be a more simple way to get this data.\n\nFinally, after a bit of research, I found that there are various \"Get a copy of your data\" reports that you can run within LinkedIn.  In order to get to these reports, you can do the following:\n1. On the homepage toolbar, click the **Me** dropdown\n2. Under the _Account_ section, click **Settings \u0026 Privacy**\n3. Click on **Get a copy of your data**, and you can view the various reports\n4. Select the reports you're interested in, for this, I just checked **Connections**\n\nAfter requesting the report, it should only take a few minutes before you get an email saying your report is ready for export.\n\n\n## Diving into the data\n\nTo reiterate our goal, we want to get a broad understanding of the companies within the first layer of our network (direct connections). Now, let's load up Python and learn more about this data in this CSV.\n\n### Reading in the data\nOnce the CSV is downloaded, we can open it up with Pandas and take a look (_output will be commented below_).\n\n```python\nimport pandas as pd\n\n# We want to skip the first three rows because of Notes at the top\ndf = pd.read_csv('Connections.csv', skiprows=3)\n\ndf.columns\n# ['First Name', 'Last Name', 'Email Address', 'Company', 'Position', 'Connected On',]\n\ndf.info()\n\"\"\"\n\u003cclass 'pandas.core.frame.DataFrame'\u003e\nRangeIndex: 376 entries, 0 to 375\nData columns (total 6 columns):\n #   Column         Non-Null Count  Dtype \n---  ------         --------------  ----- \n 0   First Name     375 non-null    object\n 1   Last Name      375 non-null    object\n 2   Email Address  1 non-null      object\n 3   Company        371 non-null    object\n 4   Position       371 non-null    object\n 5   Connected On   376 non-null    object\ndtypes: object(6)\nmemory usage: 17.8+ KB\n\"\"\"\n```\n\nI won't post the name's of any individuals or full rows to respect the privacy of my connections, but when I searched through the my Connections CSV, I noticed a few initial patterns that would help clean up the data.\n\n### Cleaning up the data\n\nAt first glance, the first thing I notice is connections who don't list a current company, so let's get rid of those.\n\n```python\ndf = df[df['Company'].notna()].sort_values(by='Company')\n```\n\nAfter sorting, another thing I noticed was that some of these company names belong to the same company, but the individuals wrote them differently.\n\nAn example of this is `'IBM Global Solution Center'` and `'IBM'`; for our purposes, these should both be classified as `IBM`.\n\nLet's run through a fuzzy match run using [difflib's `get_close_matches`](https://docs.python.org/3/library/difflib.html#difflib.get_close_matches) to try and bucket some of these similar company names.\n```python\nfrom difflib import get_close_matches\n\ncompanies = df['Company'].drop_duplicates()\n\n# cutoff=0.7 is a similarity ranking, and n=10 just takes the top 10 values\nsimilar_companies = {x: get_close_matches(x, companies, n=10, cutoff=0.7)\n                     for x in companies}\n\n# We are only interested in the entries that had another match\nsimilar_companies = {x: [name for name in y if name != x]\n                     for x, y in similar_companies.items() if len(y) \u003e 1}\n```\n\nNow, this solution is not perfect, but it will help draw out some similar companies. You should still run a manual inspection of the data (the IBM example I gave above is one that doesn't show up in the fuzzy match results).\n\nBased upon the results, let's group together some of the companies that had matches.\n```python\ndf['Company'] = df['Company'].replace({\n    'KPMG US': similar_companies['KPMG US'],\n    'Self-employed': similar_companies['Self-employed'],\n    'IBM Global Solution Center': 'IBM',\n})\n```\n\nThe next thing you may have noticed is that in our `similar_companies` dictionary, we cleaned up a `Self-employed` entry.\n\nTo stay aligned with our goal, let's drop these entries, as well as your current company.\n```python\ncompanies_to_drop = ['self employed', 'your current company']\ndf = df[~df['Company'].str.lower().isin(companies_to_drop)]\n```\n\n### Aggregating the data\nNow that our data is cleaned up a bit, let's aggregate and sum the number of connections for each of the companies.\n\n```python\ndf_company_counts = df['Company'].value_counts().reset_index()\ndf_company_counts.columns = ['Company', 'Count']  # For ease of understanding\ndf_company_counts = df_company_counts.sort_values(by='Count', ascending=False)\n```\n\n## Creating the network\n\nWe have the numbers we want for each company, now let's jump into using `NetworkX` to recreate a network.\n\nThe first step will be to initialize our graph, and add yourself as the central node, as it is your network.\n\n```python\nimport networkx as nx\n\nG = nx.Graph()\nG.add_node('Me')\n```\n\nThen, we'll loop through our `df_company_counts` DataFrame and add each company as a node.\n\n_You'll notice some HTML tags in the title below, this is just to make it more readable for later_\n```python\nfor _, row in df_company_counts.iterrows():\n\t# The title will be for more information later on\n    title = '\u003cb\u003e{0}\u003c/b\u003e ({1})\u003cbr\u003e\u003chr\u003ePositions:\u003cbr\u003e'.format(row['Company'],\n    \t\t\t\t\t\t\t\t\t\t\t\t\t\trow['Count'])\n\n    # In addition to the full company name, let's add each position in a\n    # list to see the roles our connections have at these companies\n    position_list = ''.join('\u003cli\u003e{}\u003c/li\u003e'.format(x)\n    \t\t\t\t\t\tfor x in df[df['Company'] == row['Company']]['Position'])\n    title += '\u003cul\u003e{0}\u003c/ul\u003e'.format(position_list)\n\n    # For ease of viewing, limit company names to 15 letters\n    node_name = row['Company']\n    if len(node_name) \u003e 15:\n        node_name = node_name[:15] + '...'\n\n    # Add the node and an edge connection ourself to the new node\n    G.add_node(node_name, weight=row['Count'], size=row['Count'] * 2, title=title)\n    G.add_edge('Me', node_name)\n```\n\nAnd just like that, we've created our network of connections.\n\n\n## Visualization\n\nOur network graph is created, so let's get into visualizing the network.\n\nThere are a few options for visualizing networks including `matplotlib.pyplot`, but I found that `pyvis` was the easiest to use for several reasons:\n- `pyvis` generates an HTML file\n- Customization is made very easy\n- The graph is interactive by default\n\nLet's look into generating this HTML file.\n```python\nfrom pyvis.network import Network\n\nnt = Network('100%', '100%', bgcolor='#222222', font_color='white')\nnt.from_nx(G)\nnt.repulsion()  # Spaces out the nodes\nnt.show('nx.html')\n```\n\nAnd it's that simple! We specify a width and height, optional styling attributes, and then we can generate the network graph visual straight from what we created with NetworkX.\n\nNow we can see [the network we generated](/network/first-nx-graph.html).\n\nYou can hover over each node to see the total number of connections that work at the respective company, and below is a list of the positions held by your connections.\n\nAs you can see, this is a bit hard to read into since there are a lot of nodes. Try and imagine reading this with +1,000 connections.\n\n## Improving the output\n\nThere are a few ways that our network could be narrowed down.\n\nBeing a _Software Developer_, the thought that first occurred to me was to try and dial in on tech-related companies through known positions titles.\n\nTo do this, I thought of a list of buzzwords/common job titles that I've seen across LinkedIn, and filtered down the initial DataFrame.\n\nThen, we go through the same process we did in previous sections of generating and displaying the graph.\n\n_Again, this is not perfect, but it's a good starting point._\n```python\n# Filter down from a list of popular tech positions\npositions = [\n    'developer', 'engineer', 'ai', 'analytics', 'software', 'cloud', 'cto',\n    'sde', 'sre', 'saas', 'product', 'engineering', 'scientist', 'data',\n]\ndf = df[df['Position'].str.contains('|'.join(positions), case=False)]\ndf_company_counts = df['Company'].value_counts().reset_index()\ndf_company_counts.columns = ['Company', 'Count']\ndf_company_counts = df_company_counts.sort_values(by='Count', ascending=False)\n\n# Re-initialize the graph and add the nodes/edges again\nG = nx.Graph()\nG.add_node('Me')\n\nfor _, row in df_company_counts.iterrows():\n    title = '\u003cb\u003e{0}\u003c/b\u003e ({1})\u003cbr\u003e\u003chr\u003ePositions:\u003cbr\u003e'.format(row['Company'], row['Count'])\n    position_list = ''.join('\u003cli\u003e{}\u003c/li\u003e'.format(x)\n    \t\t\t\t\t\tfor x in df[df['Company'] == row['Company']]['Position'])\n    title += '\u003cul\u003e{0}\u003c/ul\u003e'.format(position_list)\n    node_name = row['Company']\n    if len(node_name) \u003e 15:\n        node_name = node_name[:15] + '...'\n\n    # Since there are less nodes, let's increase the sizes\n    G.add_node(node_name, weight=row['Count'], size=row['Count'] * 5, title=title)\n    G.add_edge('Me', node_name)\n\n# Generate the visualization\nnt = Network('100%', '100%', bgcolor='#222222', font_color='white')\nnt.from_nx(G)\nnt.repulsion()\nnt.show('nx.html')\n```\n\nNow, let's look at the [updated results](/network/second-nx-graph.html).\n\nMuch better! This is more readable and easier to interact with.\n\nAnd just like that, we achieved our goal of gaining a broader understanding of the companies in our LinkedIn network.\n\n---\n\n**_Possible improvements for those interested_**\n- Scraping the profile location of each of your connections to segment by location\n- Compiling a list of companies you'd like to work for/are interested in and creating a filtering system\n- Researching salary data for positions and gathering average pay by company\n\n---\n","title":"Visualizing your LinkedIn connections using Python","date":"2021-04-08","tags":["python","pandas","networkx","data-analysis"],"description":"Using Python's Pandas, NetworkX, and pyvis to understand and visualize companies within a directly connected LinkedIn network."}],"data-analysis":[{"id":"forecasting-spy-prices","contentHtml":"\u003ch2\u003etl;dr\u003c/h2\u003e\n\u003ch3\u003eGoal\u003c/h3\u003e\n\u003cp\u003e\u003cem\u003eTo apply Facebook's Prophet forecasting procedure to historical SPY (SPDR S\u0026#x26;P 500 ETF Trust) market data to gather future pricing predictions.\u003c/em\u003e\u003c/p\u003e\n\u003ch3\u003eA few notes\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eI'm by no means a data scientist, so this is more of an exploratory analysis than an accurate one\u003c/li\u003e\n\u003cli\u003eFor sake of brevity, I won't be using a training/test split or measuring the error of the model, I will just train the model on the entire dataset and then make a prediction\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003eProcess overview\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eDownloading the data\u003c/strong\u003e - exporting the data from Yahoo Finance as a CSV\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eExploring the data\u003c/strong\u003e - loading and exploring the data using Pandas\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eFitting the model\u003c/strong\u003e - reading in the data and applying a basic fit of the Prophet model to the data\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eVisualizing the forecast\u003c/strong\u003e - visualizing the forecasted pricing data\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3\u003ePython dependencies\u003c/h3\u003e\n\u003cpre\u003e\u003ccode\u003eimport pandas as pd\nfrom prophet import Prophet\n\u003c/code\u003e\u003c/pre\u003e\n\u003chr\u003e\n\u003cp\u003eBefore we jump in, let's give a little background on SPY and on Facebook's Prophet.\u003c/p\u003e\n\u003cp\u003eThe \u003cem\u003eSPDR S\u0026#x26;P 500 ETF Trust\u003c/em\u003e (SPY) is an ETF (\u003cem\u003eExchange Traded Fund\u003c/em\u003e) that tracks the performance of the S\u0026#x26;P 500 index.  SPY is also the largest ETF in the world, and is popular compared to other ETFs that track the S\u0026#x26;P 500 because of the high volume, or the number of shares that trade on a given day (we'll be able to see the volume per day in the CSV we export from Yahoo Finance).\u003c/p\u003e\n\u003cp\u003eFor more information on ETFs, \u003ca href=\"https://www.investopedia.com/terms/e/etf.asp\"\u003eInvestopedia gives a good overview\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://facebook.github.io/prophet/\"\u003eFacebook Prophet\u003c/a\u003e is an open source, automated forecasting procedure for time series data.  I'm not going to dive too much into the mathematics or implementation details of Prophet, but if you are more interested, you can read the \u003ca href=\"https://peerj.com/preprints/3190/\"\u003eresearch paper\u003c/a\u003e.  Prophet makes it easy to handle outliers, adjust to different time intervals, deal with holidays, and leaves the ability to easily tune the forecasting model.\u003c/p\u003e\n\u003cp\u003eNow that we have a general idea of what we're trying to predict and the tool we'll use to forecast, let's dive into the actual data.\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003eDownloading the data\u003c/h2\u003e\n\u003cp\u003eThanks to Yahoo Finance, we can download historical pricing data for free. You can click \u003ca href=\"https://finance.yahoo.com/quote/SPY/history?p=SPY\"\u003ehere\u003c/a\u003e to view the SPY historical pricing data.\u003c/p\u003e\n\u003cp\u003eClick on the \u003ccode\u003eHistorical Data\u003c/code\u003e tab, and then we can adjust our \u003ccode\u003eTime Period\u003c/code\u003e to the Max as seen below (back to January 1993).\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/forecasting-spy/export-data.jpg\" alt=\"Historical pricing data {priority}{680x243}\"\u003e\u003c/p\u003e\n\u003cp\u003eNow we can click download to get our CSV and start diving into the data.\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003eExploring the data\u003c/h2\u003e\n\u003cp\u003eLet's fire up Pandas and load our data into a DataFrame to see what general insights we can extract.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003edf = pd.read_csv('SPY.csv')\n\n# Columns and row count\ndf.info()\n\"\"\"\n\u0026#x3C;class 'pandas.core.frame.DataFrame'\u003e\nRangeIndex: 7125 entries, 0 to 7124\nData columns (total 7 columns):\n #   Column     Non-Null Count  Dtype  \n---  ------     --------------  -----  \n 0   Date       7125 non-null   object \n 1   Open       7125 non-null   float64\n 2   High       7125 non-null   float64\n 3   Low        7125 non-null   float64\n 4   Close      7125 non-null   float64\n 5   Adj Close  7125 non-null   float64\n 6   Volume     7125 non-null   int64  \ndtypes: float64(5), int64(1), object(1)\nmemory usage: 389.8+ KB\n\"\"\"\n\n# Preview of the data\ndf.head()\n\"\"\"\n         Date      Open      High       Low     Close  Adj Close   Volume\n0  1993-01-29  43.96875  43.96875  43.75000  43.93750  25.884184  1003200\n1  1993-02-01  43.96875  44.25000  43.96875  44.25000  26.068277   480500\n2  1993-02-02  44.21875  44.37500  44.12500  44.34375  26.123499   201300\n3  1993-02-03  44.40625  44.84375  44.37500  44.81250  26.399649   529400\n4  1993-02-04  44.96875  45.09375  44.46875  45.00000  26.510111   531500\n\"\"\"\n\n# General statistics\ndf.describe().loc[['mean', 'min', 'max']]\n\"\"\"\n            Open        High         Low       Close   Adj Close        Volume\nmean  146.896395  147.766581  145.928716  146.896373  121.611954  8.453727e+07\nmin    43.343750   43.531250   42.812500   43.406250   25.571209  5.200000e+03\nmax   422.500000  422.820007  419.160004  422.119995  422.119995  8.710263e+08\n\"\"\"\n\n# Day to day percent changes of Highs\ndf[['Date', 'High']].set_index('Date').pct_change().reset_index()\n\"\"\"\n            Date      High\n0     1993-01-29       NaN\n1     1993-02-01  0.006397\n2     1993-02-02  0.002825\n3     1993-02-03  0.010563\n4     1993-02-04  0.005575\n         ...       ...\n7120  2021-05-10 -0.000189\n7121  2021-05-11 -0.017670\n7122  2021-05-12 -0.006454\n7123  2021-05-13 -0.000582\n7124  2021-05-14  0.012465\n\n[7125 rows x 2 columns]\n\"\"\"\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eNow that we know a bit more about our data in general, we can create a model using Prophet.\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003eFitting the model\u003c/h2\u003e\n\u003cp\u003eSince we're not concerned in this post about making our model the best it can be, we can train our model on the entire dataset.\u003c/p\u003e\n\u003cp\u003eThis typically isn't a good practice.  When trying to make an accurate prediction, you should use training and test subsets of the data and calculate errors within your model and use those results to tune hyperparameters.\u003c/p\u003e\n\u003cp\u003eNevertheless, let's continue.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e# The prophet model fits to a DataFrame with a date column (ds)\n# and a value to predict (y)\ndf_predict = df[['Date', 'Close']]\ndf_predict.columns = ['ds', 'y']\n\n# We can find all of the missing days within our dataset\n# and mark those as \"holidays\"\ndate_series = pd.to_datetime(df['Date'])\ndf_missing_dates = pd\\\n    .date_range(start=date_series.min(), end=date_series.max())\\\n    .difference(date_series)\\\n    .to_frame()\\\n    .reset_index()\ndf_missing_dates.columns = ['holiday', 'ds']\ndf_missing_dates['holiday'] = 'Stock Market Closed'\n\n# Fitting our model is incredibly simple and can be done in the\n# most basic sense in just two lines of code\nm = Prophet(daily_seasonality=True, holidays=df_missing_dates)\nm.fit(df_predict)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eJust like that, we have built our model for a forecast.  All we have left to do is generate dates to predict values for, and run the actual prediction.\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003eVisualizing the forecast\u003c/h2\u003e\n\u003cp\u003eNow let's forecast with our model and visualize the results.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e# Create a DataFrame with past and future dates (only weekdays)\nfuture = m.make_future_dataframe(periods=365)\nfuture = future[pd.to_datetime(future['ds']).dt.weekday \u0026#x3C; 5]\n\n# Now we can forecast and visualize in just two more lines of code\nforecast = m.predict(future)\nm.plot(forecast, xlabel='Date', ylabel='Daily Closing Price')\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cimg src=\"/images/forecasting-spy/first-prediction.jpg\" alt=\"First SPY forecast {800x480}\"\u003e\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003eA few things to notice\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eThe black dots are the training data points\u003c/li\u003e\n\u003cli\u003eThe blue outline is the confidence interval\u003c/li\u003e\n\u003cli\u003eThe line within the confidence interval is the actual forecast\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eBased on our results, we can see the forecast is fairly linear and the confidence interval is relatively narrow (due to the volume of date).  The behavior of the stock market since Covid-19 started back around February 2020 has be a little unorthodox, so let's narrow our model to be trained back to data starting in 2017 to see if there is an effect.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e# Narrow down to start at 2017\ndf_recent_predict = df_predict.iloc[date_series[date_series.dt.year \u003e 2016].index]\ndate_series = pd.to_datetime(df_recent_predict['ds'])\ndf_recent_missing_dates =  pd\\\n    .date_range(start=date_series.min(), end=date_series.max())\\\n    .difference(date_series)\\\n    .to_frame()\\\n    .reset_index()\ndf_recent_missing_dates.columns = ['holiday', 'ds']\ndf_recent_missing_dates['holiday'] = 'Stock Market Closed'\n\n# Create and fit our new model\nm = Prophet(daily_seasonality=True, holidays=df_recent_missing_dates)\nm.fit(df_recent_predict)\n\n# Recreate our future predictions\nfuture = m.make_future_dataframe(periods=365)\nfuture = future[pd.to_datetime(future['ds']).dt.weekday \u0026#x3C; 5]\n\n# Forecast and visualize\nforecast = m.predict(future)\nm.plot(forecast, xlabel='Date', ylabel='Daily Closing Price')\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cimg src=\"/images/forecasting-spy/second-prediction.jpg\" alt=\"Second SPY forecast {800x480}\"\u003e\u003c/p\u003e\n\u003cp\u003eNow we can see a much wider confidence interval and a bit more of a bumpy forecast line; however, this looks much more realistic in terms of stock market prediction.\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003eConclusion\u003c/h2\u003e\n\u003cp\u003eAll in all, Facebook's Prophet is a very fast, impressive, and strongly abstracted library.  The entire script, including reading in the data, training and forecasting two models, and plotting both of the forecasts took right around \u003cstrong\u003e25 seconds\u003c/strong\u003e.\u003c/p\u003e\n\u003cp\u003eI would love to see this tool in the hands of an actual data scientist to see the accuracy of the models they'd be able to create using Prophet.\u003c/p\u003e\n\u003chr\u003e\n","markdown":"\n## tl;dr\n\n### Goal\n_To apply Facebook's Prophet forecasting procedure to historical SPY (SPDR S\u0026P 500 ETF Trust) market data to gather future pricing predictions._\n\n### A few notes\n- I'm by no means a data scientist, so this is more of an exploratory analysis than an accurate one\n- For sake of brevity, I won't be using a training/test split or measuring the error of the model, I will just train the model on the entire dataset and then make a prediction\n\n### Process overview\n1. **Downloading the data** - exporting the data from Yahoo Finance as a CSV\n2. **Exploring the data** - loading and exploring the data using Pandas\n3. **Fitting the model** - reading in the data and applying a basic fit of the Prophet model to the data\n4. **Visualizing the forecast** - visualizing the forecasted pricing data\n\n### Python dependencies\n```python\nimport pandas as pd\nfrom prophet import Prophet\n```\n\n\u003cp style=\"background-color: orange; padding: 7px 20px; border-radius: 6px;\"\u003e\n    \u003cb\u003eImportant\u003c/b\u003e This article is not investment advice, please conduct your own due diligence. This is merely a simple analysis.\n\u003c/p\u003e\n\n---\n\nBefore we jump in, let's give a little background on SPY and on Facebook's Prophet.\n\nThe _SPDR S\u0026P 500 ETF Trust_ (SPY) is an ETF (_Exchange Traded Fund_) that tracks the performance of the S\u0026P 500 index.  SPY is also the largest ETF in the world, and is popular compared to other ETFs that track the S\u0026P 500 because of the high volume, or the number of shares that trade on a given day (we'll be able to see the volume per day in the CSV we export from Yahoo Finance).\n\nFor more information on ETFs, [Investopedia gives a good overview](https://www.investopedia.com/terms/e/etf.asp).\n\n[Facebook Prophet](https://facebook.github.io/prophet/) is an open source, automated forecasting procedure for time series data.  I'm not going to dive too much into the mathematics or implementation details of Prophet, but if you are more interested, you can read the [research paper](https://peerj.com/preprints/3190/).  Prophet makes it easy to handle outliers, adjust to different time intervals, deal with holidays, and leaves the ability to easily tune the forecasting model.\n\nNow that we have a general idea of what we're trying to predict and the tool we'll use to forecast, let's dive into the actual data.\n\n---\n\n## Downloading the data\nThanks to Yahoo Finance, we can download historical pricing data for free. You can click [here](https://finance.yahoo.com/quote/SPY/history?p=SPY) to view the SPY historical pricing data.\n\nClick on the `Historical Data` tab, and then we can adjust our `Time Period` to the Max as seen below (back to January 1993).\n\n![Historical pricing data {priority}{680x243}](/images/forecasting-spy/export-data.jpg)\n\nNow we can click download to get our CSV and start diving into the data.\n\n---\n\n## Exploring the data\nLet's fire up Pandas and load our data into a DataFrame to see what general insights we can extract.\n\n```python\ndf = pd.read_csv('SPY.csv')\n\n# Columns and row count\ndf.info()\n\"\"\"\n\u003cclass 'pandas.core.frame.DataFrame'\u003e\nRangeIndex: 7125 entries, 0 to 7124\nData columns (total 7 columns):\n #   Column     Non-Null Count  Dtype  \n---  ------     --------------  -----  \n 0   Date       7125 non-null   object \n 1   Open       7125 non-null   float64\n 2   High       7125 non-null   float64\n 3   Low        7125 non-null   float64\n 4   Close      7125 non-null   float64\n 5   Adj Close  7125 non-null   float64\n 6   Volume     7125 non-null   int64  \ndtypes: float64(5), int64(1), object(1)\nmemory usage: 389.8+ KB\n\"\"\"\n\n# Preview of the data\ndf.head()\n\"\"\"\n         Date      Open      High       Low     Close  Adj Close   Volume\n0  1993-01-29  43.96875  43.96875  43.75000  43.93750  25.884184  1003200\n1  1993-02-01  43.96875  44.25000  43.96875  44.25000  26.068277   480500\n2  1993-02-02  44.21875  44.37500  44.12500  44.34375  26.123499   201300\n3  1993-02-03  44.40625  44.84375  44.37500  44.81250  26.399649   529400\n4  1993-02-04  44.96875  45.09375  44.46875  45.00000  26.510111   531500\n\"\"\"\n\n# General statistics\ndf.describe().loc[['mean', 'min', 'max']]\n\"\"\"\n            Open        High         Low       Close   Adj Close        Volume\nmean  146.896395  147.766581  145.928716  146.896373  121.611954  8.453727e+07\nmin    43.343750   43.531250   42.812500   43.406250   25.571209  5.200000e+03\nmax   422.500000  422.820007  419.160004  422.119995  422.119995  8.710263e+08\n\"\"\"\n\n# Day to day percent changes of Highs\ndf[['Date', 'High']].set_index('Date').pct_change().reset_index()\n\"\"\"\n            Date      High\n0     1993-01-29       NaN\n1     1993-02-01  0.006397\n2     1993-02-02  0.002825\n3     1993-02-03  0.010563\n4     1993-02-04  0.005575\n         ...       ...\n7120  2021-05-10 -0.000189\n7121  2021-05-11 -0.017670\n7122  2021-05-12 -0.006454\n7123  2021-05-13 -0.000582\n7124  2021-05-14  0.012465\n\n[7125 rows x 2 columns]\n\"\"\"\n```\n\nNow that we know a bit more about our data in general, we can create a model using Prophet.\n\n---\n\n## Fitting the model\n\nSince we're not concerned in this post about making our model the best it can be, we can train our model on the entire dataset.\n\nThis typically isn't a good practice.  When trying to make an accurate prediction, you should use training and test subsets of the data and calculate errors within your model and use those results to tune hyperparameters.\n\nNevertheless, let's continue.\n\n```python\n# The prophet model fits to a DataFrame with a date column (ds)\n# and a value to predict (y)\ndf_predict = df[['Date', 'Close']]\ndf_predict.columns = ['ds', 'y']\n\n# We can find all of the missing days within our dataset\n# and mark those as \"holidays\"\ndate_series = pd.to_datetime(df['Date'])\ndf_missing_dates = pd\\\n    .date_range(start=date_series.min(), end=date_series.max())\\\n    .difference(date_series)\\\n    .to_frame()\\\n    .reset_index()\ndf_missing_dates.columns = ['holiday', 'ds']\ndf_missing_dates['holiday'] = 'Stock Market Closed'\n\n# Fitting our model is incredibly simple and can be done in the\n# most basic sense in just two lines of code\nm = Prophet(daily_seasonality=True, holidays=df_missing_dates)\nm.fit(df_predict)\n```\n\nJust like that, we have built our model for a forecast.  All we have left to do is generate dates to predict values for, and run the actual prediction.\n\n---\n\n## Visualizing the forecast\nNow let's forecast with our model and visualize the results.\n\n```python\n# Create a DataFrame with past and future dates (only weekdays)\nfuture = m.make_future_dataframe(periods=365)\nfuture = future[pd.to_datetime(future['ds']).dt.weekday \u003c 5]\n\n# Now we can forecast and visualize in just two more lines of code\nforecast = m.predict(future)\nm.plot(forecast, xlabel='Date', ylabel='Daily Closing Price')\n```\n\n![First SPY forecast {800x480}](/images/forecasting-spy/first-prediction.jpg)\n\n\u003e **A few things to notice**\n\u003e - The black dots are the training data points\n\u003e - The blue outline is the confidence interval\n\u003e - The line within the confidence interval is the actual forecast\n\nBased on our results, we can see the forecast is fairly linear and the confidence interval is relatively narrow (due to the volume of date).  The behavior of the stock market since Covid-19 started back around February 2020 has be a little unorthodox, so let's narrow our model to be trained back to data starting in 2017 to see if there is an effect.\n\n```python\n# Narrow down to start at 2017\ndf_recent_predict = df_predict.iloc[date_series[date_series.dt.year \u003e 2016].index]\ndate_series = pd.to_datetime(df_recent_predict['ds'])\ndf_recent_missing_dates =  pd\\\n    .date_range(start=date_series.min(), end=date_series.max())\\\n    .difference(date_series)\\\n    .to_frame()\\\n    .reset_index()\ndf_recent_missing_dates.columns = ['holiday', 'ds']\ndf_recent_missing_dates['holiday'] = 'Stock Market Closed'\n\n# Create and fit our new model\nm = Prophet(daily_seasonality=True, holidays=df_recent_missing_dates)\nm.fit(df_recent_predict)\n\n# Recreate our future predictions\nfuture = m.make_future_dataframe(periods=365)\nfuture = future[pd.to_datetime(future['ds']).dt.weekday \u003c 5]\n\n# Forecast and visualize\nforecast = m.predict(future)\nm.plot(forecast, xlabel='Date', ylabel='Daily Closing Price')\n```\n\n![Second SPY forecast {800x480}](/images/forecasting-spy/second-prediction.jpg)\n\nNow we can see a much wider confidence interval and a bit more of a bumpy forecast line; however, this looks much more realistic in terms of stock market prediction.\n\n---\n\n## Conclusion\n\nAll in all, Facebook's Prophet is a very fast, impressive, and strongly abstracted library.  The entire script, including reading in the data, training and forecasting two models, and plotting both of the forecasts took right around **25 seconds**.\n\nI would love to see this tool in the hands of an actual data scientist to see the accuracy of the models they'd be able to create using Prophet.\n\n---\n","title":"Forecasting SPY prices using Facebook's Prophet","date":"2021-05-19","tags":["python","pandas","data-analysis"],"description":"Using Facebook‚Äôs Prophet, an open-source, time series forecasting procedure to predict SPY (SPDR S\u0026P 500 ETF Trust) closing prices."},{"id":"visualizing-your-linkedin-connections","contentHtml":"\u003ch2\u003etl;dr\u003c/h2\u003e\n\u003ch3\u003eGoal\u003c/h3\u003e\n\u003cp\u003e\u003cem\u003eTo understand and visualize the companies within my directly connected network on LinkedIn\u003c/em\u003e\u003c/p\u003e\n\u003ch3\u003eProcess overview\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eLinkedIn data sources\u003c/strong\u003e - retrieving LinkedIn Network data from a \"Get a copy of your data\" CSV export\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eDiving into the data\u003c/strong\u003e - exploring, cleaning, and aggregating the data with \u003ca href=\"https://pandas.pydata.org/\"\u003e\u003ccode\u003ePandas\u003c/code\u003e\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eCreating the network\u003c/strong\u003e - creating a network graph using \u003ca href=\"https://networkx.org/\"\u003e\u003ccode\u003eNetworkX\u003c/code\u003e\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eVisualization\u003c/strong\u003e - visualizing the network with \u003ca href=\"https://pyvis.readthedocs.io/en/latest/\"\u003e\u003ccode\u003epyvis\u003c/code\u003e\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eImproving the output\u003c/strong\u003e - cleaning up the network graph with additional filtering\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3\u003eResults\u003c/h3\u003e\n\u003cp\u003e\u003cem\u003eHover over the nodes for more details\u003c/em\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"/network/first-nx-graph.html\"\u003eThe first network graph\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/network/second-nx-graph.html\"\u003eThe second (more specific) network graph\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003ePython dependencies\u003c/h3\u003e\n\u003cpre\u003e\u003ccode\u003e# Python standard library\nfrom difflib import get_close_matches\n\n# 3rd party\nimport networkx as nx\nimport pandas as pd\nfrom pyvis.network import Network\n\u003c/code\u003e\u003c/pre\u003e\n\u003chr\u003e\n\u003cp\u003eRecently, I was exploring \u003ca href=\"https://www.linkedin.com/in/bradley-schoeneweis/\"\u003emy LinkedIn\u003c/a\u003e network to see what some of my colleagues from high school and undergrad are currently up to.\u003c/p\u003e\n\u003cp\u003eAs I was scrolling through the connections page, I noticed LinkedIn gives you options to filter and searching with ease, but it doesn't really provide tools to learn about your network as a whole.\u003c/p\u003e\n\u003cp\u003eSo I decided to see if there was an easy way to export my network data to see what I could do with a few hours of exploring the data.\u003c/p\u003e\n\u003ch2\u003eLinkedIn data sources\u003c/h2\u003e\n\u003cp\u003eMy first thought was to checkout out the \u003ca href=\"https://www.linkedin.com/developers/\"\u003eLinkedIn's Developer API\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eSomething I do fairly frequently at my current job is integrating various 3rd-party REST APIs into our platform, so I wanted to see all the functionality and possibilities that this API would provide.\u003c/p\u003e\n\u003cp\u003eAfter reading through some documentation, I decided this wasn't a direction I wanted to pursue. Most of their developer products require approval, so I decided to look into other options.\u003c/p\u003e\n\u003cp\u003eAnother thought I had was to write a quick scraping script to pull down the HTML of my connections page and parse out names and companies, but I assumed there had to be a more simple way to get this data.\u003c/p\u003e\n\u003cp\u003eFinally, after a bit of research, I found that there are various \"Get a copy of your data\" reports that you can run within LinkedIn.  In order to get to these reports, you can do the following:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eOn the homepage toolbar, click the \u003cstrong\u003eMe\u003c/strong\u003e dropdown\u003c/li\u003e\n\u003cli\u003eUnder the \u003cem\u003eAccount\u003c/em\u003e section, click \u003cstrong\u003eSettings \u0026#x26; Privacy\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003eClick on \u003cstrong\u003eGet a copy of your data\u003c/strong\u003e, and you can view the various reports\u003c/li\u003e\n\u003cli\u003eSelect the reports you're interested in, for this, I just checked \u003cstrong\u003eConnections\u003c/strong\u003e\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eAfter requesting the report, it should only take a few minutes before you get an email saying your report is ready for export.\u003c/p\u003e\n\u003ch2\u003eDiving into the data\u003c/h2\u003e\n\u003cp\u003eTo reiterate our goal, we want to get a broad understanding of the companies within the first layer of our network (direct connections). Now, let's load up Python and learn more about this data in this CSV.\u003c/p\u003e\n\u003ch3\u003eReading in the data\u003c/h3\u003e\n\u003cp\u003eOnce the CSV is downloaded, we can open it up with Pandas and take a look (\u003cem\u003eoutput will be commented below\u003c/em\u003e).\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eimport pandas as pd\n\n# We want to skip the first three rows because of Notes at the top\ndf = pd.read_csv('Connections.csv', skiprows=3)\n\ndf.columns\n# ['First Name', 'Last Name', 'Email Address', 'Company', 'Position', 'Connected On',]\n\ndf.info()\n\"\"\"\n\u0026#x3C;class 'pandas.core.frame.DataFrame'\u003e\nRangeIndex: 376 entries, 0 to 375\nData columns (total 6 columns):\n #   Column         Non-Null Count  Dtype \n---  ------         --------------  ----- \n 0   First Name     375 non-null    object\n 1   Last Name      375 non-null    object\n 2   Email Address  1 non-null      object\n 3   Company        371 non-null    object\n 4   Position       371 non-null    object\n 5   Connected On   376 non-null    object\ndtypes: object(6)\nmemory usage: 17.8+ KB\n\"\"\"\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eI won't post the name's of any individuals or full rows to respect the privacy of my connections, but when I searched through the my Connections CSV, I noticed a few initial patterns that would help clean up the data.\u003c/p\u003e\n\u003ch3\u003eCleaning up the data\u003c/h3\u003e\n\u003cp\u003eAt first glance, the first thing I notice is connections who don't list a current company, so let's get rid of those.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003edf = df[df['Company'].notna()].sort_values(by='Company')\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eAfter sorting, another thing I noticed was that some of these company names belong to the same company, but the individuals wrote them differently.\u003c/p\u003e\n\u003cp\u003eAn example of this is \u003ccode\u003e'IBM Global Solution Center'\u003c/code\u003e and \u003ccode\u003e'IBM'\u003c/code\u003e; for our purposes, these should both be classified as \u003ccode\u003eIBM\u003c/code\u003e.\u003c/p\u003e\n\u003cp\u003eLet's run through a fuzzy match run using \u003ca href=\"https://docs.python.org/3/library/difflib.html#difflib.get_close_matches\"\u003edifflib's \u003ccode\u003eget_close_matches\u003c/code\u003e\u003c/a\u003e to try and bucket some of these similar company names.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003efrom difflib import get_close_matches\n\ncompanies = df['Company'].drop_duplicates()\n\n# cutoff=0.7 is a similarity ranking, and n=10 just takes the top 10 values\nsimilar_companies = {x: get_close_matches(x, companies, n=10, cutoff=0.7)\n                     for x in companies}\n\n# We are only interested in the entries that had another match\nsimilar_companies = {x: [name for name in y if name != x]\n                     for x, y in similar_companies.items() if len(y) \u003e 1}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eNow, this solution is not perfect, but it will help draw out some similar companies. You should still run a manual inspection of the data (the IBM example I gave above is one that doesn't show up in the fuzzy match results).\u003c/p\u003e\n\u003cp\u003eBased upon the results, let's group together some of the companies that had matches.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003edf['Company'] = df['Company'].replace({\n    'KPMG US': similar_companies['KPMG US'],\n    'Self-employed': similar_companies['Self-employed'],\n    'IBM Global Solution Center': 'IBM',\n})\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe next thing you may have noticed is that in our \u003ccode\u003esimilar_companies\u003c/code\u003e dictionary, we cleaned up a \u003ccode\u003eSelf-employed\u003c/code\u003e entry.\u003c/p\u003e\n\u003cp\u003eTo stay aligned with our goal, let's drop these entries, as well as your current company.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ecompanies_to_drop = ['self employed', 'your current company']\ndf = df[~df['Company'].str.lower().isin(companies_to_drop)]\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003eAggregating the data\u003c/h3\u003e\n\u003cp\u003eNow that our data is cleaned up a bit, let's aggregate and sum the number of connections for each of the companies.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003edf_company_counts = df['Company'].value_counts().reset_index()\ndf_company_counts.columns = ['Company', 'Count']  # For ease of understanding\ndf_company_counts = df_company_counts.sort_values(by='Count', ascending=False)\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2\u003eCreating the network\u003c/h2\u003e\n\u003cp\u003eWe have the numbers we want for each company, now let's jump into using \u003ccode\u003eNetworkX\u003c/code\u003e to recreate a network.\u003c/p\u003e\n\u003cp\u003eThe first step will be to initialize our graph, and add yourself as the central node, as it is your network.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eimport networkx as nx\n\nG = nx.Graph()\nG.add_node('Me')\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThen, we'll loop through our \u003ccode\u003edf_company_counts\u003c/code\u003e DataFrame and add each company as a node.\u003c/p\u003e\n\u003cp\u003e\u003cem\u003eYou'll notice some HTML tags in the title below, this is just to make it more readable for later\u003c/em\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003efor _, row in df_company_counts.iterrows():\n\t# The title will be for more information later on\n    title = '\u0026#x3C;b\u003e{0}\u0026#x3C;/b\u003e ({1})\u0026#x3C;br\u003e\u0026#x3C;hr\u003ePositions:\u0026#x3C;br\u003e'.format(row['Company'],\n    \t\t\t\t\t\t\t\t\t\t\t\t\t\trow['Count'])\n\n    # In addition to the full company name, let's add each position in a\n    # list to see the roles our connections have at these companies\n    position_list = ''.join('\u0026#x3C;li\u003e{}\u0026#x3C;/li\u003e'.format(x)\n    \t\t\t\t\t\tfor x in df[df['Company'] == row['Company']]['Position'])\n    title += '\u0026#x3C;ul\u003e{0}\u0026#x3C;/ul\u003e'.format(position_list)\n\n    # For ease of viewing, limit company names to 15 letters\n    node_name = row['Company']\n    if len(node_name) \u003e 15:\n        node_name = node_name[:15] + '...'\n\n    # Add the node and an edge connection ourself to the new node\n    G.add_node(node_name, weight=row['Count'], size=row['Count'] * 2, title=title)\n    G.add_edge('Me', node_name)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eAnd just like that, we've created our network of connections.\u003c/p\u003e\n\u003ch2\u003eVisualization\u003c/h2\u003e\n\u003cp\u003eOur network graph is created, so let's get into visualizing the network.\u003c/p\u003e\n\u003cp\u003eThere are a few options for visualizing networks including \u003ccode\u003ematplotlib.pyplot\u003c/code\u003e, but I found that \u003ccode\u003epyvis\u003c/code\u003e was the easiest to use for several reasons:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003epyvis\u003c/code\u003e generates an HTML file\u003c/li\u003e\n\u003cli\u003eCustomization is made very easy\u003c/li\u003e\n\u003cli\u003eThe graph is interactive by default\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eLet's look into generating this HTML file.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003efrom pyvis.network import Network\n\nnt = Network('100%', '100%', bgcolor='#222222', font_color='white')\nnt.from_nx(G)\nnt.repulsion()  # Spaces out the nodes\nnt.show('nx.html')\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eAnd it's that simple! We specify a width and height, optional styling attributes, and then we can generate the network graph visual straight from what we created with NetworkX.\u003c/p\u003e\n\u003cp\u003eNow we can see \u003ca href=\"/network/first-nx-graph.html\"\u003ethe network we generated\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eYou can hover over each node to see the total number of connections that work at the respective company, and below is a list of the positions held by your connections.\u003c/p\u003e\n\u003cp\u003eAs you can see, this is a bit hard to read into since there are a lot of nodes. Try and imagine reading this with +1,000 connections.\u003c/p\u003e\n\u003ch2\u003eImproving the output\u003c/h2\u003e\n\u003cp\u003eThere are a few ways that our network could be narrowed down.\u003c/p\u003e\n\u003cp\u003eBeing a \u003cem\u003eSoftware Developer\u003c/em\u003e, the thought that first occurred to me was to try and dial in on tech-related companies through known positions titles.\u003c/p\u003e\n\u003cp\u003eTo do this, I thought of a list of buzzwords/common job titles that I've seen across LinkedIn, and filtered down the initial DataFrame.\u003c/p\u003e\n\u003cp\u003eThen, we go through the same process we did in previous sections of generating and displaying the graph.\u003c/p\u003e\n\u003cp\u003e\u003cem\u003eAgain, this is not perfect, but it's a good starting point.\u003c/em\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e# Filter down from a list of popular tech positions\npositions = [\n    'developer', 'engineer', 'ai', 'analytics', 'software', 'cloud', 'cto',\n    'sde', 'sre', 'saas', 'product', 'engineering', 'scientist', 'data',\n]\ndf = df[df['Position'].str.contains('|'.join(positions), case=False)]\ndf_company_counts = df['Company'].value_counts().reset_index()\ndf_company_counts.columns = ['Company', 'Count']\ndf_company_counts = df_company_counts.sort_values(by='Count', ascending=False)\n\n# Re-initialize the graph and add the nodes/edges again\nG = nx.Graph()\nG.add_node('Me')\n\nfor _, row in df_company_counts.iterrows():\n    title = '\u0026#x3C;b\u003e{0}\u0026#x3C;/b\u003e ({1})\u0026#x3C;br\u003e\u0026#x3C;hr\u003ePositions:\u0026#x3C;br\u003e'.format(row['Company'], row['Count'])\n    position_list = ''.join('\u0026#x3C;li\u003e{}\u0026#x3C;/li\u003e'.format(x)\n    \t\t\t\t\t\tfor x in df[df['Company'] == row['Company']]['Position'])\n    title += '\u0026#x3C;ul\u003e{0}\u0026#x3C;/ul\u003e'.format(position_list)\n    node_name = row['Company']\n    if len(node_name) \u003e 15:\n        node_name = node_name[:15] + '...'\n\n    # Since there are less nodes, let's increase the sizes\n    G.add_node(node_name, weight=row['Count'], size=row['Count'] * 5, title=title)\n    G.add_edge('Me', node_name)\n\n# Generate the visualization\nnt = Network('100%', '100%', bgcolor='#222222', font_color='white')\nnt.from_nx(G)\nnt.repulsion()\nnt.show('nx.html')\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eNow, let's look at the \u003ca href=\"/network/second-nx-graph.html\"\u003eupdated results\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eMuch better! This is more readable and easier to interact with.\u003c/p\u003e\n\u003cp\u003eAnd just like that, we achieved our goal of gaining a broader understanding of the companies in our LinkedIn network.\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003e\u003cstrong\u003e\u003cem\u003ePossible improvements for those interested\u003c/em\u003e\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eScraping the profile location of each of your connections to segment by location\u003c/li\u003e\n\u003cli\u003eCompiling a list of companies you'd like to work for/are interested in and creating a filtering system\u003c/li\u003e\n\u003cli\u003eResearching salary data for positions and gathering average pay by company\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n","markdown":"\n## tl;dr\n\n### Goal\n_To understand and visualize the companies within my directly connected network on LinkedIn_\n\n### Process overview\n1. **LinkedIn data sources** - retrieving LinkedIn Network data from a \"Get a copy of your data\" CSV export\n2. **Diving into the data** - exploring, cleaning, and aggregating the data with [`Pandas`](https://pandas.pydata.org/)\n3. **Creating the network** - creating a network graph using [`NetworkX`](https://networkx.org/)\n4. **Visualization** - visualizing the network with [`pyvis`](https://pyvis.readthedocs.io/en/latest/)\n5. **Improving the output** - cleaning up the network graph with additional filtering\n\n### Results\n_Hover over the nodes for more details_\n- [The first network graph](/network/first-nx-graph.html)\n- [The second (more specific) network graph](/network/second-nx-graph.html)\n\n### Python dependencies\n```python\n# Python standard library\nfrom difflib import get_close_matches\n\n# 3rd party\nimport networkx as nx\nimport pandas as pd\nfrom pyvis.network import Network\n```\n\n---\n\nRecently, I was exploring [my LinkedIn](https://www.linkedin.com/in/bradley-schoeneweis/) network to see what some of my colleagues from high school and undergrad are currently up to.\n\nAs I was scrolling through the connections page, I noticed LinkedIn gives you options to filter and searching with ease, but it doesn't really provide tools to learn about your network as a whole.\n\nSo I decided to see if there was an easy way to export my network data to see what I could do with a few hours of exploring the data.\n\n\n## LinkedIn data sources\n\nMy first thought was to checkout out the [LinkedIn's Developer API](https://www.linkedin.com/developers/).\n\nSomething I do fairly frequently at my current job is integrating various 3rd-party REST APIs into our platform, so I wanted to see all the functionality and possibilities that this API would provide.\n\nAfter reading through some documentation, I decided this wasn't a direction I wanted to pursue. Most of their developer products require approval, so I decided to look into other options.\n\nAnother thought I had was to write a quick scraping script to pull down the HTML of my connections page and parse out names and companies, but I assumed there had to be a more simple way to get this data.\n\nFinally, after a bit of research, I found that there are various \"Get a copy of your data\" reports that you can run within LinkedIn.  In order to get to these reports, you can do the following:\n1. On the homepage toolbar, click the **Me** dropdown\n2. Under the _Account_ section, click **Settings \u0026 Privacy**\n3. Click on **Get a copy of your data**, and you can view the various reports\n4. Select the reports you're interested in, for this, I just checked **Connections**\n\nAfter requesting the report, it should only take a few minutes before you get an email saying your report is ready for export.\n\n\n## Diving into the data\n\nTo reiterate our goal, we want to get a broad understanding of the companies within the first layer of our network (direct connections). Now, let's load up Python and learn more about this data in this CSV.\n\n### Reading in the data\nOnce the CSV is downloaded, we can open it up with Pandas and take a look (_output will be commented below_).\n\n```python\nimport pandas as pd\n\n# We want to skip the first three rows because of Notes at the top\ndf = pd.read_csv('Connections.csv', skiprows=3)\n\ndf.columns\n# ['First Name', 'Last Name', 'Email Address', 'Company', 'Position', 'Connected On',]\n\ndf.info()\n\"\"\"\n\u003cclass 'pandas.core.frame.DataFrame'\u003e\nRangeIndex: 376 entries, 0 to 375\nData columns (total 6 columns):\n #   Column         Non-Null Count  Dtype \n---  ------         --------------  ----- \n 0   First Name     375 non-null    object\n 1   Last Name      375 non-null    object\n 2   Email Address  1 non-null      object\n 3   Company        371 non-null    object\n 4   Position       371 non-null    object\n 5   Connected On   376 non-null    object\ndtypes: object(6)\nmemory usage: 17.8+ KB\n\"\"\"\n```\n\nI won't post the name's of any individuals or full rows to respect the privacy of my connections, but when I searched through the my Connections CSV, I noticed a few initial patterns that would help clean up the data.\n\n### Cleaning up the data\n\nAt first glance, the first thing I notice is connections who don't list a current company, so let's get rid of those.\n\n```python\ndf = df[df['Company'].notna()].sort_values(by='Company')\n```\n\nAfter sorting, another thing I noticed was that some of these company names belong to the same company, but the individuals wrote them differently.\n\nAn example of this is `'IBM Global Solution Center'` and `'IBM'`; for our purposes, these should both be classified as `IBM`.\n\nLet's run through a fuzzy match run using [difflib's `get_close_matches`](https://docs.python.org/3/library/difflib.html#difflib.get_close_matches) to try and bucket some of these similar company names.\n```python\nfrom difflib import get_close_matches\n\ncompanies = df['Company'].drop_duplicates()\n\n# cutoff=0.7 is a similarity ranking, and n=10 just takes the top 10 values\nsimilar_companies = {x: get_close_matches(x, companies, n=10, cutoff=0.7)\n                     for x in companies}\n\n# We are only interested in the entries that had another match\nsimilar_companies = {x: [name for name in y if name != x]\n                     for x, y in similar_companies.items() if len(y) \u003e 1}\n```\n\nNow, this solution is not perfect, but it will help draw out some similar companies. You should still run a manual inspection of the data (the IBM example I gave above is one that doesn't show up in the fuzzy match results).\n\nBased upon the results, let's group together some of the companies that had matches.\n```python\ndf['Company'] = df['Company'].replace({\n    'KPMG US': similar_companies['KPMG US'],\n    'Self-employed': similar_companies['Self-employed'],\n    'IBM Global Solution Center': 'IBM',\n})\n```\n\nThe next thing you may have noticed is that in our `similar_companies` dictionary, we cleaned up a `Self-employed` entry.\n\nTo stay aligned with our goal, let's drop these entries, as well as your current company.\n```python\ncompanies_to_drop = ['self employed', 'your current company']\ndf = df[~df['Company'].str.lower().isin(companies_to_drop)]\n```\n\n### Aggregating the data\nNow that our data is cleaned up a bit, let's aggregate and sum the number of connections for each of the companies.\n\n```python\ndf_company_counts = df['Company'].value_counts().reset_index()\ndf_company_counts.columns = ['Company', 'Count']  # For ease of understanding\ndf_company_counts = df_company_counts.sort_values(by='Count', ascending=False)\n```\n\n## Creating the network\n\nWe have the numbers we want for each company, now let's jump into using `NetworkX` to recreate a network.\n\nThe first step will be to initialize our graph, and add yourself as the central node, as it is your network.\n\n```python\nimport networkx as nx\n\nG = nx.Graph()\nG.add_node('Me')\n```\n\nThen, we'll loop through our `df_company_counts` DataFrame and add each company as a node.\n\n_You'll notice some HTML tags in the title below, this is just to make it more readable for later_\n```python\nfor _, row in df_company_counts.iterrows():\n\t# The title will be for more information later on\n    title = '\u003cb\u003e{0}\u003c/b\u003e ({1})\u003cbr\u003e\u003chr\u003ePositions:\u003cbr\u003e'.format(row['Company'],\n    \t\t\t\t\t\t\t\t\t\t\t\t\t\trow['Count'])\n\n    # In addition to the full company name, let's add each position in a\n    # list to see the roles our connections have at these companies\n    position_list = ''.join('\u003cli\u003e{}\u003c/li\u003e'.format(x)\n    \t\t\t\t\t\tfor x in df[df['Company'] == row['Company']]['Position'])\n    title += '\u003cul\u003e{0}\u003c/ul\u003e'.format(position_list)\n\n    # For ease of viewing, limit company names to 15 letters\n    node_name = row['Company']\n    if len(node_name) \u003e 15:\n        node_name = node_name[:15] + '...'\n\n    # Add the node and an edge connection ourself to the new node\n    G.add_node(node_name, weight=row['Count'], size=row['Count'] * 2, title=title)\n    G.add_edge('Me', node_name)\n```\n\nAnd just like that, we've created our network of connections.\n\n\n## Visualization\n\nOur network graph is created, so let's get into visualizing the network.\n\nThere are a few options for visualizing networks including `matplotlib.pyplot`, but I found that `pyvis` was the easiest to use for several reasons:\n- `pyvis` generates an HTML file\n- Customization is made very easy\n- The graph is interactive by default\n\nLet's look into generating this HTML file.\n```python\nfrom pyvis.network import Network\n\nnt = Network('100%', '100%', bgcolor='#222222', font_color='white')\nnt.from_nx(G)\nnt.repulsion()  # Spaces out the nodes\nnt.show('nx.html')\n```\n\nAnd it's that simple! We specify a width and height, optional styling attributes, and then we can generate the network graph visual straight from what we created with NetworkX.\n\nNow we can see [the network we generated](/network/first-nx-graph.html).\n\nYou can hover over each node to see the total number of connections that work at the respective company, and below is a list of the positions held by your connections.\n\nAs you can see, this is a bit hard to read into since there are a lot of nodes. Try and imagine reading this with +1,000 connections.\n\n## Improving the output\n\nThere are a few ways that our network could be narrowed down.\n\nBeing a _Software Developer_, the thought that first occurred to me was to try and dial in on tech-related companies through known positions titles.\n\nTo do this, I thought of a list of buzzwords/common job titles that I've seen across LinkedIn, and filtered down the initial DataFrame.\n\nThen, we go through the same process we did in previous sections of generating and displaying the graph.\n\n_Again, this is not perfect, but it's a good starting point._\n```python\n# Filter down from a list of popular tech positions\npositions = [\n    'developer', 'engineer', 'ai', 'analytics', 'software', 'cloud', 'cto',\n    'sde', 'sre', 'saas', 'product', 'engineering', 'scientist', 'data',\n]\ndf = df[df['Position'].str.contains('|'.join(positions), case=False)]\ndf_company_counts = df['Company'].value_counts().reset_index()\ndf_company_counts.columns = ['Company', 'Count']\ndf_company_counts = df_company_counts.sort_values(by='Count', ascending=False)\n\n# Re-initialize the graph and add the nodes/edges again\nG = nx.Graph()\nG.add_node('Me')\n\nfor _, row in df_company_counts.iterrows():\n    title = '\u003cb\u003e{0}\u003c/b\u003e ({1})\u003cbr\u003e\u003chr\u003ePositions:\u003cbr\u003e'.format(row['Company'], row['Count'])\n    position_list = ''.join('\u003cli\u003e{}\u003c/li\u003e'.format(x)\n    \t\t\t\t\t\tfor x in df[df['Company'] == row['Company']]['Position'])\n    title += '\u003cul\u003e{0}\u003c/ul\u003e'.format(position_list)\n    node_name = row['Company']\n    if len(node_name) \u003e 15:\n        node_name = node_name[:15] + '...'\n\n    # Since there are less nodes, let's increase the sizes\n    G.add_node(node_name, weight=row['Count'], size=row['Count'] * 5, title=title)\n    G.add_edge('Me', node_name)\n\n# Generate the visualization\nnt = Network('100%', '100%', bgcolor='#222222', font_color='white')\nnt.from_nx(G)\nnt.repulsion()\nnt.show('nx.html')\n```\n\nNow, let's look at the [updated results](/network/second-nx-graph.html).\n\nMuch better! This is more readable and easier to interact with.\n\nAnd just like that, we achieved our goal of gaining a broader understanding of the companies in our LinkedIn network.\n\n---\n\n**_Possible improvements for those interested_**\n- Scraping the profile location of each of your connections to segment by location\n- Compiling a list of companies you'd like to work for/are interested in and creating a filtering system\n- Researching salary data for positions and gathering average pay by company\n\n---\n","title":"Visualizing your LinkedIn connections using Python","date":"2021-04-08","tags":["python","pandas","networkx","data-analysis"],"description":"Using Python's Pandas, NetworkX, and pyvis to understand and visualize companies within a directly connected LinkedIn network."}],"nextjs":[{"id":"rebuilding-my-blog","contentHtml":"\u003ch2\u003eVersion \u003ccode\u003e0.1.x\u003c/code\u003e\u003c/h2\u003e\n\u003cp\u003eThe first iteration of my blog was built using a pre-configured \u003ca href=\"https://www.gatsbyjs.com/\"\u003eGatsbyJS\u003c/a\u003e site template.  I chose a template (\u003ca href=\"https://novela.narative.co/\"\u003eNovela by Narative\u003c/a\u003e) that checked all my boxes for an easy tool to start sharing my writing.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eThe theme was modern and sleek\u003c/li\u003e\n\u003cli\u003eEverything was mobile-friendly\u003c/li\u003e\n\u003cli\u003eLots of plug-and-play options and prebuilt components that flowed together\n\u003cul\u003e\n\u003cli\u003eArticle metadata that connects to an author bio page\u003c/li\u003e\n\u003cli\u003eReading time estimates and progress bars\u003c/li\u003e\n\u003cli\u003eEasy image optimizations\u003c/li\u003e\n\u003cli\u003eA config for a Google Analytics tag\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eDeployment was straightforward with GitHub pages\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eBut most importantly, all I had to do was add Markdown pages to a directory to get started.  At the time, I didn't really know much about GatsbyJS, other than it being a popular static site generator, and my modern JavaScript knowledge was introductory at-best (albeit growing each and every day).  So this seemed like the perfect route forward.\u003c/p\u003e\n\u003ch2\u003eThe problem\u003c/h2\u003e\n\u003cp\u003eAs I started writing more and more posts, I began noting different features I wanted to include on my site.  These weren't terribly complex additions, but rather simple things like adding tags to group common posts or wanting to change the styling of the inline code snippets.\u003c/p\u003e\n\u003cp\u003eI soon discovered that trying to color outside the lines when using a cookiecutter template can get very complex, very quickly.\u003c/p\u003e\n\u003cp\u003eI found myself digging into nested modules in my \u003ccode\u003enode_modules\u003c/code\u003e folder where I would need to overload different functions and components to get what I wanted.  It was added complexity than I didn't foresee when I signed up to use a template.  Plus, this site could eventually house more than just a blog, and the template I chose wasn't designed to accommodate much else.\u003c/p\u003e\n\u003ch2\u003eWhat now?\u003c/h2\u003e\n\u003cp\u003eIf you haven't noticed from the timestamp on my last article, I haven't written a post in ~9 months.  This is largely because I was interviewing for new positions and eventually joined the team at \u003ca href=\"https://radar.com\"\u003eRadar\u003c/a\u003e as a Product Engineer!  Preparation for interviews and taking a break after accepting this new position occupied much of the time I would normally spend writing.  Plus, taking a break from coding outside of work is a good way to avoid burnout ü§∑‚Äç‚ôÇÔ∏è.\u003c/p\u003e\n\u003cp\u003eThe reason I mention this is because one of the technologies we use at Radar is \u003ca href=\"https://nextjs.org/\"\u003eNext.js\u003c/a\u003e.  Next.js was something I was already trying to learn in my free time, but I've been able to gain a good amount of experience with it since I've started my new role, and my modern JavaScript fundamentals and understanding have grown drastically in the past several month (expect a lot more JavaScript posts going forward).\u003c/p\u003e\n\u003cp\u003eSeeing the power of Next.js and knowing I wanted my blog to be more flexible, I decided to recreate my blog from scratch using Next.js.\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003eNext.js\u003c/h2\u003e\n\u003cp\u003eA quick prelude on \u003ca href=\"https://nextjs.org/\"\u003eNext.js\u003c/a\u003e for those who have never used it.  \u003ca href=\"https://vercel.com/\"\u003eVercel\u003c/a\u003e, the creators of Next.js (and a company to keep üëÄ on) says it best, Next.js is...\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\"The \u003ca href=\"https://reactjs.org/\"\u003eReact\u003c/a\u003e Framework for Production\"\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eNext.js comes with a ton of great built-in features including:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eStatic + server-side rendering\u003c/li\u003e\n\u003cli\u003eSmart bundling and code-splitting, TypeScript support, Routing, Fast Refresh, CSS + Sass support all without complex configs\u003c/li\u003e\n\u003cli\u003eImage optimization\u003c/li\u003e\n\u003cli\u003eIntuitive code organization (because there are a million-plus ways to organize a React project)\u003c/li\u003e\n\u003cli\u003eStatic HTML exports (this one is important for our purposes)\u003c/li\u003e\n\u003cli\u003eSo much more...\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eIt's an awesome framework.\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eCoincidentally enough, the \u003ca href=\"https://nextjs.org/learn/basics/create-nextjs-app\"\u003eNext.js hands-on tutorial\u003c/a\u003e walks you through setting up a blog with Next.js. Following this tutorial will set you up with a great and simplistic starter blog (but not quite ready for deployment on GitHub pages, where this blog lives at the time of writing).\u003c/p\u003e\n\u003cp\u003eA few things this tutorial covers:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eCreating the Next.js app\u003c/li\u003e\n\u003cli\u003eBasics like in-app navigation, styling, adding images and more\u003c/li\u003e\n\u003cli\u003eSetting up metadata, blog pages, and pre-rendering\u003c/li\u003e\n\u003cli\u003eMarkdown ‚û°Ô∏è HTML\u003c/li\u003e\n\u003cli\u003eReworking your app to use dynamic routing\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThe tutorial is great so I won't cover anything that's already covered there.  If you're interested in using Next.js, you should definitely go through it.\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003eBeyond the basics\u003c/h2\u003e\n\u003cp\u003eAs mentioned, the \u003ca href=\"https://nextjs.org/learn/basics/create-nextjs-app\"\u003eNext.js tutorial\u003c/a\u003e is a great starting point, but I wanted to get my blog to a place where it was comparable to the previous iteration, along with the new features that encouraged me to take on this project in the first place.\u003c/p\u003e\n\u003cp\u003eTo keep things concise, we'll cover adding \u003ca href=\"/tags\"\u003etags\u003c/a\u003e, adding a custom domain from \u003ca href=\"https://domains.google/\"\u003eGoogle Domains\u003c/a\u003e to GitHub pages, and adding a GitHub action to automatically build and deploy our blog on each commit.\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003eTags\u003c/h2\u003e\n\u003cp\u003eOrganization within code and outside of code is always at the top of my priority list, so categorizing posts by tag was first on my blog todo list.\u003c/p\u003e\n\u003ch3\u003eAdding tags to each post\u003c/h3\u003e\n\u003cp\u003eFirst, let's add tags to each of our posts.  We can work off of the blog data section of the \u003ca href=\"https://nextjs.org/learn/basics/data-fetching/blog-data\"\u003eNext.js tutorial\u003c/a\u003e and add some additional YAML metadata to our markdown posts using \u003ca href=\"https://github.com/jonschlinkert/gray-matter\"\u003egray-matter\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eWithin the current metadata, add a list of tags relevant to the post:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e---\ntitle: 'Rebuilding my blog from scratch with Next.js'\ndate: '2022-04-23'\ntags: ['nextjs', 'react', 'javascript']\ndescription: 'Rebuilding my blog from a Gatsby.js templated site to a custom Next.js site from scratch.'\n---\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eI won't cover rendering of the tags below each posts in the post list, but the tags list should get picked up automatically with the \u003ccode\u003egetSortedPostsData()\u003c/code\u003e function that was already written and is called by \u003ccode\u003egetStaticProps()\u003c/code\u003e in order to pass props down the the post related components.\u003c/p\u003e\n\u003ch3\u003e/tags/[tag]\u003c/h3\u003e\n\u003cp\u003eWhat we've done so far will associate posts with a list of tags, but now we also want a page for each tag that lists out the associated posts.  For example, to view \u003ccode\u003epython\u003c/code\u003e related posts, we can go to \u003ca href=\"/tags/python\"\u003e/tags/python\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eWith Next.js, this can be done easily using \u003ca href=\"https://nextjs.org/docs/routing/dynamic-routes\"\u003edynamic routes\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eUnder the \u003ccode\u003epages/\u003c/code\u003e directory, create a \u003ccode\u003epages/tags/[tag].js\u003c/code\u003e file structure.  We'll be repeating similar patterns done within \u003ccode\u003epages/posts/[id].js\u003c/code\u003e.\u003c/p\u003e\n\u003cp\u003eLike earlier, we need to implement \u003ccode\u003egetStaticProps()\u003c/code\u003e (\u003ca href=\"https://nextjs.org/docs/basic-features/data-fetching/get-static-props\"\u003emore info here\u003c/a\u003e), so we can render these pages at build time.  We also need to implement \u003ccode\u003egetStaticPaths()\u003c/code\u003e (\u003ca href=\"https://nextjs.org/docs/basic-features/data-fetching/get-static-paths\"\u003emore info here\u003c/a\u003e) to get a list of all possible tags at build time.\u003c/p\u003e\n\u003cp\u003eLet's create a \u003ccode\u003elib/tags.js\u003c/code\u003e file to house some of the helper functions to implement \u003ccode\u003egetStaticProps()\u003c/code\u003e and \u003ccode\u003egetStaticPaths()\u003c/code\u003e.\u003c/p\u003e\n\u003cp\u003eFirst, we want to get a list of all the tags so we can write \u003ccode\u003egetStaticPaths()\u003c/code\u003e.  This will require processing all of the files within \u003ccode\u003eposts/\u003c/code\u003e, and processing the metadata using \u003ca href=\"https://github.com/jonschlinkert/gray-matter\"\u003egray-matter\u003c/a\u003e.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eimport fs from 'fs';\nimport path from 'path';\nimport matter from 'gray-matter';\n\nconst postsDirectory = path.join(process.cwd(), 'posts');\n\nexport const getAllTags = () =\u003e {\n  const fileNames = fs.readdirSync(postsDirectory);\n  const tags = new Set();\n\n  fileNames.map(fileName =\u003e {\n    // Read markdown file as string\n    const fullPath = path.join(postsDirectory, fileName);\n    const fileContents = fs.readFileSync(fullPath, 'utf8');\n\n    // Use gray-matter to parse the post metadata section\n    const matterResult = matter(fileContents);\n    if (matterResult?.data?.tags) {\n      matterResult.data.tags.forEach(\n        (tag) =\u003e tags.add(`/tags/${tag.replace(/\\s+/g, '-').toLowerCase()}`)\n      );\n    }\n  });\n\n  return Array.from(tags);\n};\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eNow we can call this within \u003ccode\u003epages/tags/[tag].js\u003c/code\u003e under \u003ccode\u003egetStaticPaths()\u003c/code\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eexport const getStaticPaths = () =\u003e {\n  const paths = getAllTags();\n  return {\n    paths,\n    fallback: false,\n  }\n};\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eNow, we can add another helper function \u003ccode\u003egetPostDataByTag()\u003c/code\u003e in \u003ccode\u003elib/tags.js\u003c/code\u003e to fulfill \u003ccode\u003egetStaticProps()\u003c/code\u003e.  This is basically what we already do with \u003ccode\u003epages/posts/[id].js\u003c/code\u003e, and it's not very efficient to do this twice, but all of this is happening at build time so it's not a huge deal for us.\u003c/p\u003e\n\u003cp\u003eFor this, we will use \u003ca href=\"https://github.com/remarkjs/remark\"\u003eremark\u003c/a\u003e to process our markdown files.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eimport fs from 'fs';\nimport path from 'path';\nimport matter from 'gray-matter';\nimport { remark } from 'remark';\nimport html from 'remark-html';\n\nconst postsDirectory = path.join(process.cwd(), 'posts');\n\nexport const getPostDataByTag = async (tag) =\u003e {\n  const fileNames = fs.readdirSync(postsDirectory);\n  const posts = [];\n\n  fileNames.map(async (fileName) =\u003e {\n    const id = fileName.replace(/\\.md$/, '');\n  \n    // Read markdown file as string\n    const fullPath = path.join(postsDirectory, fileName);\n    const fileContents = fs.readFileSync(fullPath, 'utf8');\n\n    // Use gray-matter to parse the post metadata section\n    const matterResult = matter(fileContents);\n\n    if (matterResult?.data?.tags \u0026#x26;\u0026#x26; matterResult.data.tags.includes(tag)) {\n      // Use remark to convert markdown into HTML string\n      const processedContent = await remark()\n        .use(html)\n        .process(matterResult.content);\n      const contentHtml = processedContent.toString();\n\n      // Combine the data with the id and contentHtml\n      posts.push({\n        id,\n        contentHtml,\n        markdown: matterResult.content,\n        ...matterResult.data,\n      });\n    }\n  });\n\n  return posts;\n};\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eWe can call this helper function in \u003ccode\u003epages/tags/[tag].js\u003c/code\u003e under \u003ccode\u003egetStaticProps()\u003c/code\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eexport const getStaticProps = async ({ params }) =\u003e {\n  const { tag } = params;\n  const taggedPosts = await getPostDataByTag(tag);\n  return {\n    props: {\n      tag,\n      taggedPosts,\n    },\n  };\n};\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eNow, you can render the associated tag pages as you wish, but I did it with a few components I had set up:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003econst TagPage = ({ tag, taggedPosts }) =\u003e {\n  const title = `Posts tagged \"${tag}\"`;\n  return (\n    \u0026#x3C;Layout tagPage title={title} description={title}\u003e \n      \u0026#x3C;header\u003e\n        \u0026#x3C;Tag tag={tag} isHeader/\u003e\n      \u0026#x3C;/header\u003e\n\n      \u0026#x3C;section\u003e\n        \u0026#x3C;PostList posts={taggedPosts} /\u003e\n      \u0026#x3C;/section\u003e\n    \u0026#x3C;/Layout\u003e\n  );\n};\n\nexport default TagPage;\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003eAll tags\u003c/h3\u003e\n\u003cp\u003eThe last thing we want to add is a page containing all of the tags in a list, and all of the posts organized into categories.\u003c/p\u003e\n\u003cp\u003eTo do this, we can add \u003ccode\u003epages/tags.js\u003c/code\u003e, which can be reached at \u003ca href=\"/tags\"\u003e/tags\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eOnce again, we want to implement \u003ccode\u003egetStaticProps()\u003c/code\u003e so we can pre-render this page at build time.  Luckily, we can reuse the two functions we wrote in \u003ccode\u003elib/tags.js\u003c/code\u003e to make this easy.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eimport { getAllTags, getPostDataByTag } from '../lib/tags';\n\nexport const getStaticProps = async () =\u003e {\n  const tagsWithPosts = {};\n  const allTags = getAllTags();\n\n  for (const tagPath of allTags) {\n    const tag = tagPath.replace('/tags/', '');\n    tagsWithPosts[tag] = await getPostDataByTag(tag);\n  }\n\n  return {\n    props: {\n      tagsWithPosts,\n    },\n  };\n};\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eNow, you can render this as you'd like using \u003ccode\u003etagsWithPosts\u003c/code\u003e as a prop in your page component.  I also like having a toggle to show/hide the associated posts.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003econst TagPage = ({ tagsWithPosts }) =\u003e {\n  const [showPosts, setShowPosts] = useState(false);\n\n  const tagAndPostList = Object.keys(tagsWithPosts).map((tag) =\u003e {\n    return (\n      \u0026#x3C;section key={tag}\u003e\n        \u0026#x3C;Tag tag={tag} isHeader useLink label={tagsWithPosts[tag].length} /\u003e\n        {showPosts \u0026#x26;\u0026#x26; \u0026#x3C;PostList posts={tagsWithPosts[tag]} withPadding /\u003e }\n      \u0026#x3C;/section\u003e\n    );\n  });\n\n  const title = 'All Tags';\n  return (\n    \u0026#x3C;Layout title={title} description={title}\u003e\n      \u0026#x3C;header\u003e\n        \u0026#x3C;h1\u003eAll tags\u0026#x3C;/h1\u003e\n        \u0026#x3C;div\u003e\n          \u0026#x3C;Checkbox label={'Show posts'} value={showPosts} onChange={(x) =\u003e setShowPosts(!showPosts)} /\u003e\n        \u0026#x3C;/div\u003e\n      \u0026#x3C;/header\u003e\n\n      {tagAndPostList}\n\n    \u0026#x3C;/Layout\u003e\n  );\n};\n\nexport default TagPage;\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eNow we have a page with all of our tags üôå.\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003eAdding a custom domain\u003c/h2\u003e\n\u003cp\u003eNext on my todo list was adding a custom domain to transition from bschoeneweis.github.io ‚û°Ô∏è bradleyschoeneweis.com.  GitHub gives a good overview of the steps \u003ca href=\"https://docs.github.com/en/pages/configuring-a-custom-domain-for-your-github-pages-site/managing-a-custom-domain-for-your-github-pages-site#configuring-an-apex-domain\"\u003ehere\u003c/a\u003e, but we'll go through it below specifically using \u003ca href=\"https://domains.google/\"\u003eGoogle domains\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eWe'll be using an apex domain (e.g. bradleyschoeneweis.com).\u003c/p\u003e\n\u003ch3\u003eGitHub changes\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003eGo to the repository settings for your GitHub pages repository\u003c/li\u003e\n\u003cli\u003eClick into the \u003cstrong\u003ePages\u003c/strong\u003e section\u003c/li\u003e\n\u003cli\u003eType your apex domain into the \u003cstrong\u003eCustom domain\u003c/strong\u003e input and click \u003cstrong\u003eSave\u003c/strong\u003e\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3\u003eGoogle domains changes\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003eGo to your \u003ca href=\"https://domains.google.com/registrar/\"\u003eGoogle domains registrar\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003eClick \u003cstrong\u003eManage\u003c/strong\u003e on the domain you'd like to use\u003c/li\u003e\n\u003cli\u003eNavigate to the \u003cstrong\u003eDNS\u003c/strong\u003e settings and under \u003cstrong\u003eResource records\u003c/strong\u003e, click \u003cstrong\u003eManage custom records\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003eRefer to the \u003ca href=\"https://docs.github.com/en/pages/configuring-a-custom-domain-for-your-github-pages-site/managing-a-custom-domain-for-your-github-pages-site#configuring-an-apex-domain\"\u003eGitHub documentation\u003c/a\u003e for the official IP address list, but add the following \u003ccode\u003eA\u003c/code\u003e and \u003ccode\u003eCNAME\u003c/code\u003e records\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\u003cimg src=\"/images/rebuilding-my-blog/dns-records.jpg\" alt=\"DNS records\"\u003e\u003c/p\u003e\n\u003ch3\u003eFinal steps and confirmation\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003eHead back to the \u003cstrong\u003ePages\u003c/strong\u003e settings for your repository and check \u003cstrong\u003eEnforce HTTPS\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003eAfter a bit of time has passed, run \u003ccode\u003edig www.mynewdomain.com +nostats +nocomments +nocmd\u003c/code\u003e replace with your domain name and your output should look similar to the following:\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\u003cimg src=\"/images/rebuilding-my-blog/dig-output.jpg\" alt=\"dig output\"\u003e\u003c/p\u003e\n\u003cp\u003eNow your custom domain should be all set up with your GitHub pages blog! üéâ\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003eSimple automated deployment\u003c/h2\u003e\n\u003cp\u003eFor the final touches, I didn't want to have to worry about building the blog locally each time, so we'll create a simple GitHub action to build and serve our blog on each commit.\u003c/p\u003e\n\u003ch3\u003eThe \u003ccode\u003epackage.json\u003c/code\u003e scripts\u003c/h3\u003e\n\u003cp\u003eIf you don't have one already, you should create a \u003ccode\u003ebuild\u003c/code\u003e script in \u003ccode\u003epackage.json\u003c/code\u003e as \u003ccode\u003ebuild: \"next build\"\u003c/code\u003e.\u003c/p\u003e\n\u003cp\u003eI won't cover it here, but you'll also need to go through tutorials related to \u003ca href=\"https://nextjs.org/docs/advanced-features/static-html-export\"\u003eexporting your Next.js project as static HTML\u003c/a\u003e.  There are a few gotchas here.  For example, you cannot use the Next.js image optimization or API routes.  You can see the full list of \u003ca href=\"https://nextjs.org/docs/advanced-features/static-html-export#unsupported-features\"\u003eunsupported features\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eLong story short, within your \u003ccode\u003epackage.json\u003c/code\u003e file, you should add an \u003ccode\u003eexport: \"next export\"\u003c/code\u003e script.  This will create an \u003ccode\u003eout/\u003c/code\u003e directory with HTML files when this command is run.  You probably want to add this directory to your \u003ccode\u003e.gitignore\u003c/code\u003e file.\u003c/p\u003e\n\u003ch3\u003eDeploy key\u003c/h3\u003e\n\u003cp\u003eWe will be using \u003ca href=\"https://github.com/peaceiris/actions-gh-pages\"\u003epeaceiris/actions-gh-pages@v3\u003c/a\u003e for making the deployment step easy.  As a part of this, we want to set up an SSH deploy key for safety.\u003c/p\u003e\n\u003cp\u003eYou can use an SSH key that you already have setup, or create a new one with:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003essh-keygen -t rsa -b 4096 -C \"$(git config user.email)\" -f gh-pages -N \"\"\n\u003c/code\u003e\u003c/pre\u003e\n\u003col\u003e\n\u003cli\u003eNavigate back to your repository settings, and under security, go to \u003cstrong\u003eDeploy keys\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003eClick \u003cstrong\u003eAdd a deploy key\u003c/strong\u003e and enter \u003ccode\u003eACTIONS_DEPLOY_KEY\u003c/code\u003e as the title\u003c/li\u003e\n\u003cli\u003ePaste in your public RSA key (ends with \u003ccode\u003e.pub\u003c/code\u003e)\u003c/li\u003e\n\u003cli\u003eCheck \u003cstrong\u003eAllow write access\u003c/strong\u003e and then click \u003cstrong\u003eAdd key\u003c/strong\u003e\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3\u003e\u003ccode\u003edeploy.yml\u003c/code\u003e\u003c/h3\u003e\n\u003cp\u003eNow that every thing is set up, we can put this all into a GitHub actions file.\u003c/p\u003e\n\u003cp\u003eFrom the root of the project, create \u003ccode\u003e.github/workflows/deploy.yml\u003c/code\u003e and refer to the following:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ename: Deploy to Github Pages\n\non:\n  push:\n    branches:\n      - develop\n\njobs:\n  deployment:\n    runs-on: ubuntu-latest\n\n    strategy:\n      matrix:\n        node-version: [14.x]\n\n    steps:\n      - uses: actions/checkout@v2\n\n      - name: Use Node.js ${{ matrix.node-version }}\n        uses: actions/setup-node@v2\n        with:\n          node-version: ${{ matrix.node-version }}\n\n      - name: Update NPM\n        run: npm i -g npm@latest\n\n      - name: Cache dependencies\n        uses: actions/cache@v2\n        with:\n          path: ~/.npm\n          key: ${{ runner.OS }}-node-${{ hashFiles('**/package-lock.json') }}\n          restore-keys: |\n            ${{ runner.OS }}-node-\n            ${{ runner.OS }}-\n\n      - name: Build\n        run: |\n          npm i --legacy-peer-deps\n          npm run build\n          npm run export\n\n      - name: Deploy\n        uses: peaceiris/actions-gh-pages@v3\n        with:\n          deploy_key: ${{ secrets.ACTIONS_DEPLOY_KEY }}\n          publish_dir: ./out\n          cname: yoururl.com\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eA few things to note:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eThe branch I actively work on is \u003ccode\u003edevelop\u003c/code\u003e, so you'll want to update that to the branch you push to\u003c/li\u003e\n\u003cli\u003eIf you didn't name your deploy key \u003ccode\u003eACTIONS_DEPLOY_KEY\u003c/code\u003e, change the \u003ccode\u003edeploy_key\u003c/code\u003e value to \u003ccode\u003esecrets.[Your key name]\u003c/code\u003e in the \u003cstrong\u003eDeploy\u003c/strong\u003e step\u003c/li\u003e\n\u003cli\u003eThe \u003ccode\u003ecname\u003c/code\u003e value in the \u003cstrong\u003eDeploy\u003c/strong\u003e step should be replaced with your newly configured custom domain\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eNow, each time you commit and push up you blog changes, your blog should automatically be built and served under your custom domain.\u003c/p\u003e\n\u003cp\u003eJust like that, your blog is just as functional as a cookiecutter template üç™ and more easy to build upon than ever before.\u003c/p\u003e\n\u003chr\u003e\n","markdown":"\n## Version `0.1.x`\n\nThe first iteration of my blog was built using a pre-configured [GatsbyJS](https://www.gatsbyjs.com/) site template.  I chose a template ([Novela by Narative](https://novela.narative.co/)) that checked all my boxes for an easy tool to start sharing my writing.\n\n- The theme was modern and sleek\n- Everything was mobile-friendly\n- Lots of plug-and-play options and prebuilt components that flowed together\n  - Article metadata that connects to an author bio page\n  - Reading time estimates and progress bars\n  - Easy image optimizations\n  - A config for a Google Analytics tag\n- Deployment was straightforward with GitHub pages\n  \nBut most importantly, all I had to do was add Markdown pages to a directory to get started.  At the time, I didn't really know much about GatsbyJS, other than it being a popular static site generator, and my modern JavaScript knowledge was introductory at-best (albeit growing each and every day).  So this seemed like the perfect route forward.\n\n## The problem\n\nAs I started writing more and more posts, I began noting different features I wanted to include on my site.  These weren't terribly complex additions, but rather simple things like adding tags to group common posts or wanting to change the styling of the inline code snippets.\n\nI soon discovered that trying to color outside the lines when using a cookiecutter template can get very complex, very quickly.\n\nI found myself digging into nested modules in my `node_modules` folder where I would need to overload different functions and components to get what I wanted.  It was added complexity than I didn't foresee when I signed up to use a template.  Plus, this site could eventually house more than just a blog, and the template I chose wasn't designed to accommodate much else.\n\n## What now?\n\nIf you haven't noticed from the timestamp on my last article, I haven't written a post in ~9 months.  This is largely because I was interviewing for new positions and eventually joined the team at [Radar](https://radar.com) as a Product Engineer!  Preparation for interviews and taking a break after accepting this new position occupied much of the time I would normally spend writing.  Plus, taking a break from coding outside of work is a good way to avoid burnout ü§∑‚Äç‚ôÇÔ∏è.\n\nThe reason I mention this is because one of the technologies we use at Radar is [Next.js](https://nextjs.org/).  Next.js was something I was already trying to learn in my free time, but I've been able to gain a good amount of experience with it since I've started my new role, and my modern JavaScript fundamentals and understanding have grown drastically in the past several month (expect a lot more JavaScript posts going forward).\n\nSeeing the power of Next.js and knowing I wanted my blog to be more flexible, I decided to recreate my blog from scratch using Next.js.\n\n---\n\n## Next.js\n\nA quick prelude on [Next.js](https://nextjs.org/) for those who have never used it.  [Vercel](https://vercel.com/), the creators of Next.js (and a company to keep üëÄ on) says it best, Next.js is...\n\n\u003e \"The [React](https://reactjs.org/) Framework for Production\"\n\nNext.js comes with a ton of great built-in features including:\n- Static + server-side rendering\n- Smart bundling and code-splitting, TypeScript support, Routing, Fast Refresh, CSS + Sass support all without complex configs\n- Image optimization\n- Intuitive code organization (because there are a million-plus ways to organize a React project)\n- Static HTML exports (this one is important for our purposes)\n- So much more...\n\n**It's an awesome framework.**\n\nCoincidentally enough, the [Next.js hands-on tutorial](https://nextjs.org/learn/basics/create-nextjs-app) walks you through setting up a blog with Next.js. Following this tutorial will set you up with a great and simplistic starter blog (but not quite ready for deployment on GitHub pages, where this blog lives at the time of writing).\n\nA few things this tutorial covers:\n- Creating the Next.js app\n- Basics like in-app navigation, styling, adding images and more\n- Setting up metadata, blog pages, and pre-rendering\n- Markdown ‚û°Ô∏è HTML\n- Reworking your app to use dynamic routing\n\nThe tutorial is great so I won't cover anything that's already covered there.  If you're interested in using Next.js, you should definitely go through it.\n\n---\n\n## Beyond the basics\n\nAs mentioned, the [Next.js tutorial](https://nextjs.org/learn/basics/create-nextjs-app) is a great starting point, but I wanted to get my blog to a place where it was comparable to the previous iteration, along with the new features that encouraged me to take on this project in the first place.\n\nTo keep things concise, we'll cover adding [tags](/tags), adding a custom domain from [Google Domains](https://domains.google/) to GitHub pages, and adding a GitHub action to automatically build and deploy our blog on each commit.\n\n---\n\n## Tags\nOrganization within code and outside of code is always at the top of my priority list, so categorizing posts by tag was first on my blog todo list.\n\n### Adding tags to each post\n\nFirst, let's add tags to each of our posts.  We can work off of the blog data section of the [Next.js tutorial](https://nextjs.org/learn/basics/data-fetching/blog-data) and add some additional YAML metadata to our markdown posts using [gray-matter](https://github.com/jonschlinkert/gray-matter).\n\nWithin the current metadata, add a list of tags relevant to the post:\n\n```yaml\n---\ntitle: 'Rebuilding my blog from scratch with Next.js'\ndate: '2022-04-23'\ntags: ['nextjs', 'react', 'javascript']\ndescription: 'Rebuilding my blog from a Gatsby.js templated site to a custom Next.js site from scratch.'\n---\n```\n\nI won't cover rendering of the tags below each posts in the post list, but the tags list should get picked up automatically with the `getSortedPostsData()` function that was already written and is called by `getStaticProps()` in order to pass props down the the post related components.\n\n### /tags/[tag]\n\nWhat we've done so far will associate posts with a list of tags, but now we also want a page for each tag that lists out the associated posts.  For example, to view `python` related posts, we can go to [/tags/python](/tags/python).\n\nWith Next.js, this can be done easily using [dynamic routes](https://nextjs.org/docs/routing/dynamic-routes).\n\nUnder the `pages/` directory, create a `pages/tags/[tag].js` file structure.  We'll be repeating similar patterns done within `pages/posts/[id].js`.\n\nLike earlier, we need to implement `getStaticProps()` ([more info here](https://nextjs.org/docs/basic-features/data-fetching/get-static-props)), so we can render these pages at build time.  We also need to implement `getStaticPaths()` ([more info here](https://nextjs.org/docs/basic-features/data-fetching/get-static-paths)) to get a list of all possible tags at build time.\n\nLet's create a `lib/tags.js` file to house some of the helper functions to implement `getStaticProps()` and `getStaticPaths()`.\n\nFirst, we want to get a list of all the tags so we can write `getStaticPaths()`.  This will require processing all of the files within `posts/`, and processing the metadata using [gray-matter](https://github.com/jonschlinkert/gray-matter).\n\n```js\nimport fs from 'fs';\nimport path from 'path';\nimport matter from 'gray-matter';\n\nconst postsDirectory = path.join(process.cwd(), 'posts');\n\nexport const getAllTags = () =\u003e {\n  const fileNames = fs.readdirSync(postsDirectory);\n  const tags = new Set();\n\n  fileNames.map(fileName =\u003e {\n    // Read markdown file as string\n    const fullPath = path.join(postsDirectory, fileName);\n    const fileContents = fs.readFileSync(fullPath, 'utf8');\n\n    // Use gray-matter to parse the post metadata section\n    const matterResult = matter(fileContents);\n    if (matterResult?.data?.tags) {\n      matterResult.data.tags.forEach(\n        (tag) =\u003e tags.add(`/tags/${tag.replace(/\\s+/g, '-').toLowerCase()}`)\n      );\n    }\n  });\n\n  return Array.from(tags);\n};\n```\n\nNow we can call this within `pages/tags/[tag].js` under `getStaticPaths()`\n\n```js\nexport const getStaticPaths = () =\u003e {\n  const paths = getAllTags();\n  return {\n    paths,\n    fallback: false,\n  }\n};\n```\n\nNow, we can add another helper function `getPostDataByTag()` in `lib/tags.js` to fulfill `getStaticProps()`.  This is basically what we already do with `pages/posts/[id].js`, and it's not very efficient to do this twice, but all of this is happening at build time so it's not a huge deal for us.\n\nFor this, we will use [remark](https://github.com/remarkjs/remark) to process our markdown files.\n\n```js\nimport fs from 'fs';\nimport path from 'path';\nimport matter from 'gray-matter';\nimport { remark } from 'remark';\nimport html from 'remark-html';\n\nconst postsDirectory = path.join(process.cwd(), 'posts');\n\nexport const getPostDataByTag = async (tag) =\u003e {\n  const fileNames = fs.readdirSync(postsDirectory);\n  const posts = [];\n\n  fileNames.map(async (fileName) =\u003e {\n    const id = fileName.replace(/\\.md$/, '');\n  \n    // Read markdown file as string\n    const fullPath = path.join(postsDirectory, fileName);\n    const fileContents = fs.readFileSync(fullPath, 'utf8');\n\n    // Use gray-matter to parse the post metadata section\n    const matterResult = matter(fileContents);\n\n    if (matterResult?.data?.tags \u0026\u0026 matterResult.data.tags.includes(tag)) {\n      // Use remark to convert markdown into HTML string\n      const processedContent = await remark()\n        .use(html)\n        .process(matterResult.content);\n      const contentHtml = processedContent.toString();\n\n      // Combine the data with the id and contentHtml\n      posts.push({\n        id,\n        contentHtml,\n        markdown: matterResult.content,\n        ...matterResult.data,\n      });\n    }\n  });\n\n  return posts;\n};\n```\n\nWe can call this helper function in `pages/tags/[tag].js` under `getStaticProps()`\n\n```js\nexport const getStaticProps = async ({ params }) =\u003e {\n  const { tag } = params;\n  const taggedPosts = await getPostDataByTag(tag);\n  return {\n    props: {\n      tag,\n      taggedPosts,\n    },\n  };\n};\n```\n\nNow, you can render the associated tag pages as you wish, but I did it with a few components I had set up:\n\n```jsx\nconst TagPage = ({ tag, taggedPosts }) =\u003e {\n  const title = `Posts tagged \"${tag}\"`;\n  return (\n    \u003cLayout tagPage title={title} description={title}\u003e \n      \u003cheader\u003e\n        \u003cTag tag={tag} isHeader/\u003e\n      \u003c/header\u003e\n\n      \u003csection\u003e\n        \u003cPostList posts={taggedPosts} /\u003e\n      \u003c/section\u003e\n    \u003c/Layout\u003e\n  );\n};\n\nexport default TagPage;\n```\n\n### All tags\nThe last thing we want to add is a page containing all of the tags in a list, and all of the posts organized into categories.\n\nTo do this, we can add `pages/tags.js`, which can be reached at [/tags](/tags).\n\nOnce again, we want to implement `getStaticProps()` so we can pre-render this page at build time.  Luckily, we can reuse the two functions we wrote in `lib/tags.js` to make this easy.\n\n```js\nimport { getAllTags, getPostDataByTag } from '../lib/tags';\n\nexport const getStaticProps = async () =\u003e {\n  const tagsWithPosts = {};\n  const allTags = getAllTags();\n\n  for (const tagPath of allTags) {\n    const tag = tagPath.replace('/tags/', '');\n    tagsWithPosts[tag] = await getPostDataByTag(tag);\n  }\n\n  return {\n    props: {\n      tagsWithPosts,\n    },\n  };\n};\n```\n\nNow, you can render this as you'd like using `tagsWithPosts` as a prop in your page component.  I also like having a toggle to show/hide the associated posts.\n\n```jsx\nconst TagPage = ({ tagsWithPosts }) =\u003e {\n  const [showPosts, setShowPosts] = useState(false);\n\n  const tagAndPostList = Object.keys(tagsWithPosts).map((tag) =\u003e {\n    return (\n      \u003csection key={tag}\u003e\n        \u003cTag tag={tag} isHeader useLink label={tagsWithPosts[tag].length} /\u003e\n        {showPosts \u0026\u0026 \u003cPostList posts={tagsWithPosts[tag]} withPadding /\u003e }\n      \u003c/section\u003e\n    );\n  });\n\n  const title = 'All Tags';\n  return (\n    \u003cLayout title={title} description={title}\u003e\n      \u003cheader\u003e\n        \u003ch1\u003eAll tags\u003c/h1\u003e\n        \u003cdiv\u003e\n          \u003cCheckbox label={'Show posts'} value={showPosts} onChange={(x) =\u003e setShowPosts(!showPosts)} /\u003e\n        \u003c/div\u003e\n      \u003c/header\u003e\n\n      {tagAndPostList}\n\n    \u003c/Layout\u003e\n  );\n};\n\nexport default TagPage;\n```\n\nNow we have a page with all of our tags üôå.\n\n---\n\n## Adding a custom domain\nNext on my todo list was adding a custom domain to transition from bschoeneweis.github.io ‚û°Ô∏è bradleyschoeneweis.com.  GitHub gives a good overview of the steps [here](https://docs.github.com/en/pages/configuring-a-custom-domain-for-your-github-pages-site/managing-a-custom-domain-for-your-github-pages-site#configuring-an-apex-domain), but we'll go through it below specifically using [Google domains](https://domains.google/).\n\nWe'll be using an apex domain (e.g. bradleyschoeneweis.com).\n\n### GitHub changes\n1. Go to the repository settings for your GitHub pages repository\n2. Click into the **Pages** section\n3. Type your apex domain into the **Custom domain** input and click **Save**\n\n### Google domains changes\n1. Go to your [Google domains registrar](https://domains.google.com/registrar/)\n2. Click **Manage** on the domain you'd like to use\n3. Navigate to the **DNS** settings and under **Resource records**, click **Manage custom records**\n4. Refer to the [GitHub documentation](https://docs.github.com/en/pages/configuring-a-custom-domain-for-your-github-pages-site/managing-a-custom-domain-for-your-github-pages-site#configuring-an-apex-domain) for the official IP address list, but add the following `A` and `CNAME` records\n\n![DNS records](/images/rebuilding-my-blog/dns-records.jpg)\n\n### Final steps and confirmation\n1. Head back to the **Pages** settings for your repository and check **Enforce HTTPS**\n2. After a bit of time has passed, run `dig www.mynewdomain.com +nostats +nocomments +nocmd` replace with your domain name and your output should look similar to the following:\n\n![dig output](/images/rebuilding-my-blog/dig-output.jpg)\n\nNow your custom domain should be all set up with your GitHub pages blog! üéâ\n\n---\n\n## Simple automated deployment\nFor the final touches, I didn't want to have to worry about building the blog locally each time, so we'll create a simple GitHub action to build and serve our blog on each commit.\n\n### The `package.json` scripts\nIf you don't have one already, you should create a `build` script in `package.json` as `build: \"next build\"`.\n\nI won't cover it here, but you'll also need to go through tutorials related to [exporting your Next.js project as static HTML](https://nextjs.org/docs/advanced-features/static-html-export).  There are a few gotchas here.  For example, you cannot use the Next.js image optimization or API routes.  You can see the full list of [unsupported features](https://nextjs.org/docs/advanced-features/static-html-export#unsupported-features).\n\nLong story short, within your `package.json` file, you should add an `export: \"next export\"` script.  This will create an `out/` directory with HTML files when this command is run.  You probably want to add this directory to your `.gitignore` file.\n\n### Deploy key\nWe will be using [peaceiris/actions-gh-pages@v3](https://github.com/peaceiris/actions-gh-pages) for making the deployment step easy.  As a part of this, we want to set up an SSH deploy key for safety.\n\nYou can use an SSH key that you already have setup, or create a new one with:\n\n```bash\nssh-keygen -t rsa -b 4096 -C \"$(git config user.email)\" -f gh-pages -N \"\"\n```\n\n1. Navigate back to your repository settings, and under security, go to **Deploy keys**\n2. Click **Add a deploy key** and enter `ACTIONS_DEPLOY_KEY` as the title\n3. Paste in your public RSA key (ends with `.pub`)\n4. Check **Allow write access** and then click **Add key**\n\n### `deploy.yml`\nNow that every thing is set up, we can put this all into a GitHub actions file.\n\nFrom the root of the project, create `.github/workflows/deploy.yml` and refer to the following:\n\n```yml\nname: Deploy to Github Pages\n\non:\n  push:\n    branches:\n      - develop\n\njobs:\n  deployment:\n    runs-on: ubuntu-latest\n\n    strategy:\n      matrix:\n        node-version: [14.x]\n\n    steps:\n      - uses: actions/checkout@v2\n\n      - name: Use Node.js ${{ matrix.node-version }}\n        uses: actions/setup-node@v2\n        with:\n          node-version: ${{ matrix.node-version }}\n\n      - name: Update NPM\n        run: npm i -g npm@latest\n\n      - name: Cache dependencies\n        uses: actions/cache@v2\n        with:\n          path: ~/.npm\n          key: ${{ runner.OS }}-node-${{ hashFiles('**/package-lock.json') }}\n          restore-keys: |\n            ${{ runner.OS }}-node-\n            ${{ runner.OS }}-\n\n      - name: Build\n        run: |\n          npm i --legacy-peer-deps\n          npm run build\n          npm run export\n\n      - name: Deploy\n        uses: peaceiris/actions-gh-pages@v3\n        with:\n          deploy_key: ${{ secrets.ACTIONS_DEPLOY_KEY }}\n          publish_dir: ./out\n          cname: yoururl.com\n```\n\nA few things to note:\n- The branch I actively work on is `develop`, so you'll want to update that to the branch you push to\n- If you didn't name your deploy key `ACTIONS_DEPLOY_KEY`, change the `deploy_key` value to `secrets.[Your key name]` in the **Deploy** step\n- The `cname` value in the **Deploy** step should be replaced with your newly configured custom domain\n\nNow, each time you commit and push up you blog changes, your blog should automatically be built and served under your custom domain.\n\nJust like that, your blog is just as functional as a cookiecutter template üç™ and more easy to build upon than ever before.\n\n---\n","title":"Rebuilding my blog from scratch with Next.js","date":"2022-04-23","tags":["nextjs","react","javascript"],"description":"Rebuilding my blog from a Gatsby.js templated site to a custom Next.js site from scratch."}],"react":[{"id":"rebuilding-my-blog","contentHtml":"\u003ch2\u003eVersion \u003ccode\u003e0.1.x\u003c/code\u003e\u003c/h2\u003e\n\u003cp\u003eThe first iteration of my blog was built using a pre-configured \u003ca href=\"https://www.gatsbyjs.com/\"\u003eGatsbyJS\u003c/a\u003e site template.  I chose a template (\u003ca href=\"https://novela.narative.co/\"\u003eNovela by Narative\u003c/a\u003e) that checked all my boxes for an easy tool to start sharing my writing.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eThe theme was modern and sleek\u003c/li\u003e\n\u003cli\u003eEverything was mobile-friendly\u003c/li\u003e\n\u003cli\u003eLots of plug-and-play options and prebuilt components that flowed together\n\u003cul\u003e\n\u003cli\u003eArticle metadata that connects to an author bio page\u003c/li\u003e\n\u003cli\u003eReading time estimates and progress bars\u003c/li\u003e\n\u003cli\u003eEasy image optimizations\u003c/li\u003e\n\u003cli\u003eA config for a Google Analytics tag\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eDeployment was straightforward with GitHub pages\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eBut most importantly, all I had to do was add Markdown pages to a directory to get started.  At the time, I didn't really know much about GatsbyJS, other than it being a popular static site generator, and my modern JavaScript knowledge was introductory at-best (albeit growing each and every day).  So this seemed like the perfect route forward.\u003c/p\u003e\n\u003ch2\u003eThe problem\u003c/h2\u003e\n\u003cp\u003eAs I started writing more and more posts, I began noting different features I wanted to include on my site.  These weren't terribly complex additions, but rather simple things like adding tags to group common posts or wanting to change the styling of the inline code snippets.\u003c/p\u003e\n\u003cp\u003eI soon discovered that trying to color outside the lines when using a cookiecutter template can get very complex, very quickly.\u003c/p\u003e\n\u003cp\u003eI found myself digging into nested modules in my \u003ccode\u003enode_modules\u003c/code\u003e folder where I would need to overload different functions and components to get what I wanted.  It was added complexity than I didn't foresee when I signed up to use a template.  Plus, this site could eventually house more than just a blog, and the template I chose wasn't designed to accommodate much else.\u003c/p\u003e\n\u003ch2\u003eWhat now?\u003c/h2\u003e\n\u003cp\u003eIf you haven't noticed from the timestamp on my last article, I haven't written a post in ~9 months.  This is largely because I was interviewing for new positions and eventually joined the team at \u003ca href=\"https://radar.com\"\u003eRadar\u003c/a\u003e as a Product Engineer!  Preparation for interviews and taking a break after accepting this new position occupied much of the time I would normally spend writing.  Plus, taking a break from coding outside of work is a good way to avoid burnout ü§∑‚Äç‚ôÇÔ∏è.\u003c/p\u003e\n\u003cp\u003eThe reason I mention this is because one of the technologies we use at Radar is \u003ca href=\"https://nextjs.org/\"\u003eNext.js\u003c/a\u003e.  Next.js was something I was already trying to learn in my free time, but I've been able to gain a good amount of experience with it since I've started my new role, and my modern JavaScript fundamentals and understanding have grown drastically in the past several month (expect a lot more JavaScript posts going forward).\u003c/p\u003e\n\u003cp\u003eSeeing the power of Next.js and knowing I wanted my blog to be more flexible, I decided to recreate my blog from scratch using Next.js.\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003eNext.js\u003c/h2\u003e\n\u003cp\u003eA quick prelude on \u003ca href=\"https://nextjs.org/\"\u003eNext.js\u003c/a\u003e for those who have never used it.  \u003ca href=\"https://vercel.com/\"\u003eVercel\u003c/a\u003e, the creators of Next.js (and a company to keep üëÄ on) says it best, Next.js is...\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\"The \u003ca href=\"https://reactjs.org/\"\u003eReact\u003c/a\u003e Framework for Production\"\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eNext.js comes with a ton of great built-in features including:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eStatic + server-side rendering\u003c/li\u003e\n\u003cli\u003eSmart bundling and code-splitting, TypeScript support, Routing, Fast Refresh, CSS + Sass support all without complex configs\u003c/li\u003e\n\u003cli\u003eImage optimization\u003c/li\u003e\n\u003cli\u003eIntuitive code organization (because there are a million-plus ways to organize a React project)\u003c/li\u003e\n\u003cli\u003eStatic HTML exports (this one is important for our purposes)\u003c/li\u003e\n\u003cli\u003eSo much more...\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eIt's an awesome framework.\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eCoincidentally enough, the \u003ca href=\"https://nextjs.org/learn/basics/create-nextjs-app\"\u003eNext.js hands-on tutorial\u003c/a\u003e walks you through setting up a blog with Next.js. Following this tutorial will set you up with a great and simplistic starter blog (but not quite ready for deployment on GitHub pages, where this blog lives at the time of writing).\u003c/p\u003e\n\u003cp\u003eA few things this tutorial covers:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eCreating the Next.js app\u003c/li\u003e\n\u003cli\u003eBasics like in-app navigation, styling, adding images and more\u003c/li\u003e\n\u003cli\u003eSetting up metadata, blog pages, and pre-rendering\u003c/li\u003e\n\u003cli\u003eMarkdown ‚û°Ô∏è HTML\u003c/li\u003e\n\u003cli\u003eReworking your app to use dynamic routing\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThe tutorial is great so I won't cover anything that's already covered there.  If you're interested in using Next.js, you should definitely go through it.\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003eBeyond the basics\u003c/h2\u003e\n\u003cp\u003eAs mentioned, the \u003ca href=\"https://nextjs.org/learn/basics/create-nextjs-app\"\u003eNext.js tutorial\u003c/a\u003e is a great starting point, but I wanted to get my blog to a place where it was comparable to the previous iteration, along with the new features that encouraged me to take on this project in the first place.\u003c/p\u003e\n\u003cp\u003eTo keep things concise, we'll cover adding \u003ca href=\"/tags\"\u003etags\u003c/a\u003e, adding a custom domain from \u003ca href=\"https://domains.google/\"\u003eGoogle Domains\u003c/a\u003e to GitHub pages, and adding a GitHub action to automatically build and deploy our blog on each commit.\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003eTags\u003c/h2\u003e\n\u003cp\u003eOrganization within code and outside of code is always at the top of my priority list, so categorizing posts by tag was first on my blog todo list.\u003c/p\u003e\n\u003ch3\u003eAdding tags to each post\u003c/h3\u003e\n\u003cp\u003eFirst, let's add tags to each of our posts.  We can work off of the blog data section of the \u003ca href=\"https://nextjs.org/learn/basics/data-fetching/blog-data\"\u003eNext.js tutorial\u003c/a\u003e and add some additional YAML metadata to our markdown posts using \u003ca href=\"https://github.com/jonschlinkert/gray-matter\"\u003egray-matter\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eWithin the current metadata, add a list of tags relevant to the post:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e---\ntitle: 'Rebuilding my blog from scratch with Next.js'\ndate: '2022-04-23'\ntags: ['nextjs', 'react', 'javascript']\ndescription: 'Rebuilding my blog from a Gatsby.js templated site to a custom Next.js site from scratch.'\n---\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eI won't cover rendering of the tags below each posts in the post list, but the tags list should get picked up automatically with the \u003ccode\u003egetSortedPostsData()\u003c/code\u003e function that was already written and is called by \u003ccode\u003egetStaticProps()\u003c/code\u003e in order to pass props down the the post related components.\u003c/p\u003e\n\u003ch3\u003e/tags/[tag]\u003c/h3\u003e\n\u003cp\u003eWhat we've done so far will associate posts with a list of tags, but now we also want a page for each tag that lists out the associated posts.  For example, to view \u003ccode\u003epython\u003c/code\u003e related posts, we can go to \u003ca href=\"/tags/python\"\u003e/tags/python\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eWith Next.js, this can be done easily using \u003ca href=\"https://nextjs.org/docs/routing/dynamic-routes\"\u003edynamic routes\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eUnder the \u003ccode\u003epages/\u003c/code\u003e directory, create a \u003ccode\u003epages/tags/[tag].js\u003c/code\u003e file structure.  We'll be repeating similar patterns done within \u003ccode\u003epages/posts/[id].js\u003c/code\u003e.\u003c/p\u003e\n\u003cp\u003eLike earlier, we need to implement \u003ccode\u003egetStaticProps()\u003c/code\u003e (\u003ca href=\"https://nextjs.org/docs/basic-features/data-fetching/get-static-props\"\u003emore info here\u003c/a\u003e), so we can render these pages at build time.  We also need to implement \u003ccode\u003egetStaticPaths()\u003c/code\u003e (\u003ca href=\"https://nextjs.org/docs/basic-features/data-fetching/get-static-paths\"\u003emore info here\u003c/a\u003e) to get a list of all possible tags at build time.\u003c/p\u003e\n\u003cp\u003eLet's create a \u003ccode\u003elib/tags.js\u003c/code\u003e file to house some of the helper functions to implement \u003ccode\u003egetStaticProps()\u003c/code\u003e and \u003ccode\u003egetStaticPaths()\u003c/code\u003e.\u003c/p\u003e\n\u003cp\u003eFirst, we want to get a list of all the tags so we can write \u003ccode\u003egetStaticPaths()\u003c/code\u003e.  This will require processing all of the files within \u003ccode\u003eposts/\u003c/code\u003e, and processing the metadata using \u003ca href=\"https://github.com/jonschlinkert/gray-matter\"\u003egray-matter\u003c/a\u003e.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eimport fs from 'fs';\nimport path from 'path';\nimport matter from 'gray-matter';\n\nconst postsDirectory = path.join(process.cwd(), 'posts');\n\nexport const getAllTags = () =\u003e {\n  const fileNames = fs.readdirSync(postsDirectory);\n  const tags = new Set();\n\n  fileNames.map(fileName =\u003e {\n    // Read markdown file as string\n    const fullPath = path.join(postsDirectory, fileName);\n    const fileContents = fs.readFileSync(fullPath, 'utf8');\n\n    // Use gray-matter to parse the post metadata section\n    const matterResult = matter(fileContents);\n    if (matterResult?.data?.tags) {\n      matterResult.data.tags.forEach(\n        (tag) =\u003e tags.add(`/tags/${tag.replace(/\\s+/g, '-').toLowerCase()}`)\n      );\n    }\n  });\n\n  return Array.from(tags);\n};\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eNow we can call this within \u003ccode\u003epages/tags/[tag].js\u003c/code\u003e under \u003ccode\u003egetStaticPaths()\u003c/code\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eexport const getStaticPaths = () =\u003e {\n  const paths = getAllTags();\n  return {\n    paths,\n    fallback: false,\n  }\n};\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eNow, we can add another helper function \u003ccode\u003egetPostDataByTag()\u003c/code\u003e in \u003ccode\u003elib/tags.js\u003c/code\u003e to fulfill \u003ccode\u003egetStaticProps()\u003c/code\u003e.  This is basically what we already do with \u003ccode\u003epages/posts/[id].js\u003c/code\u003e, and it's not very efficient to do this twice, but all of this is happening at build time so it's not a huge deal for us.\u003c/p\u003e\n\u003cp\u003eFor this, we will use \u003ca href=\"https://github.com/remarkjs/remark\"\u003eremark\u003c/a\u003e to process our markdown files.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eimport fs from 'fs';\nimport path from 'path';\nimport matter from 'gray-matter';\nimport { remark } from 'remark';\nimport html from 'remark-html';\n\nconst postsDirectory = path.join(process.cwd(), 'posts');\n\nexport const getPostDataByTag = async (tag) =\u003e {\n  const fileNames = fs.readdirSync(postsDirectory);\n  const posts = [];\n\n  fileNames.map(async (fileName) =\u003e {\n    const id = fileName.replace(/\\.md$/, '');\n  \n    // Read markdown file as string\n    const fullPath = path.join(postsDirectory, fileName);\n    const fileContents = fs.readFileSync(fullPath, 'utf8');\n\n    // Use gray-matter to parse the post metadata section\n    const matterResult = matter(fileContents);\n\n    if (matterResult?.data?.tags \u0026#x26;\u0026#x26; matterResult.data.tags.includes(tag)) {\n      // Use remark to convert markdown into HTML string\n      const processedContent = await remark()\n        .use(html)\n        .process(matterResult.content);\n      const contentHtml = processedContent.toString();\n\n      // Combine the data with the id and contentHtml\n      posts.push({\n        id,\n        contentHtml,\n        markdown: matterResult.content,\n        ...matterResult.data,\n      });\n    }\n  });\n\n  return posts;\n};\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eWe can call this helper function in \u003ccode\u003epages/tags/[tag].js\u003c/code\u003e under \u003ccode\u003egetStaticProps()\u003c/code\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eexport const getStaticProps = async ({ params }) =\u003e {\n  const { tag } = params;\n  const taggedPosts = await getPostDataByTag(tag);\n  return {\n    props: {\n      tag,\n      taggedPosts,\n    },\n  };\n};\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eNow, you can render the associated tag pages as you wish, but I did it with a few components I had set up:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003econst TagPage = ({ tag, taggedPosts }) =\u003e {\n  const title = `Posts tagged \"${tag}\"`;\n  return (\n    \u0026#x3C;Layout tagPage title={title} description={title}\u003e \n      \u0026#x3C;header\u003e\n        \u0026#x3C;Tag tag={tag} isHeader/\u003e\n      \u0026#x3C;/header\u003e\n\n      \u0026#x3C;section\u003e\n        \u0026#x3C;PostList posts={taggedPosts} /\u003e\n      \u0026#x3C;/section\u003e\n    \u0026#x3C;/Layout\u003e\n  );\n};\n\nexport default TagPage;\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003eAll tags\u003c/h3\u003e\n\u003cp\u003eThe last thing we want to add is a page containing all of the tags in a list, and all of the posts organized into categories.\u003c/p\u003e\n\u003cp\u003eTo do this, we can add \u003ccode\u003epages/tags.js\u003c/code\u003e, which can be reached at \u003ca href=\"/tags\"\u003e/tags\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eOnce again, we want to implement \u003ccode\u003egetStaticProps()\u003c/code\u003e so we can pre-render this page at build time.  Luckily, we can reuse the two functions we wrote in \u003ccode\u003elib/tags.js\u003c/code\u003e to make this easy.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eimport { getAllTags, getPostDataByTag } from '../lib/tags';\n\nexport const getStaticProps = async () =\u003e {\n  const tagsWithPosts = {};\n  const allTags = getAllTags();\n\n  for (const tagPath of allTags) {\n    const tag = tagPath.replace('/tags/', '');\n    tagsWithPosts[tag] = await getPostDataByTag(tag);\n  }\n\n  return {\n    props: {\n      tagsWithPosts,\n    },\n  };\n};\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eNow, you can render this as you'd like using \u003ccode\u003etagsWithPosts\u003c/code\u003e as a prop in your page component.  I also like having a toggle to show/hide the associated posts.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003econst TagPage = ({ tagsWithPosts }) =\u003e {\n  const [showPosts, setShowPosts] = useState(false);\n\n  const tagAndPostList = Object.keys(tagsWithPosts).map((tag) =\u003e {\n    return (\n      \u0026#x3C;section key={tag}\u003e\n        \u0026#x3C;Tag tag={tag} isHeader useLink label={tagsWithPosts[tag].length} /\u003e\n        {showPosts \u0026#x26;\u0026#x26; \u0026#x3C;PostList posts={tagsWithPosts[tag]} withPadding /\u003e }\n      \u0026#x3C;/section\u003e\n    );\n  });\n\n  const title = 'All Tags';\n  return (\n    \u0026#x3C;Layout title={title} description={title}\u003e\n      \u0026#x3C;header\u003e\n        \u0026#x3C;h1\u003eAll tags\u0026#x3C;/h1\u003e\n        \u0026#x3C;div\u003e\n          \u0026#x3C;Checkbox label={'Show posts'} value={showPosts} onChange={(x) =\u003e setShowPosts(!showPosts)} /\u003e\n        \u0026#x3C;/div\u003e\n      \u0026#x3C;/header\u003e\n\n      {tagAndPostList}\n\n    \u0026#x3C;/Layout\u003e\n  );\n};\n\nexport default TagPage;\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eNow we have a page with all of our tags üôå.\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003eAdding a custom domain\u003c/h2\u003e\n\u003cp\u003eNext on my todo list was adding a custom domain to transition from bschoeneweis.github.io ‚û°Ô∏è bradleyschoeneweis.com.  GitHub gives a good overview of the steps \u003ca href=\"https://docs.github.com/en/pages/configuring-a-custom-domain-for-your-github-pages-site/managing-a-custom-domain-for-your-github-pages-site#configuring-an-apex-domain\"\u003ehere\u003c/a\u003e, but we'll go through it below specifically using \u003ca href=\"https://domains.google/\"\u003eGoogle domains\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eWe'll be using an apex domain (e.g. bradleyschoeneweis.com).\u003c/p\u003e\n\u003ch3\u003eGitHub changes\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003eGo to the repository settings for your GitHub pages repository\u003c/li\u003e\n\u003cli\u003eClick into the \u003cstrong\u003ePages\u003c/strong\u003e section\u003c/li\u003e\n\u003cli\u003eType your apex domain into the \u003cstrong\u003eCustom domain\u003c/strong\u003e input and click \u003cstrong\u003eSave\u003c/strong\u003e\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3\u003eGoogle domains changes\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003eGo to your \u003ca href=\"https://domains.google.com/registrar/\"\u003eGoogle domains registrar\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003eClick \u003cstrong\u003eManage\u003c/strong\u003e on the domain you'd like to use\u003c/li\u003e\n\u003cli\u003eNavigate to the \u003cstrong\u003eDNS\u003c/strong\u003e settings and under \u003cstrong\u003eResource records\u003c/strong\u003e, click \u003cstrong\u003eManage custom records\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003eRefer to the \u003ca href=\"https://docs.github.com/en/pages/configuring-a-custom-domain-for-your-github-pages-site/managing-a-custom-domain-for-your-github-pages-site#configuring-an-apex-domain\"\u003eGitHub documentation\u003c/a\u003e for the official IP address list, but add the following \u003ccode\u003eA\u003c/code\u003e and \u003ccode\u003eCNAME\u003c/code\u003e records\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\u003cimg src=\"/images/rebuilding-my-blog/dns-records.jpg\" alt=\"DNS records\"\u003e\u003c/p\u003e\n\u003ch3\u003eFinal steps and confirmation\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003eHead back to the \u003cstrong\u003ePages\u003c/strong\u003e settings for your repository and check \u003cstrong\u003eEnforce HTTPS\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003eAfter a bit of time has passed, run \u003ccode\u003edig www.mynewdomain.com +nostats +nocomments +nocmd\u003c/code\u003e replace with your domain name and your output should look similar to the following:\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\u003cimg src=\"/images/rebuilding-my-blog/dig-output.jpg\" alt=\"dig output\"\u003e\u003c/p\u003e\n\u003cp\u003eNow your custom domain should be all set up with your GitHub pages blog! üéâ\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003eSimple automated deployment\u003c/h2\u003e\n\u003cp\u003eFor the final touches, I didn't want to have to worry about building the blog locally each time, so we'll create a simple GitHub action to build and serve our blog on each commit.\u003c/p\u003e\n\u003ch3\u003eThe \u003ccode\u003epackage.json\u003c/code\u003e scripts\u003c/h3\u003e\n\u003cp\u003eIf you don't have one already, you should create a \u003ccode\u003ebuild\u003c/code\u003e script in \u003ccode\u003epackage.json\u003c/code\u003e as \u003ccode\u003ebuild: \"next build\"\u003c/code\u003e.\u003c/p\u003e\n\u003cp\u003eI won't cover it here, but you'll also need to go through tutorials related to \u003ca href=\"https://nextjs.org/docs/advanced-features/static-html-export\"\u003eexporting your Next.js project as static HTML\u003c/a\u003e.  There are a few gotchas here.  For example, you cannot use the Next.js image optimization or API routes.  You can see the full list of \u003ca href=\"https://nextjs.org/docs/advanced-features/static-html-export#unsupported-features\"\u003eunsupported features\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eLong story short, within your \u003ccode\u003epackage.json\u003c/code\u003e file, you should add an \u003ccode\u003eexport: \"next export\"\u003c/code\u003e script.  This will create an \u003ccode\u003eout/\u003c/code\u003e directory with HTML files when this command is run.  You probably want to add this directory to your \u003ccode\u003e.gitignore\u003c/code\u003e file.\u003c/p\u003e\n\u003ch3\u003eDeploy key\u003c/h3\u003e\n\u003cp\u003eWe will be using \u003ca href=\"https://github.com/peaceiris/actions-gh-pages\"\u003epeaceiris/actions-gh-pages@v3\u003c/a\u003e for making the deployment step easy.  As a part of this, we want to set up an SSH deploy key for safety.\u003c/p\u003e\n\u003cp\u003eYou can use an SSH key that you already have setup, or create a new one with:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003essh-keygen -t rsa -b 4096 -C \"$(git config user.email)\" -f gh-pages -N \"\"\n\u003c/code\u003e\u003c/pre\u003e\n\u003col\u003e\n\u003cli\u003eNavigate back to your repository settings, and under security, go to \u003cstrong\u003eDeploy keys\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003eClick \u003cstrong\u003eAdd a deploy key\u003c/strong\u003e and enter \u003ccode\u003eACTIONS_DEPLOY_KEY\u003c/code\u003e as the title\u003c/li\u003e\n\u003cli\u003ePaste in your public RSA key (ends with \u003ccode\u003e.pub\u003c/code\u003e)\u003c/li\u003e\n\u003cli\u003eCheck \u003cstrong\u003eAllow write access\u003c/strong\u003e and then click \u003cstrong\u003eAdd key\u003c/strong\u003e\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3\u003e\u003ccode\u003edeploy.yml\u003c/code\u003e\u003c/h3\u003e\n\u003cp\u003eNow that every thing is set up, we can put this all into a GitHub actions file.\u003c/p\u003e\n\u003cp\u003eFrom the root of the project, create \u003ccode\u003e.github/workflows/deploy.yml\u003c/code\u003e and refer to the following:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ename: Deploy to Github Pages\n\non:\n  push:\n    branches:\n      - develop\n\njobs:\n  deployment:\n    runs-on: ubuntu-latest\n\n    strategy:\n      matrix:\n        node-version: [14.x]\n\n    steps:\n      - uses: actions/checkout@v2\n\n      - name: Use Node.js ${{ matrix.node-version }}\n        uses: actions/setup-node@v2\n        with:\n          node-version: ${{ matrix.node-version }}\n\n      - name: Update NPM\n        run: npm i -g npm@latest\n\n      - name: Cache dependencies\n        uses: actions/cache@v2\n        with:\n          path: ~/.npm\n          key: ${{ runner.OS }}-node-${{ hashFiles('**/package-lock.json') }}\n          restore-keys: |\n            ${{ runner.OS }}-node-\n            ${{ runner.OS }}-\n\n      - name: Build\n        run: |\n          npm i --legacy-peer-deps\n          npm run build\n          npm run export\n\n      - name: Deploy\n        uses: peaceiris/actions-gh-pages@v3\n        with:\n          deploy_key: ${{ secrets.ACTIONS_DEPLOY_KEY }}\n          publish_dir: ./out\n          cname: yoururl.com\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eA few things to note:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eThe branch I actively work on is \u003ccode\u003edevelop\u003c/code\u003e, so you'll want to update that to the branch you push to\u003c/li\u003e\n\u003cli\u003eIf you didn't name your deploy key \u003ccode\u003eACTIONS_DEPLOY_KEY\u003c/code\u003e, change the \u003ccode\u003edeploy_key\u003c/code\u003e value to \u003ccode\u003esecrets.[Your key name]\u003c/code\u003e in the \u003cstrong\u003eDeploy\u003c/strong\u003e step\u003c/li\u003e\n\u003cli\u003eThe \u003ccode\u003ecname\u003c/code\u003e value in the \u003cstrong\u003eDeploy\u003c/strong\u003e step should be replaced with your newly configured custom domain\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eNow, each time you commit and push up you blog changes, your blog should automatically be built and served under your custom domain.\u003c/p\u003e\n\u003cp\u003eJust like that, your blog is just as functional as a cookiecutter template üç™ and more easy to build upon than ever before.\u003c/p\u003e\n\u003chr\u003e\n","markdown":"\n## Version `0.1.x`\n\nThe first iteration of my blog was built using a pre-configured [GatsbyJS](https://www.gatsbyjs.com/) site template.  I chose a template ([Novela by Narative](https://novela.narative.co/)) that checked all my boxes for an easy tool to start sharing my writing.\n\n- The theme was modern and sleek\n- Everything was mobile-friendly\n- Lots of plug-and-play options and prebuilt components that flowed together\n  - Article metadata that connects to an author bio page\n  - Reading time estimates and progress bars\n  - Easy image optimizations\n  - A config for a Google Analytics tag\n- Deployment was straightforward with GitHub pages\n  \nBut most importantly, all I had to do was add Markdown pages to a directory to get started.  At the time, I didn't really know much about GatsbyJS, other than it being a popular static site generator, and my modern JavaScript knowledge was introductory at-best (albeit growing each and every day).  So this seemed like the perfect route forward.\n\n## The problem\n\nAs I started writing more and more posts, I began noting different features I wanted to include on my site.  These weren't terribly complex additions, but rather simple things like adding tags to group common posts or wanting to change the styling of the inline code snippets.\n\nI soon discovered that trying to color outside the lines when using a cookiecutter template can get very complex, very quickly.\n\nI found myself digging into nested modules in my `node_modules` folder where I would need to overload different functions and components to get what I wanted.  It was added complexity than I didn't foresee when I signed up to use a template.  Plus, this site could eventually house more than just a blog, and the template I chose wasn't designed to accommodate much else.\n\n## What now?\n\nIf you haven't noticed from the timestamp on my last article, I haven't written a post in ~9 months.  This is largely because I was interviewing for new positions and eventually joined the team at [Radar](https://radar.com) as a Product Engineer!  Preparation for interviews and taking a break after accepting this new position occupied much of the time I would normally spend writing.  Plus, taking a break from coding outside of work is a good way to avoid burnout ü§∑‚Äç‚ôÇÔ∏è.\n\nThe reason I mention this is because one of the technologies we use at Radar is [Next.js](https://nextjs.org/).  Next.js was something I was already trying to learn in my free time, but I've been able to gain a good amount of experience with it since I've started my new role, and my modern JavaScript fundamentals and understanding have grown drastically in the past several month (expect a lot more JavaScript posts going forward).\n\nSeeing the power of Next.js and knowing I wanted my blog to be more flexible, I decided to recreate my blog from scratch using Next.js.\n\n---\n\n## Next.js\n\nA quick prelude on [Next.js](https://nextjs.org/) for those who have never used it.  [Vercel](https://vercel.com/), the creators of Next.js (and a company to keep üëÄ on) says it best, Next.js is...\n\n\u003e \"The [React](https://reactjs.org/) Framework for Production\"\n\nNext.js comes with a ton of great built-in features including:\n- Static + server-side rendering\n- Smart bundling and code-splitting, TypeScript support, Routing, Fast Refresh, CSS + Sass support all without complex configs\n- Image optimization\n- Intuitive code organization (because there are a million-plus ways to organize a React project)\n- Static HTML exports (this one is important for our purposes)\n- So much more...\n\n**It's an awesome framework.**\n\nCoincidentally enough, the [Next.js hands-on tutorial](https://nextjs.org/learn/basics/create-nextjs-app) walks you through setting up a blog with Next.js. Following this tutorial will set you up with a great and simplistic starter blog (but not quite ready for deployment on GitHub pages, where this blog lives at the time of writing).\n\nA few things this tutorial covers:\n- Creating the Next.js app\n- Basics like in-app navigation, styling, adding images and more\n- Setting up metadata, blog pages, and pre-rendering\n- Markdown ‚û°Ô∏è HTML\n- Reworking your app to use dynamic routing\n\nThe tutorial is great so I won't cover anything that's already covered there.  If you're interested in using Next.js, you should definitely go through it.\n\n---\n\n## Beyond the basics\n\nAs mentioned, the [Next.js tutorial](https://nextjs.org/learn/basics/create-nextjs-app) is a great starting point, but I wanted to get my blog to a place where it was comparable to the previous iteration, along with the new features that encouraged me to take on this project in the first place.\n\nTo keep things concise, we'll cover adding [tags](/tags), adding a custom domain from [Google Domains](https://domains.google/) to GitHub pages, and adding a GitHub action to automatically build and deploy our blog on each commit.\n\n---\n\n## Tags\nOrganization within code and outside of code is always at the top of my priority list, so categorizing posts by tag was first on my blog todo list.\n\n### Adding tags to each post\n\nFirst, let's add tags to each of our posts.  We can work off of the blog data section of the [Next.js tutorial](https://nextjs.org/learn/basics/data-fetching/blog-data) and add some additional YAML metadata to our markdown posts using [gray-matter](https://github.com/jonschlinkert/gray-matter).\n\nWithin the current metadata, add a list of tags relevant to the post:\n\n```yaml\n---\ntitle: 'Rebuilding my blog from scratch with Next.js'\ndate: '2022-04-23'\ntags: ['nextjs', 'react', 'javascript']\ndescription: 'Rebuilding my blog from a Gatsby.js templated site to a custom Next.js site from scratch.'\n---\n```\n\nI won't cover rendering of the tags below each posts in the post list, but the tags list should get picked up automatically with the `getSortedPostsData()` function that was already written and is called by `getStaticProps()` in order to pass props down the the post related components.\n\n### /tags/[tag]\n\nWhat we've done so far will associate posts with a list of tags, but now we also want a page for each tag that lists out the associated posts.  For example, to view `python` related posts, we can go to [/tags/python](/tags/python).\n\nWith Next.js, this can be done easily using [dynamic routes](https://nextjs.org/docs/routing/dynamic-routes).\n\nUnder the `pages/` directory, create a `pages/tags/[tag].js` file structure.  We'll be repeating similar patterns done within `pages/posts/[id].js`.\n\nLike earlier, we need to implement `getStaticProps()` ([more info here](https://nextjs.org/docs/basic-features/data-fetching/get-static-props)), so we can render these pages at build time.  We also need to implement `getStaticPaths()` ([more info here](https://nextjs.org/docs/basic-features/data-fetching/get-static-paths)) to get a list of all possible tags at build time.\n\nLet's create a `lib/tags.js` file to house some of the helper functions to implement `getStaticProps()` and `getStaticPaths()`.\n\nFirst, we want to get a list of all the tags so we can write `getStaticPaths()`.  This will require processing all of the files within `posts/`, and processing the metadata using [gray-matter](https://github.com/jonschlinkert/gray-matter).\n\n```js\nimport fs from 'fs';\nimport path from 'path';\nimport matter from 'gray-matter';\n\nconst postsDirectory = path.join(process.cwd(), 'posts');\n\nexport const getAllTags = () =\u003e {\n  const fileNames = fs.readdirSync(postsDirectory);\n  const tags = new Set();\n\n  fileNames.map(fileName =\u003e {\n    // Read markdown file as string\n    const fullPath = path.join(postsDirectory, fileName);\n    const fileContents = fs.readFileSync(fullPath, 'utf8');\n\n    // Use gray-matter to parse the post metadata section\n    const matterResult = matter(fileContents);\n    if (matterResult?.data?.tags) {\n      matterResult.data.tags.forEach(\n        (tag) =\u003e tags.add(`/tags/${tag.replace(/\\s+/g, '-').toLowerCase()}`)\n      );\n    }\n  });\n\n  return Array.from(tags);\n};\n```\n\nNow we can call this within `pages/tags/[tag].js` under `getStaticPaths()`\n\n```js\nexport const getStaticPaths = () =\u003e {\n  const paths = getAllTags();\n  return {\n    paths,\n    fallback: false,\n  }\n};\n```\n\nNow, we can add another helper function `getPostDataByTag()` in `lib/tags.js` to fulfill `getStaticProps()`.  This is basically what we already do with `pages/posts/[id].js`, and it's not very efficient to do this twice, but all of this is happening at build time so it's not a huge deal for us.\n\nFor this, we will use [remark](https://github.com/remarkjs/remark) to process our markdown files.\n\n```js\nimport fs from 'fs';\nimport path from 'path';\nimport matter from 'gray-matter';\nimport { remark } from 'remark';\nimport html from 'remark-html';\n\nconst postsDirectory = path.join(process.cwd(), 'posts');\n\nexport const getPostDataByTag = async (tag) =\u003e {\n  const fileNames = fs.readdirSync(postsDirectory);\n  const posts = [];\n\n  fileNames.map(async (fileName) =\u003e {\n    const id = fileName.replace(/\\.md$/, '');\n  \n    // Read markdown file as string\n    const fullPath = path.join(postsDirectory, fileName);\n    const fileContents = fs.readFileSync(fullPath, 'utf8');\n\n    // Use gray-matter to parse the post metadata section\n    const matterResult = matter(fileContents);\n\n    if (matterResult?.data?.tags \u0026\u0026 matterResult.data.tags.includes(tag)) {\n      // Use remark to convert markdown into HTML string\n      const processedContent = await remark()\n        .use(html)\n        .process(matterResult.content);\n      const contentHtml = processedContent.toString();\n\n      // Combine the data with the id and contentHtml\n      posts.push({\n        id,\n        contentHtml,\n        markdown: matterResult.content,\n        ...matterResult.data,\n      });\n    }\n  });\n\n  return posts;\n};\n```\n\nWe can call this helper function in `pages/tags/[tag].js` under `getStaticProps()`\n\n```js\nexport const getStaticProps = async ({ params }) =\u003e {\n  const { tag } = params;\n  const taggedPosts = await getPostDataByTag(tag);\n  return {\n    props: {\n      tag,\n      taggedPosts,\n    },\n  };\n};\n```\n\nNow, you can render the associated tag pages as you wish, but I did it with a few components I had set up:\n\n```jsx\nconst TagPage = ({ tag, taggedPosts }) =\u003e {\n  const title = `Posts tagged \"${tag}\"`;\n  return (\n    \u003cLayout tagPage title={title} description={title}\u003e \n      \u003cheader\u003e\n        \u003cTag tag={tag} isHeader/\u003e\n      \u003c/header\u003e\n\n      \u003csection\u003e\n        \u003cPostList posts={taggedPosts} /\u003e\n      \u003c/section\u003e\n    \u003c/Layout\u003e\n  );\n};\n\nexport default TagPage;\n```\n\n### All tags\nThe last thing we want to add is a page containing all of the tags in a list, and all of the posts organized into categories.\n\nTo do this, we can add `pages/tags.js`, which can be reached at [/tags](/tags).\n\nOnce again, we want to implement `getStaticProps()` so we can pre-render this page at build time.  Luckily, we can reuse the two functions we wrote in `lib/tags.js` to make this easy.\n\n```js\nimport { getAllTags, getPostDataByTag } from '../lib/tags';\n\nexport const getStaticProps = async () =\u003e {\n  const tagsWithPosts = {};\n  const allTags = getAllTags();\n\n  for (const tagPath of allTags) {\n    const tag = tagPath.replace('/tags/', '');\n    tagsWithPosts[tag] = await getPostDataByTag(tag);\n  }\n\n  return {\n    props: {\n      tagsWithPosts,\n    },\n  };\n};\n```\n\nNow, you can render this as you'd like using `tagsWithPosts` as a prop in your page component.  I also like having a toggle to show/hide the associated posts.\n\n```jsx\nconst TagPage = ({ tagsWithPosts }) =\u003e {\n  const [showPosts, setShowPosts] = useState(false);\n\n  const tagAndPostList = Object.keys(tagsWithPosts).map((tag) =\u003e {\n    return (\n      \u003csection key={tag}\u003e\n        \u003cTag tag={tag} isHeader useLink label={tagsWithPosts[tag].length} /\u003e\n        {showPosts \u0026\u0026 \u003cPostList posts={tagsWithPosts[tag]} withPadding /\u003e }\n      \u003c/section\u003e\n    );\n  });\n\n  const title = 'All Tags';\n  return (\n    \u003cLayout title={title} description={title}\u003e\n      \u003cheader\u003e\n        \u003ch1\u003eAll tags\u003c/h1\u003e\n        \u003cdiv\u003e\n          \u003cCheckbox label={'Show posts'} value={showPosts} onChange={(x) =\u003e setShowPosts(!showPosts)} /\u003e\n        \u003c/div\u003e\n      \u003c/header\u003e\n\n      {tagAndPostList}\n\n    \u003c/Layout\u003e\n  );\n};\n\nexport default TagPage;\n```\n\nNow we have a page with all of our tags üôå.\n\n---\n\n## Adding a custom domain\nNext on my todo list was adding a custom domain to transition from bschoeneweis.github.io ‚û°Ô∏è bradleyschoeneweis.com.  GitHub gives a good overview of the steps [here](https://docs.github.com/en/pages/configuring-a-custom-domain-for-your-github-pages-site/managing-a-custom-domain-for-your-github-pages-site#configuring-an-apex-domain), but we'll go through it below specifically using [Google domains](https://domains.google/).\n\nWe'll be using an apex domain (e.g. bradleyschoeneweis.com).\n\n### GitHub changes\n1. Go to the repository settings for your GitHub pages repository\n2. Click into the **Pages** section\n3. Type your apex domain into the **Custom domain** input and click **Save**\n\n### Google domains changes\n1. Go to your [Google domains registrar](https://domains.google.com/registrar/)\n2. Click **Manage** on the domain you'd like to use\n3. Navigate to the **DNS** settings and under **Resource records**, click **Manage custom records**\n4. Refer to the [GitHub documentation](https://docs.github.com/en/pages/configuring-a-custom-domain-for-your-github-pages-site/managing-a-custom-domain-for-your-github-pages-site#configuring-an-apex-domain) for the official IP address list, but add the following `A` and `CNAME` records\n\n![DNS records](/images/rebuilding-my-blog/dns-records.jpg)\n\n### Final steps and confirmation\n1. Head back to the **Pages** settings for your repository and check **Enforce HTTPS**\n2. After a bit of time has passed, run `dig www.mynewdomain.com +nostats +nocomments +nocmd` replace with your domain name and your output should look similar to the following:\n\n![dig output](/images/rebuilding-my-blog/dig-output.jpg)\n\nNow your custom domain should be all set up with your GitHub pages blog! üéâ\n\n---\n\n## Simple automated deployment\nFor the final touches, I didn't want to have to worry about building the blog locally each time, so we'll create a simple GitHub action to build and serve our blog on each commit.\n\n### The `package.json` scripts\nIf you don't have one already, you should create a `build` script in `package.json` as `build: \"next build\"`.\n\nI won't cover it here, but you'll also need to go through tutorials related to [exporting your Next.js project as static HTML](https://nextjs.org/docs/advanced-features/static-html-export).  There are a few gotchas here.  For example, you cannot use the Next.js image optimization or API routes.  You can see the full list of [unsupported features](https://nextjs.org/docs/advanced-features/static-html-export#unsupported-features).\n\nLong story short, within your `package.json` file, you should add an `export: \"next export\"` script.  This will create an `out/` directory with HTML files when this command is run.  You probably want to add this directory to your `.gitignore` file.\n\n### Deploy key\nWe will be using [peaceiris/actions-gh-pages@v3](https://github.com/peaceiris/actions-gh-pages) for making the deployment step easy.  As a part of this, we want to set up an SSH deploy key for safety.\n\nYou can use an SSH key that you already have setup, or create a new one with:\n\n```bash\nssh-keygen -t rsa -b 4096 -C \"$(git config user.email)\" -f gh-pages -N \"\"\n```\n\n1. Navigate back to your repository settings, and under security, go to **Deploy keys**\n2. Click **Add a deploy key** and enter `ACTIONS_DEPLOY_KEY` as the title\n3. Paste in your public RSA key (ends with `.pub`)\n4. Check **Allow write access** and then click **Add key**\n\n### `deploy.yml`\nNow that every thing is set up, we can put this all into a GitHub actions file.\n\nFrom the root of the project, create `.github/workflows/deploy.yml` and refer to the following:\n\n```yml\nname: Deploy to Github Pages\n\non:\n  push:\n    branches:\n      - develop\n\njobs:\n  deployment:\n    runs-on: ubuntu-latest\n\n    strategy:\n      matrix:\n        node-version: [14.x]\n\n    steps:\n      - uses: actions/checkout@v2\n\n      - name: Use Node.js ${{ matrix.node-version }}\n        uses: actions/setup-node@v2\n        with:\n          node-version: ${{ matrix.node-version }}\n\n      - name: Update NPM\n        run: npm i -g npm@latest\n\n      - name: Cache dependencies\n        uses: actions/cache@v2\n        with:\n          path: ~/.npm\n          key: ${{ runner.OS }}-node-${{ hashFiles('**/package-lock.json') }}\n          restore-keys: |\n            ${{ runner.OS }}-node-\n            ${{ runner.OS }}-\n\n      - name: Build\n        run: |\n          npm i --legacy-peer-deps\n          npm run build\n          npm run export\n\n      - name: Deploy\n        uses: peaceiris/actions-gh-pages@v3\n        with:\n          deploy_key: ${{ secrets.ACTIONS_DEPLOY_KEY }}\n          publish_dir: ./out\n          cname: yoururl.com\n```\n\nA few things to note:\n- The branch I actively work on is `develop`, so you'll want to update that to the branch you push to\n- If you didn't name your deploy key `ACTIONS_DEPLOY_KEY`, change the `deploy_key` value to `secrets.[Your key name]` in the **Deploy** step\n- The `cname` value in the **Deploy** step should be replaced with your newly configured custom domain\n\nNow, each time you commit and push up you blog changes, your blog should automatically be built and served under your custom domain.\n\nJust like that, your blog is just as functional as a cookiecutter template üç™ and more easy to build upon than ever before.\n\n---\n","title":"Rebuilding my blog from scratch with Next.js","date":"2022-04-23","tags":["nextjs","react","javascript"],"description":"Rebuilding my blog from a Gatsby.js templated site to a custom Next.js site from scratch."}],"javascript":[{"id":"rebuilding-my-blog","contentHtml":"\u003ch2\u003eVersion \u003ccode\u003e0.1.x\u003c/code\u003e\u003c/h2\u003e\n\u003cp\u003eThe first iteration of my blog was built using a pre-configured \u003ca href=\"https://www.gatsbyjs.com/\"\u003eGatsbyJS\u003c/a\u003e site template.  I chose a template (\u003ca href=\"https://novela.narative.co/\"\u003eNovela by Narative\u003c/a\u003e) that checked all my boxes for an easy tool to start sharing my writing.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eThe theme was modern and sleek\u003c/li\u003e\n\u003cli\u003eEverything was mobile-friendly\u003c/li\u003e\n\u003cli\u003eLots of plug-and-play options and prebuilt components that flowed together\n\u003cul\u003e\n\u003cli\u003eArticle metadata that connects to an author bio page\u003c/li\u003e\n\u003cli\u003eReading time estimates and progress bars\u003c/li\u003e\n\u003cli\u003eEasy image optimizations\u003c/li\u003e\n\u003cli\u003eA config for a Google Analytics tag\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eDeployment was straightforward with GitHub pages\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eBut most importantly, all I had to do was add Markdown pages to a directory to get started.  At the time, I didn't really know much about GatsbyJS, other than it being a popular static site generator, and my modern JavaScript knowledge was introductory at-best (albeit growing each and every day).  So this seemed like the perfect route forward.\u003c/p\u003e\n\u003ch2\u003eThe problem\u003c/h2\u003e\n\u003cp\u003eAs I started writing more and more posts, I began noting different features I wanted to include on my site.  These weren't terribly complex additions, but rather simple things like adding tags to group common posts or wanting to change the styling of the inline code snippets.\u003c/p\u003e\n\u003cp\u003eI soon discovered that trying to color outside the lines when using a cookiecutter template can get very complex, very quickly.\u003c/p\u003e\n\u003cp\u003eI found myself digging into nested modules in my \u003ccode\u003enode_modules\u003c/code\u003e folder where I would need to overload different functions and components to get what I wanted.  It was added complexity than I didn't foresee when I signed up to use a template.  Plus, this site could eventually house more than just a blog, and the template I chose wasn't designed to accommodate much else.\u003c/p\u003e\n\u003ch2\u003eWhat now?\u003c/h2\u003e\n\u003cp\u003eIf you haven't noticed from the timestamp on my last article, I haven't written a post in ~9 months.  This is largely because I was interviewing for new positions and eventually joined the team at \u003ca href=\"https://radar.com\"\u003eRadar\u003c/a\u003e as a Product Engineer!  Preparation for interviews and taking a break after accepting this new position occupied much of the time I would normally spend writing.  Plus, taking a break from coding outside of work is a good way to avoid burnout ü§∑‚Äç‚ôÇÔ∏è.\u003c/p\u003e\n\u003cp\u003eThe reason I mention this is because one of the technologies we use at Radar is \u003ca href=\"https://nextjs.org/\"\u003eNext.js\u003c/a\u003e.  Next.js was something I was already trying to learn in my free time, but I've been able to gain a good amount of experience with it since I've started my new role, and my modern JavaScript fundamentals and understanding have grown drastically in the past several month (expect a lot more JavaScript posts going forward).\u003c/p\u003e\n\u003cp\u003eSeeing the power of Next.js and knowing I wanted my blog to be more flexible, I decided to recreate my blog from scratch using Next.js.\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003eNext.js\u003c/h2\u003e\n\u003cp\u003eA quick prelude on \u003ca href=\"https://nextjs.org/\"\u003eNext.js\u003c/a\u003e for those who have never used it.  \u003ca href=\"https://vercel.com/\"\u003eVercel\u003c/a\u003e, the creators of Next.js (and a company to keep üëÄ on) says it best, Next.js is...\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\"The \u003ca href=\"https://reactjs.org/\"\u003eReact\u003c/a\u003e Framework for Production\"\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eNext.js comes with a ton of great built-in features including:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eStatic + server-side rendering\u003c/li\u003e\n\u003cli\u003eSmart bundling and code-splitting, TypeScript support, Routing, Fast Refresh, CSS + Sass support all without complex configs\u003c/li\u003e\n\u003cli\u003eImage optimization\u003c/li\u003e\n\u003cli\u003eIntuitive code organization (because there are a million-plus ways to organize a React project)\u003c/li\u003e\n\u003cli\u003eStatic HTML exports (this one is important for our purposes)\u003c/li\u003e\n\u003cli\u003eSo much more...\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eIt's an awesome framework.\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eCoincidentally enough, the \u003ca href=\"https://nextjs.org/learn/basics/create-nextjs-app\"\u003eNext.js hands-on tutorial\u003c/a\u003e walks you through setting up a blog with Next.js. Following this tutorial will set you up with a great and simplistic starter blog (but not quite ready for deployment on GitHub pages, where this blog lives at the time of writing).\u003c/p\u003e\n\u003cp\u003eA few things this tutorial covers:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eCreating the Next.js app\u003c/li\u003e\n\u003cli\u003eBasics like in-app navigation, styling, adding images and more\u003c/li\u003e\n\u003cli\u003eSetting up metadata, blog pages, and pre-rendering\u003c/li\u003e\n\u003cli\u003eMarkdown ‚û°Ô∏è HTML\u003c/li\u003e\n\u003cli\u003eReworking your app to use dynamic routing\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThe tutorial is great so I won't cover anything that's already covered there.  If you're interested in using Next.js, you should definitely go through it.\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003eBeyond the basics\u003c/h2\u003e\n\u003cp\u003eAs mentioned, the \u003ca href=\"https://nextjs.org/learn/basics/create-nextjs-app\"\u003eNext.js tutorial\u003c/a\u003e is a great starting point, but I wanted to get my blog to a place where it was comparable to the previous iteration, along with the new features that encouraged me to take on this project in the first place.\u003c/p\u003e\n\u003cp\u003eTo keep things concise, we'll cover adding \u003ca href=\"/tags\"\u003etags\u003c/a\u003e, adding a custom domain from \u003ca href=\"https://domains.google/\"\u003eGoogle Domains\u003c/a\u003e to GitHub pages, and adding a GitHub action to automatically build and deploy our blog on each commit.\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003eTags\u003c/h2\u003e\n\u003cp\u003eOrganization within code and outside of code is always at the top of my priority list, so categorizing posts by tag was first on my blog todo list.\u003c/p\u003e\n\u003ch3\u003eAdding tags to each post\u003c/h3\u003e\n\u003cp\u003eFirst, let's add tags to each of our posts.  We can work off of the blog data section of the \u003ca href=\"https://nextjs.org/learn/basics/data-fetching/blog-data\"\u003eNext.js tutorial\u003c/a\u003e and add some additional YAML metadata to our markdown posts using \u003ca href=\"https://github.com/jonschlinkert/gray-matter\"\u003egray-matter\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eWithin the current metadata, add a list of tags relevant to the post:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e---\ntitle: 'Rebuilding my blog from scratch with Next.js'\ndate: '2022-04-23'\ntags: ['nextjs', 'react', 'javascript']\ndescription: 'Rebuilding my blog from a Gatsby.js templated site to a custom Next.js site from scratch.'\n---\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eI won't cover rendering of the tags below each posts in the post list, but the tags list should get picked up automatically with the \u003ccode\u003egetSortedPostsData()\u003c/code\u003e function that was already written and is called by \u003ccode\u003egetStaticProps()\u003c/code\u003e in order to pass props down the the post related components.\u003c/p\u003e\n\u003ch3\u003e/tags/[tag]\u003c/h3\u003e\n\u003cp\u003eWhat we've done so far will associate posts with a list of tags, but now we also want a page for each tag that lists out the associated posts.  For example, to view \u003ccode\u003epython\u003c/code\u003e related posts, we can go to \u003ca href=\"/tags/python\"\u003e/tags/python\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eWith Next.js, this can be done easily using \u003ca href=\"https://nextjs.org/docs/routing/dynamic-routes\"\u003edynamic routes\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eUnder the \u003ccode\u003epages/\u003c/code\u003e directory, create a \u003ccode\u003epages/tags/[tag].js\u003c/code\u003e file structure.  We'll be repeating similar patterns done within \u003ccode\u003epages/posts/[id].js\u003c/code\u003e.\u003c/p\u003e\n\u003cp\u003eLike earlier, we need to implement \u003ccode\u003egetStaticProps()\u003c/code\u003e (\u003ca href=\"https://nextjs.org/docs/basic-features/data-fetching/get-static-props\"\u003emore info here\u003c/a\u003e), so we can render these pages at build time.  We also need to implement \u003ccode\u003egetStaticPaths()\u003c/code\u003e (\u003ca href=\"https://nextjs.org/docs/basic-features/data-fetching/get-static-paths\"\u003emore info here\u003c/a\u003e) to get a list of all possible tags at build time.\u003c/p\u003e\n\u003cp\u003eLet's create a \u003ccode\u003elib/tags.js\u003c/code\u003e file to house some of the helper functions to implement \u003ccode\u003egetStaticProps()\u003c/code\u003e and \u003ccode\u003egetStaticPaths()\u003c/code\u003e.\u003c/p\u003e\n\u003cp\u003eFirst, we want to get a list of all the tags so we can write \u003ccode\u003egetStaticPaths()\u003c/code\u003e.  This will require processing all of the files within \u003ccode\u003eposts/\u003c/code\u003e, and processing the metadata using \u003ca href=\"https://github.com/jonschlinkert/gray-matter\"\u003egray-matter\u003c/a\u003e.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eimport fs from 'fs';\nimport path from 'path';\nimport matter from 'gray-matter';\n\nconst postsDirectory = path.join(process.cwd(), 'posts');\n\nexport const getAllTags = () =\u003e {\n  const fileNames = fs.readdirSync(postsDirectory);\n  const tags = new Set();\n\n  fileNames.map(fileName =\u003e {\n    // Read markdown file as string\n    const fullPath = path.join(postsDirectory, fileName);\n    const fileContents = fs.readFileSync(fullPath, 'utf8');\n\n    // Use gray-matter to parse the post metadata section\n    const matterResult = matter(fileContents);\n    if (matterResult?.data?.tags) {\n      matterResult.data.tags.forEach(\n        (tag) =\u003e tags.add(`/tags/${tag.replace(/\\s+/g, '-').toLowerCase()}`)\n      );\n    }\n  });\n\n  return Array.from(tags);\n};\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eNow we can call this within \u003ccode\u003epages/tags/[tag].js\u003c/code\u003e under \u003ccode\u003egetStaticPaths()\u003c/code\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eexport const getStaticPaths = () =\u003e {\n  const paths = getAllTags();\n  return {\n    paths,\n    fallback: false,\n  }\n};\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eNow, we can add another helper function \u003ccode\u003egetPostDataByTag()\u003c/code\u003e in \u003ccode\u003elib/tags.js\u003c/code\u003e to fulfill \u003ccode\u003egetStaticProps()\u003c/code\u003e.  This is basically what we already do with \u003ccode\u003epages/posts/[id].js\u003c/code\u003e, and it's not very efficient to do this twice, but all of this is happening at build time so it's not a huge deal for us.\u003c/p\u003e\n\u003cp\u003eFor this, we will use \u003ca href=\"https://github.com/remarkjs/remark\"\u003eremark\u003c/a\u003e to process our markdown files.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eimport fs from 'fs';\nimport path from 'path';\nimport matter from 'gray-matter';\nimport { remark } from 'remark';\nimport html from 'remark-html';\n\nconst postsDirectory = path.join(process.cwd(), 'posts');\n\nexport const getPostDataByTag = async (tag) =\u003e {\n  const fileNames = fs.readdirSync(postsDirectory);\n  const posts = [];\n\n  fileNames.map(async (fileName) =\u003e {\n    const id = fileName.replace(/\\.md$/, '');\n  \n    // Read markdown file as string\n    const fullPath = path.join(postsDirectory, fileName);\n    const fileContents = fs.readFileSync(fullPath, 'utf8');\n\n    // Use gray-matter to parse the post metadata section\n    const matterResult = matter(fileContents);\n\n    if (matterResult?.data?.tags \u0026#x26;\u0026#x26; matterResult.data.tags.includes(tag)) {\n      // Use remark to convert markdown into HTML string\n      const processedContent = await remark()\n        .use(html)\n        .process(matterResult.content);\n      const contentHtml = processedContent.toString();\n\n      // Combine the data with the id and contentHtml\n      posts.push({\n        id,\n        contentHtml,\n        markdown: matterResult.content,\n        ...matterResult.data,\n      });\n    }\n  });\n\n  return posts;\n};\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eWe can call this helper function in \u003ccode\u003epages/tags/[tag].js\u003c/code\u003e under \u003ccode\u003egetStaticProps()\u003c/code\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eexport const getStaticProps = async ({ params }) =\u003e {\n  const { tag } = params;\n  const taggedPosts = await getPostDataByTag(tag);\n  return {\n    props: {\n      tag,\n      taggedPosts,\n    },\n  };\n};\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eNow, you can render the associated tag pages as you wish, but I did it with a few components I had set up:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003econst TagPage = ({ tag, taggedPosts }) =\u003e {\n  const title = `Posts tagged \"${tag}\"`;\n  return (\n    \u0026#x3C;Layout tagPage title={title} description={title}\u003e \n      \u0026#x3C;header\u003e\n        \u0026#x3C;Tag tag={tag} isHeader/\u003e\n      \u0026#x3C;/header\u003e\n\n      \u0026#x3C;section\u003e\n        \u0026#x3C;PostList posts={taggedPosts} /\u003e\n      \u0026#x3C;/section\u003e\n    \u0026#x3C;/Layout\u003e\n  );\n};\n\nexport default TagPage;\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003eAll tags\u003c/h3\u003e\n\u003cp\u003eThe last thing we want to add is a page containing all of the tags in a list, and all of the posts organized into categories.\u003c/p\u003e\n\u003cp\u003eTo do this, we can add \u003ccode\u003epages/tags.js\u003c/code\u003e, which can be reached at \u003ca href=\"/tags\"\u003e/tags\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eOnce again, we want to implement \u003ccode\u003egetStaticProps()\u003c/code\u003e so we can pre-render this page at build time.  Luckily, we can reuse the two functions we wrote in \u003ccode\u003elib/tags.js\u003c/code\u003e to make this easy.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eimport { getAllTags, getPostDataByTag } from '../lib/tags';\n\nexport const getStaticProps = async () =\u003e {\n  const tagsWithPosts = {};\n  const allTags = getAllTags();\n\n  for (const tagPath of allTags) {\n    const tag = tagPath.replace('/tags/', '');\n    tagsWithPosts[tag] = await getPostDataByTag(tag);\n  }\n\n  return {\n    props: {\n      tagsWithPosts,\n    },\n  };\n};\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eNow, you can render this as you'd like using \u003ccode\u003etagsWithPosts\u003c/code\u003e as a prop in your page component.  I also like having a toggle to show/hide the associated posts.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003econst TagPage = ({ tagsWithPosts }) =\u003e {\n  const [showPosts, setShowPosts] = useState(false);\n\n  const tagAndPostList = Object.keys(tagsWithPosts).map((tag) =\u003e {\n    return (\n      \u0026#x3C;section key={tag}\u003e\n        \u0026#x3C;Tag tag={tag} isHeader useLink label={tagsWithPosts[tag].length} /\u003e\n        {showPosts \u0026#x26;\u0026#x26; \u0026#x3C;PostList posts={tagsWithPosts[tag]} withPadding /\u003e }\n      \u0026#x3C;/section\u003e\n    );\n  });\n\n  const title = 'All Tags';\n  return (\n    \u0026#x3C;Layout title={title} description={title}\u003e\n      \u0026#x3C;header\u003e\n        \u0026#x3C;h1\u003eAll tags\u0026#x3C;/h1\u003e\n        \u0026#x3C;div\u003e\n          \u0026#x3C;Checkbox label={'Show posts'} value={showPosts} onChange={(x) =\u003e setShowPosts(!showPosts)} /\u003e\n        \u0026#x3C;/div\u003e\n      \u0026#x3C;/header\u003e\n\n      {tagAndPostList}\n\n    \u0026#x3C;/Layout\u003e\n  );\n};\n\nexport default TagPage;\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eNow we have a page with all of our tags üôå.\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003eAdding a custom domain\u003c/h2\u003e\n\u003cp\u003eNext on my todo list was adding a custom domain to transition from bschoeneweis.github.io ‚û°Ô∏è bradleyschoeneweis.com.  GitHub gives a good overview of the steps \u003ca href=\"https://docs.github.com/en/pages/configuring-a-custom-domain-for-your-github-pages-site/managing-a-custom-domain-for-your-github-pages-site#configuring-an-apex-domain\"\u003ehere\u003c/a\u003e, but we'll go through it below specifically using \u003ca href=\"https://domains.google/\"\u003eGoogle domains\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eWe'll be using an apex domain (e.g. bradleyschoeneweis.com).\u003c/p\u003e\n\u003ch3\u003eGitHub changes\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003eGo to the repository settings for your GitHub pages repository\u003c/li\u003e\n\u003cli\u003eClick into the \u003cstrong\u003ePages\u003c/strong\u003e section\u003c/li\u003e\n\u003cli\u003eType your apex domain into the \u003cstrong\u003eCustom domain\u003c/strong\u003e input and click \u003cstrong\u003eSave\u003c/strong\u003e\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3\u003eGoogle domains changes\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003eGo to your \u003ca href=\"https://domains.google.com/registrar/\"\u003eGoogle domains registrar\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003eClick \u003cstrong\u003eManage\u003c/strong\u003e on the domain you'd like to use\u003c/li\u003e\n\u003cli\u003eNavigate to the \u003cstrong\u003eDNS\u003c/strong\u003e settings and under \u003cstrong\u003eResource records\u003c/strong\u003e, click \u003cstrong\u003eManage custom records\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003eRefer to the \u003ca href=\"https://docs.github.com/en/pages/configuring-a-custom-domain-for-your-github-pages-site/managing-a-custom-domain-for-your-github-pages-site#configuring-an-apex-domain\"\u003eGitHub documentation\u003c/a\u003e for the official IP address list, but add the following \u003ccode\u003eA\u003c/code\u003e and \u003ccode\u003eCNAME\u003c/code\u003e records\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\u003cimg src=\"/images/rebuilding-my-blog/dns-records.jpg\" alt=\"DNS records\"\u003e\u003c/p\u003e\n\u003ch3\u003eFinal steps and confirmation\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003eHead back to the \u003cstrong\u003ePages\u003c/strong\u003e settings for your repository and check \u003cstrong\u003eEnforce HTTPS\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003eAfter a bit of time has passed, run \u003ccode\u003edig www.mynewdomain.com +nostats +nocomments +nocmd\u003c/code\u003e replace with your domain name and your output should look similar to the following:\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\u003cimg src=\"/images/rebuilding-my-blog/dig-output.jpg\" alt=\"dig output\"\u003e\u003c/p\u003e\n\u003cp\u003eNow your custom domain should be all set up with your GitHub pages blog! üéâ\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003eSimple automated deployment\u003c/h2\u003e\n\u003cp\u003eFor the final touches, I didn't want to have to worry about building the blog locally each time, so we'll create a simple GitHub action to build and serve our blog on each commit.\u003c/p\u003e\n\u003ch3\u003eThe \u003ccode\u003epackage.json\u003c/code\u003e scripts\u003c/h3\u003e\n\u003cp\u003eIf you don't have one already, you should create a \u003ccode\u003ebuild\u003c/code\u003e script in \u003ccode\u003epackage.json\u003c/code\u003e as \u003ccode\u003ebuild: \"next build\"\u003c/code\u003e.\u003c/p\u003e\n\u003cp\u003eI won't cover it here, but you'll also need to go through tutorials related to \u003ca href=\"https://nextjs.org/docs/advanced-features/static-html-export\"\u003eexporting your Next.js project as static HTML\u003c/a\u003e.  There are a few gotchas here.  For example, you cannot use the Next.js image optimization or API routes.  You can see the full list of \u003ca href=\"https://nextjs.org/docs/advanced-features/static-html-export#unsupported-features\"\u003eunsupported features\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eLong story short, within your \u003ccode\u003epackage.json\u003c/code\u003e file, you should add an \u003ccode\u003eexport: \"next export\"\u003c/code\u003e script.  This will create an \u003ccode\u003eout/\u003c/code\u003e directory with HTML files when this command is run.  You probably want to add this directory to your \u003ccode\u003e.gitignore\u003c/code\u003e file.\u003c/p\u003e\n\u003ch3\u003eDeploy key\u003c/h3\u003e\n\u003cp\u003eWe will be using \u003ca href=\"https://github.com/peaceiris/actions-gh-pages\"\u003epeaceiris/actions-gh-pages@v3\u003c/a\u003e for making the deployment step easy.  As a part of this, we want to set up an SSH deploy key for safety.\u003c/p\u003e\n\u003cp\u003eYou can use an SSH key that you already have setup, or create a new one with:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003essh-keygen -t rsa -b 4096 -C \"$(git config user.email)\" -f gh-pages -N \"\"\n\u003c/code\u003e\u003c/pre\u003e\n\u003col\u003e\n\u003cli\u003eNavigate back to your repository settings, and under security, go to \u003cstrong\u003eDeploy keys\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003eClick \u003cstrong\u003eAdd a deploy key\u003c/strong\u003e and enter \u003ccode\u003eACTIONS_DEPLOY_KEY\u003c/code\u003e as the title\u003c/li\u003e\n\u003cli\u003ePaste in your public RSA key (ends with \u003ccode\u003e.pub\u003c/code\u003e)\u003c/li\u003e\n\u003cli\u003eCheck \u003cstrong\u003eAllow write access\u003c/strong\u003e and then click \u003cstrong\u003eAdd key\u003c/strong\u003e\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3\u003e\u003ccode\u003edeploy.yml\u003c/code\u003e\u003c/h3\u003e\n\u003cp\u003eNow that every thing is set up, we can put this all into a GitHub actions file.\u003c/p\u003e\n\u003cp\u003eFrom the root of the project, create \u003ccode\u003e.github/workflows/deploy.yml\u003c/code\u003e and refer to the following:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ename: Deploy to Github Pages\n\non:\n  push:\n    branches:\n      - develop\n\njobs:\n  deployment:\n    runs-on: ubuntu-latest\n\n    strategy:\n      matrix:\n        node-version: [14.x]\n\n    steps:\n      - uses: actions/checkout@v2\n\n      - name: Use Node.js ${{ matrix.node-version }}\n        uses: actions/setup-node@v2\n        with:\n          node-version: ${{ matrix.node-version }}\n\n      - name: Update NPM\n        run: npm i -g npm@latest\n\n      - name: Cache dependencies\n        uses: actions/cache@v2\n        with:\n          path: ~/.npm\n          key: ${{ runner.OS }}-node-${{ hashFiles('**/package-lock.json') }}\n          restore-keys: |\n            ${{ runner.OS }}-node-\n            ${{ runner.OS }}-\n\n      - name: Build\n        run: |\n          npm i --legacy-peer-deps\n          npm run build\n          npm run export\n\n      - name: Deploy\n        uses: peaceiris/actions-gh-pages@v3\n        with:\n          deploy_key: ${{ secrets.ACTIONS_DEPLOY_KEY }}\n          publish_dir: ./out\n          cname: yoururl.com\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eA few things to note:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eThe branch I actively work on is \u003ccode\u003edevelop\u003c/code\u003e, so you'll want to update that to the branch you push to\u003c/li\u003e\n\u003cli\u003eIf you didn't name your deploy key \u003ccode\u003eACTIONS_DEPLOY_KEY\u003c/code\u003e, change the \u003ccode\u003edeploy_key\u003c/code\u003e value to \u003ccode\u003esecrets.[Your key name]\u003c/code\u003e in the \u003cstrong\u003eDeploy\u003c/strong\u003e step\u003c/li\u003e\n\u003cli\u003eThe \u003ccode\u003ecname\u003c/code\u003e value in the \u003cstrong\u003eDeploy\u003c/strong\u003e step should be replaced with your newly configured custom domain\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eNow, each time you commit and push up you blog changes, your blog should automatically be built and served under your custom domain.\u003c/p\u003e\n\u003cp\u003eJust like that, your blog is just as functional as a cookiecutter template üç™ and more easy to build upon than ever before.\u003c/p\u003e\n\u003chr\u003e\n","markdown":"\n## Version `0.1.x`\n\nThe first iteration of my blog was built using a pre-configured [GatsbyJS](https://www.gatsbyjs.com/) site template.  I chose a template ([Novela by Narative](https://novela.narative.co/)) that checked all my boxes for an easy tool to start sharing my writing.\n\n- The theme was modern and sleek\n- Everything was mobile-friendly\n- Lots of plug-and-play options and prebuilt components that flowed together\n  - Article metadata that connects to an author bio page\n  - Reading time estimates and progress bars\n  - Easy image optimizations\n  - A config for a Google Analytics tag\n- Deployment was straightforward with GitHub pages\n  \nBut most importantly, all I had to do was add Markdown pages to a directory to get started.  At the time, I didn't really know much about GatsbyJS, other than it being a popular static site generator, and my modern JavaScript knowledge was introductory at-best (albeit growing each and every day).  So this seemed like the perfect route forward.\n\n## The problem\n\nAs I started writing more and more posts, I began noting different features I wanted to include on my site.  These weren't terribly complex additions, but rather simple things like adding tags to group common posts or wanting to change the styling of the inline code snippets.\n\nI soon discovered that trying to color outside the lines when using a cookiecutter template can get very complex, very quickly.\n\nI found myself digging into nested modules in my `node_modules` folder where I would need to overload different functions and components to get what I wanted.  It was added complexity than I didn't foresee when I signed up to use a template.  Plus, this site could eventually house more than just a blog, and the template I chose wasn't designed to accommodate much else.\n\n## What now?\n\nIf you haven't noticed from the timestamp on my last article, I haven't written a post in ~9 months.  This is largely because I was interviewing for new positions and eventually joined the team at [Radar](https://radar.com) as a Product Engineer!  Preparation for interviews and taking a break after accepting this new position occupied much of the time I would normally spend writing.  Plus, taking a break from coding outside of work is a good way to avoid burnout ü§∑‚Äç‚ôÇÔ∏è.\n\nThe reason I mention this is because one of the technologies we use at Radar is [Next.js](https://nextjs.org/).  Next.js was something I was already trying to learn in my free time, but I've been able to gain a good amount of experience with it since I've started my new role, and my modern JavaScript fundamentals and understanding have grown drastically in the past several month (expect a lot more JavaScript posts going forward).\n\nSeeing the power of Next.js and knowing I wanted my blog to be more flexible, I decided to recreate my blog from scratch using Next.js.\n\n---\n\n## Next.js\n\nA quick prelude on [Next.js](https://nextjs.org/) for those who have never used it.  [Vercel](https://vercel.com/), the creators of Next.js (and a company to keep üëÄ on) says it best, Next.js is...\n\n\u003e \"The [React](https://reactjs.org/) Framework for Production\"\n\nNext.js comes with a ton of great built-in features including:\n- Static + server-side rendering\n- Smart bundling and code-splitting, TypeScript support, Routing, Fast Refresh, CSS + Sass support all without complex configs\n- Image optimization\n- Intuitive code organization (because there are a million-plus ways to organize a React project)\n- Static HTML exports (this one is important for our purposes)\n- So much more...\n\n**It's an awesome framework.**\n\nCoincidentally enough, the [Next.js hands-on tutorial](https://nextjs.org/learn/basics/create-nextjs-app) walks you through setting up a blog with Next.js. Following this tutorial will set you up with a great and simplistic starter blog (but not quite ready for deployment on GitHub pages, where this blog lives at the time of writing).\n\nA few things this tutorial covers:\n- Creating the Next.js app\n- Basics like in-app navigation, styling, adding images and more\n- Setting up metadata, blog pages, and pre-rendering\n- Markdown ‚û°Ô∏è HTML\n- Reworking your app to use dynamic routing\n\nThe tutorial is great so I won't cover anything that's already covered there.  If you're interested in using Next.js, you should definitely go through it.\n\n---\n\n## Beyond the basics\n\nAs mentioned, the [Next.js tutorial](https://nextjs.org/learn/basics/create-nextjs-app) is a great starting point, but I wanted to get my blog to a place where it was comparable to the previous iteration, along with the new features that encouraged me to take on this project in the first place.\n\nTo keep things concise, we'll cover adding [tags](/tags), adding a custom domain from [Google Domains](https://domains.google/) to GitHub pages, and adding a GitHub action to automatically build and deploy our blog on each commit.\n\n---\n\n## Tags\nOrganization within code and outside of code is always at the top of my priority list, so categorizing posts by tag was first on my blog todo list.\n\n### Adding tags to each post\n\nFirst, let's add tags to each of our posts.  We can work off of the blog data section of the [Next.js tutorial](https://nextjs.org/learn/basics/data-fetching/blog-data) and add some additional YAML metadata to our markdown posts using [gray-matter](https://github.com/jonschlinkert/gray-matter).\n\nWithin the current metadata, add a list of tags relevant to the post:\n\n```yaml\n---\ntitle: 'Rebuilding my blog from scratch with Next.js'\ndate: '2022-04-23'\ntags: ['nextjs', 'react', 'javascript']\ndescription: 'Rebuilding my blog from a Gatsby.js templated site to a custom Next.js site from scratch.'\n---\n```\n\nI won't cover rendering of the tags below each posts in the post list, but the tags list should get picked up automatically with the `getSortedPostsData()` function that was already written and is called by `getStaticProps()` in order to pass props down the the post related components.\n\n### /tags/[tag]\n\nWhat we've done so far will associate posts with a list of tags, but now we also want a page for each tag that lists out the associated posts.  For example, to view `python` related posts, we can go to [/tags/python](/tags/python).\n\nWith Next.js, this can be done easily using [dynamic routes](https://nextjs.org/docs/routing/dynamic-routes).\n\nUnder the `pages/` directory, create a `pages/tags/[tag].js` file structure.  We'll be repeating similar patterns done within `pages/posts/[id].js`.\n\nLike earlier, we need to implement `getStaticProps()` ([more info here](https://nextjs.org/docs/basic-features/data-fetching/get-static-props)), so we can render these pages at build time.  We also need to implement `getStaticPaths()` ([more info here](https://nextjs.org/docs/basic-features/data-fetching/get-static-paths)) to get a list of all possible tags at build time.\n\nLet's create a `lib/tags.js` file to house some of the helper functions to implement `getStaticProps()` and `getStaticPaths()`.\n\nFirst, we want to get a list of all the tags so we can write `getStaticPaths()`.  This will require processing all of the files within `posts/`, and processing the metadata using [gray-matter](https://github.com/jonschlinkert/gray-matter).\n\n```js\nimport fs from 'fs';\nimport path from 'path';\nimport matter from 'gray-matter';\n\nconst postsDirectory = path.join(process.cwd(), 'posts');\n\nexport const getAllTags = () =\u003e {\n  const fileNames = fs.readdirSync(postsDirectory);\n  const tags = new Set();\n\n  fileNames.map(fileName =\u003e {\n    // Read markdown file as string\n    const fullPath = path.join(postsDirectory, fileName);\n    const fileContents = fs.readFileSync(fullPath, 'utf8');\n\n    // Use gray-matter to parse the post metadata section\n    const matterResult = matter(fileContents);\n    if (matterResult?.data?.tags) {\n      matterResult.data.tags.forEach(\n        (tag) =\u003e tags.add(`/tags/${tag.replace(/\\s+/g, '-').toLowerCase()}`)\n      );\n    }\n  });\n\n  return Array.from(tags);\n};\n```\n\nNow we can call this within `pages/tags/[tag].js` under `getStaticPaths()`\n\n```js\nexport const getStaticPaths = () =\u003e {\n  const paths = getAllTags();\n  return {\n    paths,\n    fallback: false,\n  }\n};\n```\n\nNow, we can add another helper function `getPostDataByTag()` in `lib/tags.js` to fulfill `getStaticProps()`.  This is basically what we already do with `pages/posts/[id].js`, and it's not very efficient to do this twice, but all of this is happening at build time so it's not a huge deal for us.\n\nFor this, we will use [remark](https://github.com/remarkjs/remark) to process our markdown files.\n\n```js\nimport fs from 'fs';\nimport path from 'path';\nimport matter from 'gray-matter';\nimport { remark } from 'remark';\nimport html from 'remark-html';\n\nconst postsDirectory = path.join(process.cwd(), 'posts');\n\nexport const getPostDataByTag = async (tag) =\u003e {\n  const fileNames = fs.readdirSync(postsDirectory);\n  const posts = [];\n\n  fileNames.map(async (fileName) =\u003e {\n    const id = fileName.replace(/\\.md$/, '');\n  \n    // Read markdown file as string\n    const fullPath = path.join(postsDirectory, fileName);\n    const fileContents = fs.readFileSync(fullPath, 'utf8');\n\n    // Use gray-matter to parse the post metadata section\n    const matterResult = matter(fileContents);\n\n    if (matterResult?.data?.tags \u0026\u0026 matterResult.data.tags.includes(tag)) {\n      // Use remark to convert markdown into HTML string\n      const processedContent = await remark()\n        .use(html)\n        .process(matterResult.content);\n      const contentHtml = processedContent.toString();\n\n      // Combine the data with the id and contentHtml\n      posts.push({\n        id,\n        contentHtml,\n        markdown: matterResult.content,\n        ...matterResult.data,\n      });\n    }\n  });\n\n  return posts;\n};\n```\n\nWe can call this helper function in `pages/tags/[tag].js` under `getStaticProps()`\n\n```js\nexport const getStaticProps = async ({ params }) =\u003e {\n  const { tag } = params;\n  const taggedPosts = await getPostDataByTag(tag);\n  return {\n    props: {\n      tag,\n      taggedPosts,\n    },\n  };\n};\n```\n\nNow, you can render the associated tag pages as you wish, but I did it with a few components I had set up:\n\n```jsx\nconst TagPage = ({ tag, taggedPosts }) =\u003e {\n  const title = `Posts tagged \"${tag}\"`;\n  return (\n    \u003cLayout tagPage title={title} description={title}\u003e \n      \u003cheader\u003e\n        \u003cTag tag={tag} isHeader/\u003e\n      \u003c/header\u003e\n\n      \u003csection\u003e\n        \u003cPostList posts={taggedPosts} /\u003e\n      \u003c/section\u003e\n    \u003c/Layout\u003e\n  );\n};\n\nexport default TagPage;\n```\n\n### All tags\nThe last thing we want to add is a page containing all of the tags in a list, and all of the posts organized into categories.\n\nTo do this, we can add `pages/tags.js`, which can be reached at [/tags](/tags).\n\nOnce again, we want to implement `getStaticProps()` so we can pre-render this page at build time.  Luckily, we can reuse the two functions we wrote in `lib/tags.js` to make this easy.\n\n```js\nimport { getAllTags, getPostDataByTag } from '../lib/tags';\n\nexport const getStaticProps = async () =\u003e {\n  const tagsWithPosts = {};\n  const allTags = getAllTags();\n\n  for (const tagPath of allTags) {\n    const tag = tagPath.replace('/tags/', '');\n    tagsWithPosts[tag] = await getPostDataByTag(tag);\n  }\n\n  return {\n    props: {\n      tagsWithPosts,\n    },\n  };\n};\n```\n\nNow, you can render this as you'd like using `tagsWithPosts` as a prop in your page component.  I also like having a toggle to show/hide the associated posts.\n\n```jsx\nconst TagPage = ({ tagsWithPosts }) =\u003e {\n  const [showPosts, setShowPosts] = useState(false);\n\n  const tagAndPostList = Object.keys(tagsWithPosts).map((tag) =\u003e {\n    return (\n      \u003csection key={tag}\u003e\n        \u003cTag tag={tag} isHeader useLink label={tagsWithPosts[tag].length} /\u003e\n        {showPosts \u0026\u0026 \u003cPostList posts={tagsWithPosts[tag]} withPadding /\u003e }\n      \u003c/section\u003e\n    );\n  });\n\n  const title = 'All Tags';\n  return (\n    \u003cLayout title={title} description={title}\u003e\n      \u003cheader\u003e\n        \u003ch1\u003eAll tags\u003c/h1\u003e\n        \u003cdiv\u003e\n          \u003cCheckbox label={'Show posts'} value={showPosts} onChange={(x) =\u003e setShowPosts(!showPosts)} /\u003e\n        \u003c/div\u003e\n      \u003c/header\u003e\n\n      {tagAndPostList}\n\n    \u003c/Layout\u003e\n  );\n};\n\nexport default TagPage;\n```\n\nNow we have a page with all of our tags üôå.\n\n---\n\n## Adding a custom domain\nNext on my todo list was adding a custom domain to transition from bschoeneweis.github.io ‚û°Ô∏è bradleyschoeneweis.com.  GitHub gives a good overview of the steps [here](https://docs.github.com/en/pages/configuring-a-custom-domain-for-your-github-pages-site/managing-a-custom-domain-for-your-github-pages-site#configuring-an-apex-domain), but we'll go through it below specifically using [Google domains](https://domains.google/).\n\nWe'll be using an apex domain (e.g. bradleyschoeneweis.com).\n\n### GitHub changes\n1. Go to the repository settings for your GitHub pages repository\n2. Click into the **Pages** section\n3. Type your apex domain into the **Custom domain** input and click **Save**\n\n### Google domains changes\n1. Go to your [Google domains registrar](https://domains.google.com/registrar/)\n2. Click **Manage** on the domain you'd like to use\n3. Navigate to the **DNS** settings and under **Resource records**, click **Manage custom records**\n4. Refer to the [GitHub documentation](https://docs.github.com/en/pages/configuring-a-custom-domain-for-your-github-pages-site/managing-a-custom-domain-for-your-github-pages-site#configuring-an-apex-domain) for the official IP address list, but add the following `A` and `CNAME` records\n\n![DNS records](/images/rebuilding-my-blog/dns-records.jpg)\n\n### Final steps and confirmation\n1. Head back to the **Pages** settings for your repository and check **Enforce HTTPS**\n2. After a bit of time has passed, run `dig www.mynewdomain.com +nostats +nocomments +nocmd` replace with your domain name and your output should look similar to the following:\n\n![dig output](/images/rebuilding-my-blog/dig-output.jpg)\n\nNow your custom domain should be all set up with your GitHub pages blog! üéâ\n\n---\n\n## Simple automated deployment\nFor the final touches, I didn't want to have to worry about building the blog locally each time, so we'll create a simple GitHub action to build and serve our blog on each commit.\n\n### The `package.json` scripts\nIf you don't have one already, you should create a `build` script in `package.json` as `build: \"next build\"`.\n\nI won't cover it here, but you'll also need to go through tutorials related to [exporting your Next.js project as static HTML](https://nextjs.org/docs/advanced-features/static-html-export).  There are a few gotchas here.  For example, you cannot use the Next.js image optimization or API routes.  You can see the full list of [unsupported features](https://nextjs.org/docs/advanced-features/static-html-export#unsupported-features).\n\nLong story short, within your `package.json` file, you should add an `export: \"next export\"` script.  This will create an `out/` directory with HTML files when this command is run.  You probably want to add this directory to your `.gitignore` file.\n\n### Deploy key\nWe will be using [peaceiris/actions-gh-pages@v3](https://github.com/peaceiris/actions-gh-pages) for making the deployment step easy.  As a part of this, we want to set up an SSH deploy key for safety.\n\nYou can use an SSH key that you already have setup, or create a new one with:\n\n```bash\nssh-keygen -t rsa -b 4096 -C \"$(git config user.email)\" -f gh-pages -N \"\"\n```\n\n1. Navigate back to your repository settings, and under security, go to **Deploy keys**\n2. Click **Add a deploy key** and enter `ACTIONS_DEPLOY_KEY` as the title\n3. Paste in your public RSA key (ends with `.pub`)\n4. Check **Allow write access** and then click **Add key**\n\n### `deploy.yml`\nNow that every thing is set up, we can put this all into a GitHub actions file.\n\nFrom the root of the project, create `.github/workflows/deploy.yml` and refer to the following:\n\n```yml\nname: Deploy to Github Pages\n\non:\n  push:\n    branches:\n      - develop\n\njobs:\n  deployment:\n    runs-on: ubuntu-latest\n\n    strategy:\n      matrix:\n        node-version: [14.x]\n\n    steps:\n      - uses: actions/checkout@v2\n\n      - name: Use Node.js ${{ matrix.node-version }}\n        uses: actions/setup-node@v2\n        with:\n          node-version: ${{ matrix.node-version }}\n\n      - name: Update NPM\n        run: npm i -g npm@latest\n\n      - name: Cache dependencies\n        uses: actions/cache@v2\n        with:\n          path: ~/.npm\n          key: ${{ runner.OS }}-node-${{ hashFiles('**/package-lock.json') }}\n          restore-keys: |\n            ${{ runner.OS }}-node-\n            ${{ runner.OS }}-\n\n      - name: Build\n        run: |\n          npm i --legacy-peer-deps\n          npm run build\n          npm run export\n\n      - name: Deploy\n        uses: peaceiris/actions-gh-pages@v3\n        with:\n          deploy_key: ${{ secrets.ACTIONS_DEPLOY_KEY }}\n          publish_dir: ./out\n          cname: yoururl.com\n```\n\nA few things to note:\n- The branch I actively work on is `develop`, so you'll want to update that to the branch you push to\n- If you didn't name your deploy key `ACTIONS_DEPLOY_KEY`, change the `deploy_key` value to `secrets.[Your key name]` in the **Deploy** step\n- The `cname` value in the **Deploy** step should be replaced with your newly configured custom domain\n\nNow, each time you commit and push up you blog changes, your blog should automatically be built and served under your custom domain.\n\nJust like that, your blog is just as functional as a cookiecutter template üç™ and more easy to build upon than ever before.\n\n---\n","title":"Rebuilding my blog from scratch with Next.js","date":"2022-04-23","tags":["nextjs","react","javascript"],"description":"Rebuilding my blog from a Gatsby.js templated site to a custom Next.js site from scratch."}],"slack":[{"id":"slack-webhook","contentHtml":"\u003ch2\u003etl;dr\u003c/h2\u003e\n\u003ch3\u003eGoal\u003c/h3\u003e\n\u003cp\u003e\u003cem\u003eTo set up a Slack webhook so we can send text and simple HTML notifications to receive in a Slack channel.\u003c/em\u003e\u003c/p\u003e\n\u003ch3\u003eProcess Overview\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003eSetting up a Slack webhook URL in your Slack workspace to post to a channel\u003c/li\u003e\n\u003cli\u003ePosting a notification to our webhook\u003c/li\u003e\n\u003cli\u003eCreating a simple HTML parser to match the custom Slack markdown flavor\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3\u003ePython Dependencies\u003c/h3\u003e\n\u003cpre\u003e\u003ccode\u003e# Python standard library\nfrom html.parser import HTMLParser\nimport logging\nimport os\nimport re\nfrom typing import Any, List, Tuple\n\n# 3rd Party\nimport requests\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003eAssumptions\u003c/h3\u003e\n\u003cp\u003eI'll assume you have a Slack account, a Slack workspace setup, Slack is installed, and you have knowledge of Python with a basic understanding of webhooks.\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003eIf you haven't heard of it before, \u003ca href=\"https://slack.com/\"\u003eSlack\u003c/a\u003e is a very popular team/workplace communication tool.  In addition to direct messaging, it allows you to separate discussion into various topics or \u003cstrong\u003echannels\u003c/strong\u003e for more focused team communication.\u003c/p\u003e\n\u003cp\u003eAnother great feature of Slack is that you can add 3rd party \u003ca href=\"https://slack.com/apps\"\u003eapps\u003c/a\u003e (or integrations) from your existing stack, or even develop your own!  I have seen this streamline my own productivity, and I personally use a number of Slack apps.\u003c/p\u003e\n\u003cp\u003eTo name a few, you may want to check out the following (assuming you use these tools) which I've found a lot of value in:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://slack.com/apps/A011MFBJEUU-sentry?tab=more_info\"\u003eSentry\u003c/a\u003e - for application monitoring\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://slack.com/apps/ADZ494LHY-google-calendar?tab=more_info\"\u003eGoogle Calendar\u003c/a\u003e - to stay on top of my meetings schedule\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://slack.com/apps/A01BP7R4KNY-github?tab=more_info\"\u003eGitHub\u003c/a\u003e - getting notified of pull requests and meaningful changes to important repositories\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://slack.com/apps/A2RPP3NFR-jira-cloud?tab=more_info\"\u003eJira Cloud\u003c/a\u003e - staying on top of changes to Jira tickets\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://slack.com/apps/A6L22LZNH-aws-chatbot?tab=more_info\"\u003eAWS Chatbot\u003c/a\u003e - alerts from CloudWatch alarms\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eYou can browse the \u003ca href=\"https://slack.com/apps\"\u003eSlack app directory\u003c/a\u003e for more integrations.\u003c/p\u003e\n\u003cp\u003eHowever, not every integration is going to provide the functionality you need.  This post will focus on creating our own custom Slack app with the goal of posting simple notifications to a Slack channel.\u003c/p\u003e\n\u003cp\u003eA common use case where we can apply our app will be sending notifications when any sort of user activity happens on a platform.  As a developer, being notified of when a user completes a certain task can provide a lot of transparency and understanding into the usage of our application, while also keeping a sales teams informed on relevant activity on the platform.  This is the use case we'll focus on.\u003c/p\u003e\n\u003cp\u003eWe will do this by posting to a webhook hosted by Slack.  For more information on webhooks, you can check out \u003ca href=\"https://zapier.com/blog/what-are-webhooks/\"\u003ethis article\u003c/a\u003e by Zapier.\u003c/p\u003e\n\u003cp\u003eLet's get started!\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003eSetting up the Slack App\u003c/h2\u003e\n\u003cp\u003eOpen Slack, click \u003cstrong\u003eAdd channels\u003c/strong\u003e, and create a new channel called \u003ccode\u003enotifications\u003c/code\u003e.  This is where our Slack app will post to once we set it up.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/slack-webhook/create-channel.jpg\" alt=\"Create a Slack channel {priority}{1004x580}\"\u003e\u003c/p\u003e\n\u003cp\u003eNow go to a web browser and head to https://api.slack.com/apps/.\u003c/p\u003e\n\u003cp\u003eClick on \u003cstrong\u003eCreate an App\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/slack-webhook/create-app.jpg\" alt=\"Create a Slack App {1004x497}\"\u003e\u003c/p\u003e\n\u003cp\u003eSelect \u003cstrong\u003eFrom scratch\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/slack-webhook/from-scratch.jpg\" alt=\"Select From Scratch {1004x497}\"\u003e\u003c/p\u003e\n\u003cp\u003eCreate a name for your app and select the workspace you just created your \u003ccode\u003enotifications\u003c/code\u003e channel in.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/slack-webhook/app-and-workspace.jpg\" alt=\"Choose an app name and workspace {1004x501}\"\u003e\u003c/p\u003e\n\u003cp\u003eThis will redirect you to the \u003cstrong\u003eBasic Information\u003c/strong\u003e tab for your app.  Here, we'll enable \u003cstrong\u003eIncoming Webhooks\u003c/strong\u003e.  As it states, this will enable us to post messages from an external source.  In this case, our platform.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/slack-webhook/add-webhooks.jpg\" alt=\"Enable incoming webhooks {1004x497}\"\u003e\u003c/p\u003e\n\u003cp\u003eTurn on \u003cstrong\u003eActivate Incoming Webhooks\u003c/strong\u003e and you will see additional details appear.  Towards the bottom, click on \u003cstrong\u003eAdd New Webhook to Workspace\u003c/strong\u003e.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/slack-webhook/add-new-webhook.jpg\" alt=\"Add a new webhook to your workspace {1004x485}\"\u003e\u003c/p\u003e\n\u003cp\u003eYou will be redirected again to select which channel to post to.  Select the \u003ccode\u003enotifications\u003c/code\u003e channel that we previously created and press \u003cstrong\u003eAllow\u003c/strong\u003e.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/slack-webhook/choose-channel.jpg\" alt=\"Select a channel for your app {1004x498}\"\u003e\u003c/p\u003e\n\u003cp\u003eThis will redirect you back to your app configuration and you will see a webhook URL you can now post to.  This will also include a simple curl POST request you can test with if you'd like.  Copy the webhook URL for later, and remember to \u003cstrong\u003ekeep it private\u003c/strong\u003e.  This is a public URL that anyone can post to.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/slack-webhook/copy-url.jpg\" alt=\"Copy your webhook URL {680x506}\"\u003e\u003c/p\u003e\n\u003cp\u003eYou can return to the \u003cstrong\u003eBasic Information\u003c/strong\u003e of your app settings in Slack to view more API credentials and also edit the look and feel of your new Slack bot.\u003c/p\u003e\n\u003cp\u003eNow we're ready to dive into the code to communicate with our webhook!\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003eCommunicating with our Webhook\u003c/h2\u003e\n\u003cp\u003eTo communicate with our webhook, we'll use the \u003ca href=\"https://docs.python-requests.org/en/master/\"\u003e\u003ccode\u003erequests\u003c/code\u003e\u003c/a\u003e Python library.  This is a third party library, so you'll want to have a Python virtual environment set up to handle your dependencies.  Virtual environments are out of the scope of this article, but you can read more on them \u003ca href=\"https://docs.python.org/3/tutorial/venv.html\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eInside your virtual environment, you can run the following to install the library.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003epip install requests\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eNow, we'll set up a class to communicate with our Slack endpoint.  We'll start by just sending a plain text message to Slack.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eimport logging\n\nimport requests\n\n\nlogger = logging.getLogger()\nlogger.setLevel(logging.INFO)\n\n\nclass SlackWebhookBot:\n    def __init__(self, webhook_url: str, timeout: int = 15):\n        \"\"\"Class to send messages to a provided Slack webhook URL.\n\n        You can read more about Slack's Incoming Webhooks here:\n            https://api.slack.com/messaging/webhooks\n        \n        Args:\n            webhook_url: The webhook URL to send a message to.  Typically\n                formatted like \"https://hooks.slack.com/services/...\".\n        \n        Kwargs:\n            timeout: Number of seconds before the request will timeout.\n                This is used to prevent a hang and is set to a default\n                value of 15 seconds.\n        \"\"\"\n        self.webhook_url = webhook_url\n        self.timeout = timeout\n        self.headers = {\n            'Content-Type': 'application/json',\n        }\n    \n\n    def send(self, message: str) -\u003e bool:\n        \"\"\"Sends a message to the webhook URL.\n\n        Per the Slack Incoming Webhook example.  The body of the request\n        (for plain text) should be formatted as follows:\n            `{\"text\": \"Hello, World!\"}`\n\n        Args:\n            message: Plain text string to send to Slack.\n\n        Returns:\n            A boolean representing if the request was successful.\n        \"\"\"\n        success = False\n        payload = {\n            'text': message,\n        }\n        try:\n            r = requests.post(\n                self.webhook_url,\n                headers=self.headers,\n                json=payload,\n                timeout=self.timeout\n            )\n        except requests.Timeout:\n            logger.error('Timeout occurred when trying to send message to Slack.')\n        except requests.RequestException as e:\n            logger.error(f'Error occurred when communicating with Slack: {e}.')\n        else:\n            success = True\n            logger.info('Successfully sent message to Slack.')\n\n        return success\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eAbove is the basic setup for communicating with the Slack webhook.  We can run a quick test by moving this code to a script and adding the following.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eimport os\n\nwebhook_url = os.environ.get('SLACK_WEBHOOK_URL')\nslack = SlackWebhookBot(webhook_url)\nslack.send('Hello, world!')\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eMake sure to set your Slack webhook URL to the \u003ccode\u003eSLACK_WEBHOOK_URL\u003c/code\u003e environment variable, and make sure you're in your virtual environment with the \u003ccode\u003erequests\u003c/code\u003e package installed before running the script.  This can be done on MacOS with the following.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eexport SLACK_WEBHOOK_URL=https://hooks.slack.com/services/...\npython slack_webhook.py\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eWhen you run this, you should see a message from you Slack bot appear in the \u003ccode\u003enotifications\u003c/code\u003e channel!\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/slack-webhook/slack-first-message.jpg\" alt=\"Hello world message in Slack {1004x675}\"\u003e\u003c/p\u003e\n\u003cp\u003eFor our notifications to be more helpful, we may want to add links or other formatting.  To do this, we will write our notifications with HTML tags, and then parse these tags and convert them to the \u003ca href=\"https://api.slack.com/reference/surfaces/formatting\"\u003eSlack flavored Markdown\u003c/a\u003e called \u003ccode\u003emrkdwn\u003c/code\u003e.\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003eAdding a simple HTML parser to our class\u003c/h2\u003e\n\u003cp\u003eFrom the \u003ca href=\"https://api.slack.com/reference/surfaces/formatting\"\u003eSlack formatting guide\u003c/a\u003e for messages, we can see all of the ways to format text in our messages.  For our purposes, we will focus on a primary list.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eMaking text \u003ccode\u003e_italicized_\u003c/code\u003e (\u003ccode\u003e\u0026#x3C;i\u003e\u003c/code\u003e)\u003c/li\u003e\n\u003cli\u003eMaking text \u003ccode\u003e*bold*\u003c/code\u003e (\u003ccode\u003e\u0026#x3C;b\u003e\u003c/code\u003e)\u003c/li\u003e\n\u003cli\u003eStriking through ~\u003ccode\u003etext\u003c/code\u003e~ (\u003ccode\u003e\u0026#x3C;strike\u003e\u003c/code\u003e)\u003c/li\u003e\n\u003cli\u003eAdding line breaks (\u003ccode\u003e\u0026#x3C;br\u003e\u003c/code\u003e)\u003c/li\u003e\n\u003cli\u003eAdding \u003ccode\u003eone-line code blocks\u003c/code\u003e using the backtick character (\u003ccode\u003e\u0026#x3C;code\u003e\u003c/code\u003e)\u003c/li\u003e\n\u003cli\u003eAdding unordered lists (line broken dashes) (\u003ccode\u003e\u0026#x3C;ul\u003e\u0026#x3C;li\u003e\u003c/code\u003e)\u003c/li\u003e\n\u003cli\u003eAdding external links \u003ccode\u003e\u0026#x3C;[external link]|[display text]\u003e\u003c/code\u003e (\u003ccode\u003e\u0026#x3C;a\u003e\u003c/code\u003e)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eAlso note that the Slack documentation says that \u003ca href=\"https://api.slack.com/reference/surfaces/formatting#escaping\"\u003ecertain characters need to be escaped\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eThere are a few more styles that could be implemented, but we'll focus on just this list for this post.\u003c/p\u003e\n\u003cp\u003eTo do this, we will utilize the \u003ca href=\"https://docs.python.org/3/library/html.html\"\u003e\u003ccode\u003ehtml\u003c/code\u003e\u003c/a\u003e module in the Python standard library to parse HTML tags, attributes, and values.\u003c/p\u003e\n\u003cp\u003eLet's write a class (we need to inherit functions for the \u003ccode\u003eHTMLParser\u003c/code\u003e class) where we will parse all of the tags and attributes, and escape the message text when needed.  The idea here is that we can construct a string from scratch and for each tag we care about we can \"replace\" the HTML tags with the relevant mrkdwn syntax.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003efrom html.parser import HTMLParser\nimport re\nfrom typing import Any, List, Tuple\n\n\nclass SlackHTMLParser(HTMLParser):\n    def __init__(self, *args, **kwargs):\n        \"\"\"Escapes and converts an HTML string to Slack flavored\n        Markdown (mrkdwn).\n\n        More about Slack's Markdown Flavor (mrkdwn) can be seen here:\n            https://api.slack.com/reference/surfaces/formatting\n        \n        Call using `SlackHTMLParser(message_body).parse()`.\n        \"\"\"\n        super().__init__(*args, **kwargs)\n        self.slack_message = ''\n        self.ignore_tag = False  # Used to skip tags we don't care about\n        self.line_break = '::LINE::BREAK::'  # Unique sequence for swapping a \u0026#x3C;br\u003e\n\n\n    def handle_starttag(self, tag: str, attrs: List[Tuple[str, Any]]):\n        \"\"\"Called when the opening of a tag is encountered.\n\n        The idea here is to swap out the tag with the respective mrkdwn\n        symbol.\n\n        Args:\n            tag: Lowercase name of the HTML tag.  E.G. `br` or `i`.\n            attrs: List of tuples with the tuple having the following form:\n                (attribute name, value).  E.G. ('href', 'www.example.com').\n        \"\"\"\n        if tag in ['i', 'em']:\n            self.slack_message += '_'\n        elif tag in ['b', 'strong']:\n            self.slack_message += '*'\n        elif tag == 'strike':\n            self.slack_message += '~'\n        elif tag in ['br', 'p', 'ul']:\n            self.slack_message += self.line_break\n        elif tag == 'li':\n            self.slack_message += f'{self.line_break}- '\n        elif tag == 'code':\n            self.slack_message += '`'\n        elif tag == 'a':\n            href = [x[1] for x in attrs if x[0] == 'href']\n            if len(href) \u003e 0:\n                self.slack_message += f'\u0026#x3C;{href[0]}|'\n        else:\n            self.ignore_tag = True\n\n\n    def handle_data(self, data: str):\n        \"\"\"Handles the data within a tag.\n\n        This is called after `handle_starttag` and before `handle_endtag`.\n\n        We will also escape the following text per Slack's documentation:\n        - '\u0026#x26;' -\u003e '\u0026#x26;amp;'\n        - '\u0026#x3C;' -\u003e '\u0026#x26;lt;'\n        - '\u003e' -\u003e '\u0026#x26;gt;'\n\n        Args:\n            data: The data/string within the HTML tag.\n        \"\"\"\n        if not self.ignore_tag:\n            self.slack_message += data\\\n                .replace('\u0026#x26;', '\u0026#x26;amp;')\\\n                .replace('\u0026#x3C;', '\u0026#x26;lt;')\\\n                .replace('\u003e', '\u0026#x26;gt;')\n\n\n    def handle_endtag(self, tag: str):\n        \"\"\"Called when the closing of a tag is encountered.\n\n        The idea here is to swap out the tag with the respective mrkdwn\n        symbol.  This is basically the same as the handle_starttag.\n\n        Args:\n            tag: Lowercase name of the HTML tag.  E.G. `br` or `i`.\n        \"\"\"\n        if tag in ['i', 'em']:\n            self.slack_message += '_'\n        elif tag in ['b', 'strong']:\n            self.slack_message += '*'\n        elif tag == 'strike':\n            self.slack_message += '~'\n        elif tag == 'p':\n            self.slack_message += self.line_break\n        elif tag == 'code':\n            self.slack_message += '`'\n        elif tag == 'a':\n            self.slack_message += '\u003e'\n        \n        self.ignore_tag = False\n\n\n    def parse(self, html_string: str) -\u003e str:\n        \"\"\"Parses a given HTML string and applies simple formatting.\n        \n        Note that we need to apply the line break replacing here\n        instead of with the handle tag methods.\n\n        Args:\n            html_string: The HTML string to convert to Slack mrkdwn.\n\n        Returns:\n            A formatted Slack mrkdwn string.\n        \"\"\"\n        self.feed(html_string)\n        return re.sub(\n            r'^(\\n)+',  # Remove the leading line breaks\n            '',\n            ' '.join(self.slack_message.split()).replace(self.line_break, '\\n')\n        )\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eWe can test our class out with the following code.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ehtml_string = '''\n    \u0026#x3C;p\u003e\n        Here \u0026#x3C;i\u003eis\u0026#x3C;/i\u003e a \u0026#x3C;strike\u003eparagraph\u0026#x3C;/strike\u003e with a \u0026#x3C;b\u003elot\u0026#x3C;/b\u003e of formatting.\n    \u0026#x3C;/p\u003e\n    \u0026#x3C;br\u003e\n    \u0026#x3C;code\u003eCode sample\u0026#x3C;/code\u003e \u0026#x26; testing escape.\n    \u0026#x3C;ul\u003e\n        \u0026#x3C;li\u003e\n            \u0026#x3C;a href=\"https://www.google.com\"\u003eGoogle\u0026#x3C;/a\u003e\n        \u0026#x3C;/li\u003e\n        \u0026#x3C;li\u003e\n            \u0026#x3C;a href=\"https://www.amazon.com\"\u003eAmazon\u0026#x3C;/a\u003e\n        \u0026#x3C;/li\u003e\n    \u0026#x3C;/ul\u003e\n'''\nparser = SlackHTMLParser()\nslack_message = parser.parse(html_string)\nprint(slack_message)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eNow we can test our formatter in an actual Slack message!  Import your formatter class or add it to your existing code so you're able to do the following.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ehtml_string = '''\n    \u0026#x3C;p\u003e\n        Here \u0026#x3C;i\u003eis\u0026#x3C;/i\u003e a \u0026#x3C;strike\u003eparagraph\u0026#x3C;/strike\u003e with a \u0026#x3C;b\u003elot\u0026#x3C;/b\u003e of formatting.\n    \u0026#x3C;/p\u003e\n    \u0026#x3C;br\u003e\n    \u0026#x3C;code\u003eCode sample\u0026#x3C;/code\u003e \u0026#x26; testing escape.\n    \u0026#x3C;ul\u003e\n        \u0026#x3C;li\u003e\n            \u0026#x3C;a href=\"https://www.google.com\"\u003eGoogle\u0026#x3C;/a\u003e\n        \u0026#x3C;/li\u003e\n        \u0026#x3C;li\u003e\n            \u0026#x3C;a href=\"https://www.amazon.com\"\u003eAmazon\u0026#x3C;/a\u003e\n        \u0026#x3C;/li\u003e\n    \u0026#x3C;/ul\u003e\n'''\nwebhook_url = os.environ.get('SLACK_WEBHOOK_URL')\nparser = SlackHTMLParser()\nslack_message = parser.parse(html_string)\nslack = SlackWebhookBot(webhook_url)\nslack.send(slack_message)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eYou should see the following message in your notifications channel.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/slack-webhook/slack-format-message.jpg\" alt=\"Second message in Slack {680x140}\"\u003e\u003c/p\u003e\n\u003cp\u003eLooks pretty good!  \u003cem\u003eNote that you can still send plain text messages, you don't need to use HTML.\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003eFor some final adjustments, you may have noticed that the message preview on the notification that popped up showed the actual \u003ccode\u003emrkdwn\u003c/code\u003e characters as opposed to a formatted notification.  This looks a little sloppy, so let's make a new notification title that is similar to an email subject line.\u003c/p\u003e\n\u003cp\u003eWe will briefly look at the basics of Slack's \u003ca href=\"https://api.slack.com/block-kit\"\u003eBlock Kit\u003c/a\u003e, which is a powerful way to add lots of customization to your Slack messages.  You can also explore Block Kit with Slack's \u003ca href=\"https://app.slack.com/block-kit-builder/\"\u003eBlock Kit Builder\u003c/a\u003e which provides a preview of your Slack message.\u003c/p\u003e\n\u003cp\u003eWithout diving too much into the details on the Block Kit, let's update our \u003ccode\u003eSlackWebhookBot\u003c/code\u003e class and add a method that adds a title block and a body block for our message.  Our subject line will appear in the notification itself, and also in the actual Slack message.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e# Add the `Dict` typing import to the existing typing imports\nfrom typing import Dict\n\ndef format_message(self, subject: str, body: str) -\u003e Dict:\n    \"\"\"Formats the subject and message body into Slack blocks.\n\n    Args:\n        subject: Subject that will appear on the notification popup.\n        body: The full message body.\n\n    Returns:\n        A dictionary payload with Slack block formatting.\n    \"\"\"\n    return {\n        'text': subject,\n        'blocks': [\n            {\n                'type': 'section',\n                'text': {\n                    'type': 'mrkdwn',\n                    'text': f'*{subject}*',\n                },\n            },\n            {\n                'type': 'section',\n                'text': {\n                    'type': 'mrkdwn',\n                    'text': body,\n                },\n            },\n        ],\n    }\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eNow we can tweak our \u003ccode\u003esend\u003c/code\u003e method to format a new message and accept a subject string as a Kwarg.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003edef send(self, message: str, subject: str = 'New message!') -\u003e bool:\n    \"\"\"Sends a formatted message to the webhook URL.\n\n    Args:\n        message: Plain text string to send to Slack.\n\n    Kwargs:\n        subject: The subject of the message that will appear in the notification\n            preview.\n\n    Returns:\n        A boolean representing if the request was successful.\n    \"\"\"\n    success = False\n    payload = self.format_message(subject, message)\n    try:\n        r = requests.post(\n            self.webhook_url,\n            headers=self.headers,\n            json=payload,\n            timeout=self.timeout\n        )\n    except requests.Timeout:\n        logger.error('Timeout occurred when trying to send message to Slack.')\n    except requests.RequestException as e:\n        logger.error(f'Error occurred when communicating with Slack: {e}.')\n    else:\n        success = True\n        logger.info('Successfully sent message to Slack.')\n\n    return success\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eAnd we can test our notification with a new subject line.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ehtml_string = '''\n    \u0026#x3C;p\u003e\n        Here \u0026#x3C;i\u003eis\u0026#x3C;/i\u003e a \u0026#x3C;strike\u003eparagraph\u0026#x3C;/strike\u003e with a \u0026#x3C;b\u003elot\u0026#x3C;/b\u003e of formatting.\n    \u0026#x3C;/p\u003e\n    \u0026#x3C;br\u003e\n    \u0026#x3C;code\u003eCode sample\u0026#x3C;/code\u003e \u0026#x26; testing escape.\n    \u0026#x3C;ul\u003e\n        \u0026#x3C;li\u003e\n            \u0026#x3C;a href=\"https://www.google.com\"\u003eGoogle\u0026#x3C;/a\u003e\n        \u0026#x3C;/li\u003e\n        \u0026#x3C;li\u003e\n            \u0026#x3C;a href=\"https://www.amazon.com\"\u003eAmazon\u0026#x3C;/a\u003e\n        \u0026#x3C;/li\u003e\n    \u0026#x3C;/ul\u003e\n'''\nwebhook_url = os.environ.get('SLACK_WEBHOOK_URL')\nparser = SlackHTMLParser()\nslack_message = parser.parse(html_string)\nslack = SlackWebhookBot(webhook_url)\nslack.send(slack_message, subject='You\\'ve completed the tutorial!')\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eYou should see a notification appear with the following preview\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/slack-webhook/slack-popup.jpg\" alt=\"Slack notification {453x101}\"\u003e\u003c/p\u003e\n\u003cp\u003eand the following message in your channel.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/slack-webhook/slack-last-message.jpg\" alt=\"Last message in Slack {680x159}\"\u003e\u003c/p\u003e\n\u003cp\u003eWe have a custom Slack notification app!  You can place the \u003ccode\u003esend\u003c/code\u003e message calls all across your applications with related messages and now you can have a better pulse on user activity that developers and any other employees/stakeholders can easily access.\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003eFor those wanting additional challenges or to continue developing their custom app, Slack has added a lot of really cool tools to the Block Kit.  There are a ton of really cool possibilities that can be added on by updating the \u003ccode\u003eformat_message\u003c/code\u003e method in our \u003ccode\u003eSlackWebhookBot\u003c/code\u003e class.\u003c/p\u003e\n\u003cp\u003eExplore the Slack's \u003ca href=\"https://app.slack.com/block-kit-builder/\"\u003eBlock Kit Builder\u003c/a\u003e and see what you can make!\u003c/p\u003e\n\u003chr\u003e\n","markdown":"\n## tl;dr\n\n### Goal\n_To set up a Slack webhook so we can send text and simple HTML notifications to receive in a Slack channel._\n\n### Process Overview\n1. Setting up a Slack webhook URL in your Slack workspace to post to a channel\n2. Posting a notification to our webhook\n3. Creating a simple HTML parser to match the custom Slack markdown flavor\n\n### Python Dependencies\n```python\n# Python standard library\nfrom html.parser import HTMLParser\nimport logging\nimport os\nimport re\nfrom typing import Any, List, Tuple\n\n# 3rd Party\nimport requests\n```\n\n### Assumptions\nI'll assume you have a Slack account, a Slack workspace setup, Slack is installed, and you have knowledge of Python with a basic understanding of webhooks.\n\n---\n\nIf you haven't heard of it before, [Slack](https://slack.com/) is a very popular team/workplace communication tool.  In addition to direct messaging, it allows you to separate discussion into various topics or **channels** for more focused team communication.\n\nAnother great feature of Slack is that you can add 3rd party [apps](https://slack.com/apps) (or integrations) from your existing stack, or even develop your own!  I have seen this streamline my own productivity, and I personally use a number of Slack apps.\n\nTo name a few, you may want to check out the following (assuming you use these tools) which I've found a lot of value in:\n- [Sentry](https://slack.com/apps/A011MFBJEUU-sentry?tab=more_info) - for application monitoring\n- [Google Calendar](https://slack.com/apps/ADZ494LHY-google-calendar?tab=more_info) - to stay on top of my meetings schedule\n- [GitHub](https://slack.com/apps/A01BP7R4KNY-github?tab=more_info) - getting notified of pull requests and meaningful changes to important repositories\n- [Jira Cloud](https://slack.com/apps/A2RPP3NFR-jira-cloud?tab=more_info) - staying on top of changes to Jira tickets\n- [AWS Chatbot](https://slack.com/apps/A6L22LZNH-aws-chatbot?tab=more_info) - alerts from CloudWatch alarms\n\nYou can browse the [Slack app directory](https://slack.com/apps) for more integrations.\n\nHowever, not every integration is going to provide the functionality you need.  This post will focus on creating our own custom Slack app with the goal of posting simple notifications to a Slack channel.\n\nA common use case where we can apply our app will be sending notifications when any sort of user activity happens on a platform.  As a developer, being notified of when a user completes a certain task can provide a lot of transparency and understanding into the usage of our application, while also keeping a sales teams informed on relevant activity on the platform.  This is the use case we'll focus on.\n\nWe will do this by posting to a webhook hosted by Slack.  For more information on webhooks, you can check out [this article](https://zapier.com/blog/what-are-webhooks/) by Zapier.\n\nLet's get started!\n\n---\n\n## Setting up the Slack App\nOpen Slack, click **Add channels**, and create a new channel called `notifications`.  This is where our Slack app will post to once we set it up.\n\n![Create a Slack channel {priority}{1004x580}](/images/slack-webhook/create-channel.jpg)\n\nNow go to a web browser and head to https://api.slack.com/apps/.\n\nClick on **Create an App**\n\n![Create a Slack App {1004x497}](/images/slack-webhook/create-app.jpg)\n\nSelect **From scratch**\n\n![Select From Scratch {1004x497}](/images/slack-webhook/from-scratch.jpg)\n\nCreate a name for your app and select the workspace you just created your `notifications` channel in.\n\n![Choose an app name and workspace {1004x501}](/images/slack-webhook/app-and-workspace.jpg)\n\n\nThis will redirect you to the **Basic Information** tab for your app.  Here, we'll enable **Incoming Webhooks**.  As it states, this will enable us to post messages from an external source.  In this case, our platform.\n\n![Enable incoming webhooks {1004x497}](/images/slack-webhook/add-webhooks.jpg)\n\n\nTurn on **Activate Incoming Webhooks** and you will see additional details appear.  Towards the bottom, click on **Add New Webhook to Workspace**.\n\n![Add a new webhook to your workspace {1004x485}](/images/slack-webhook/add-new-webhook.jpg)\n\nYou will be redirected again to select which channel to post to.  Select the `notifications` channel that we previously created and press **Allow**.\n\n![Select a channel for your app {1004x498}](/images/slack-webhook/choose-channel.jpg)\n\n\nThis will redirect you back to your app configuration and you will see a webhook URL you can now post to.  This will also include a simple curl POST request you can test with if you'd like.  Copy the webhook URL for later, and remember to **keep it private**.  This is a public URL that anyone can post to.\n\n![Copy your webhook URL {680x506}](/images/slack-webhook/copy-url.jpg)\n\n\nYou can return to the **Basic Information** of your app settings in Slack to view more API credentials and also edit the look and feel of your new Slack bot.\n\nNow we're ready to dive into the code to communicate with our webhook!\n\n---\n\n## Communicating with our Webhook\nTo communicate with our webhook, we'll use the [`requests`](https://docs.python-requests.org/en/master/) Python library.  This is a third party library, so you'll want to have a Python virtual environment set up to handle your dependencies.  Virtual environments are out of the scope of this article, but you can read more on them [here](https://docs.python.org/3/tutorial/venv.html).\n\nInside your virtual environment, you can run the following to install the library.\n```bash\npip install requests\n```\n\nNow, we'll set up a class to communicate with our Slack endpoint.  We'll start by just sending a plain text message to Slack.\n\n```python\nimport logging\n\nimport requests\n\n\nlogger = logging.getLogger()\nlogger.setLevel(logging.INFO)\n\n\nclass SlackWebhookBot:\n    def __init__(self, webhook_url: str, timeout: int = 15):\n        \"\"\"Class to send messages to a provided Slack webhook URL.\n\n        You can read more about Slack's Incoming Webhooks here:\n            https://api.slack.com/messaging/webhooks\n        \n        Args:\n            webhook_url: The webhook URL to send a message to.  Typically\n                formatted like \"https://hooks.slack.com/services/...\".\n        \n        Kwargs:\n            timeout: Number of seconds before the request will timeout.\n                This is used to prevent a hang and is set to a default\n                value of 15 seconds.\n        \"\"\"\n        self.webhook_url = webhook_url\n        self.timeout = timeout\n        self.headers = {\n            'Content-Type': 'application/json',\n        }\n    \n\n    def send(self, message: str) -\u003e bool:\n        \"\"\"Sends a message to the webhook URL.\n\n        Per the Slack Incoming Webhook example.  The body of the request\n        (for plain text) should be formatted as follows:\n            `{\"text\": \"Hello, World!\"}`\n\n        Args:\n            message: Plain text string to send to Slack.\n\n        Returns:\n            A boolean representing if the request was successful.\n        \"\"\"\n        success = False\n        payload = {\n            'text': message,\n        }\n        try:\n            r = requests.post(\n                self.webhook_url,\n                headers=self.headers,\n                json=payload,\n                timeout=self.timeout\n            )\n        except requests.Timeout:\n            logger.error('Timeout occurred when trying to send message to Slack.')\n        except requests.RequestException as e:\n            logger.error(f'Error occurred when communicating with Slack: {e}.')\n        else:\n            success = True\n            logger.info('Successfully sent message to Slack.')\n\n        return success\n```\n\nAbove is the basic setup for communicating with the Slack webhook.  We can run a quick test by moving this code to a script and adding the following.\n```python\nimport os\n\nwebhook_url = os.environ.get('SLACK_WEBHOOK_URL')\nslack = SlackWebhookBot(webhook_url)\nslack.send('Hello, world!')\n```\n\nMake sure to set your Slack webhook URL to the `SLACK_WEBHOOK_URL` environment variable, and make sure you're in your virtual environment with the `requests` package installed before running the script.  This can be done on MacOS with the following.\n```bash\nexport SLACK_WEBHOOK_URL=https://hooks.slack.com/services/...\npython slack_webhook.py\n```\n\nWhen you run this, you should see a message from you Slack bot appear in the `notifications` channel!\n\n![Hello world message in Slack {1004x675}](/images/slack-webhook/slack-first-message.jpg)\n\n\nFor our notifications to be more helpful, we may want to add links or other formatting.  To do this, we will write our notifications with HTML tags, and then parse these tags and convert them to the [Slack flavored Markdown](https://api.slack.com/reference/surfaces/formatting) called `mrkdwn`.\n\n---\n\n## Adding a simple HTML parser to our class\nFrom the [Slack formatting guide](https://api.slack.com/reference/surfaces/formatting) for messages, we can see all of the ways to format text in our messages.  For our purposes, we will focus on a primary list.\n\n- Making text \u003ci\u003e`_italicized_`\u003c/i\u003e (`\u003ci\u003e`)\n- Making text \u003cb\u003e`*bold*`\u003c/b\u003e (`\u003cb\u003e`)\n- Striking through ~\u003cstrike\u003e`text`\u003c/strike\u003e~ (`\u003cstrike\u003e`)\n- Adding line breaks (`\u003cbr\u003e`)\n- Adding `one-line code blocks` using the backtick character (`\u003ccode\u003e`)\n- Adding unordered lists (line broken dashes) (`\u003cul\u003e\u003cli\u003e`)\n- Adding external links `\u003c[external link]|[display text]\u003e` (`\u003ca\u003e`)\n\nAlso note that the Slack documentation says that [certain characters need to be escaped](https://api.slack.com/reference/surfaces/formatting#escaping).\n\nThere are a few more styles that could be implemented, but we'll focus on just this list for this post.\n\nTo do this, we will utilize the [`html`](https://docs.python.org/3/library/html.html) module in the Python standard library to parse HTML tags, attributes, and values.\n\nLet's write a class (we need to inherit functions for the `HTMLParser` class) where we will parse all of the tags and attributes, and escape the message text when needed.  The idea here is that we can construct a string from scratch and for each tag we care about we can \"replace\" the HTML tags with the relevant mrkdwn syntax.\n\n```python\nfrom html.parser import HTMLParser\nimport re\nfrom typing import Any, List, Tuple\n\n\nclass SlackHTMLParser(HTMLParser):\n    def __init__(self, *args, **kwargs):\n        \"\"\"Escapes and converts an HTML string to Slack flavored\n        Markdown (mrkdwn).\n\n        More about Slack's Markdown Flavor (mrkdwn) can be seen here:\n            https://api.slack.com/reference/surfaces/formatting\n        \n        Call using `SlackHTMLParser(message_body).parse()`.\n        \"\"\"\n        super().__init__(*args, **kwargs)\n        self.slack_message = ''\n        self.ignore_tag = False  # Used to skip tags we don't care about\n        self.line_break = '::LINE::BREAK::'  # Unique sequence for swapping a \u003cbr\u003e\n\n\n    def handle_starttag(self, tag: str, attrs: List[Tuple[str, Any]]):\n        \"\"\"Called when the opening of a tag is encountered.\n\n        The idea here is to swap out the tag with the respective mrkdwn\n        symbol.\n\n        Args:\n            tag: Lowercase name of the HTML tag.  E.G. `br` or `i`.\n            attrs: List of tuples with the tuple having the following form:\n                (attribute name, value).  E.G. ('href', 'www.example.com').\n        \"\"\"\n        if tag in ['i', 'em']:\n            self.slack_message += '_'\n        elif tag in ['b', 'strong']:\n            self.slack_message += '*'\n        elif tag == 'strike':\n            self.slack_message += '~'\n        elif tag in ['br', 'p', 'ul']:\n            self.slack_message += self.line_break\n        elif tag == 'li':\n            self.slack_message += f'{self.line_break}- '\n        elif tag == 'code':\n            self.slack_message += '`'\n        elif tag == 'a':\n            href = [x[1] for x in attrs if x[0] == 'href']\n            if len(href) \u003e 0:\n                self.slack_message += f'\u003c{href[0]}|'\n        else:\n            self.ignore_tag = True\n\n\n    def handle_data(self, data: str):\n        \"\"\"Handles the data within a tag.\n\n        This is called after `handle_starttag` and before `handle_endtag`.\n\n        We will also escape the following text per Slack's documentation:\n        - '\u0026' -\u003e '\u0026amp;'\n        - '\u003c' -\u003e '\u0026lt;'\n        - '\u003e' -\u003e '\u0026gt;'\n\n        Args:\n            data: The data/string within the HTML tag.\n        \"\"\"\n        if not self.ignore_tag:\n            self.slack_message += data\\\n                .replace('\u0026', '\u0026amp;')\\\n                .replace('\u003c', '\u0026lt;')\\\n                .replace('\u003e', '\u0026gt;')\n\n\n    def handle_endtag(self, tag: str):\n        \"\"\"Called when the closing of a tag is encountered.\n\n        The idea here is to swap out the tag with the respective mrkdwn\n        symbol.  This is basically the same as the handle_starttag.\n\n        Args:\n            tag: Lowercase name of the HTML tag.  E.G. `br` or `i`.\n        \"\"\"\n        if tag in ['i', 'em']:\n            self.slack_message += '_'\n        elif tag in ['b', 'strong']:\n            self.slack_message += '*'\n        elif tag == 'strike':\n            self.slack_message += '~'\n        elif tag == 'p':\n            self.slack_message += self.line_break\n        elif tag == 'code':\n            self.slack_message += '`'\n        elif tag == 'a':\n            self.slack_message += '\u003e'\n        \n        self.ignore_tag = False\n\n\n    def parse(self, html_string: str) -\u003e str:\n        \"\"\"Parses a given HTML string and applies simple formatting.\n        \n        Note that we need to apply the line break replacing here\n        instead of with the handle tag methods.\n\n        Args:\n            html_string: The HTML string to convert to Slack mrkdwn.\n\n        Returns:\n            A formatted Slack mrkdwn string.\n        \"\"\"\n        self.feed(html_string)\n        return re.sub(\n            r'^(\\n)+',  # Remove the leading line breaks\n            '',\n            ' '.join(self.slack_message.split()).replace(self.line_break, '\\n')\n        )\n```\n\nWe can test our class out with the following code.\n\n```python\nhtml_string = '''\n    \u003cp\u003e\n        Here \u003ci\u003eis\u003c/i\u003e a \u003cstrike\u003eparagraph\u003c/strike\u003e with a \u003cb\u003elot\u003c/b\u003e of formatting.\n    \u003c/p\u003e\n    \u003cbr\u003e\n    \u003ccode\u003eCode sample\u003c/code\u003e \u0026 testing escape.\n    \u003cul\u003e\n        \u003cli\u003e\n            \u003ca href=\"https://www.google.com\"\u003eGoogle\u003c/a\u003e\n        \u003c/li\u003e\n        \u003cli\u003e\n            \u003ca href=\"https://www.amazon.com\"\u003eAmazon\u003c/a\u003e\n        \u003c/li\u003e\n    \u003c/ul\u003e\n'''\nparser = SlackHTMLParser()\nslack_message = parser.parse(html_string)\nprint(slack_message)\n```\n\nNow we can test our formatter in an actual Slack message!  Import your formatter class or add it to your existing code so you're able to do the following.\n\n```python\nhtml_string = '''\n    \u003cp\u003e\n        Here \u003ci\u003eis\u003c/i\u003e a \u003cstrike\u003eparagraph\u003c/strike\u003e with a \u003cb\u003elot\u003c/b\u003e of formatting.\n    \u003c/p\u003e\n    \u003cbr\u003e\n    \u003ccode\u003eCode sample\u003c/code\u003e \u0026 testing escape.\n    \u003cul\u003e\n        \u003cli\u003e\n            \u003ca href=\"https://www.google.com\"\u003eGoogle\u003c/a\u003e\n        \u003c/li\u003e\n        \u003cli\u003e\n            \u003ca href=\"https://www.amazon.com\"\u003eAmazon\u003c/a\u003e\n        \u003c/li\u003e\n    \u003c/ul\u003e\n'''\nwebhook_url = os.environ.get('SLACK_WEBHOOK_URL')\nparser = SlackHTMLParser()\nslack_message = parser.parse(html_string)\nslack = SlackWebhookBot(webhook_url)\nslack.send(slack_message)\n```\n\nYou should see the following message in your notifications channel.\n\n![Second message in Slack {680x140}](/images/slack-webhook/slack-format-message.jpg)\n\nLooks pretty good!  _Note that you can still send plain text messages, you don't need to use HTML._\n\nFor some final adjustments, you may have noticed that the message preview on the notification that popped up showed the actual `mrkdwn` characters as opposed to a formatted notification.  This looks a little sloppy, so let's make a new notification title that is similar to an email subject line.\n\nWe will briefly look at the basics of Slack's [Block Kit](https://api.slack.com/block-kit), which is a powerful way to add lots of customization to your Slack messages.  You can also explore Block Kit with Slack's [Block Kit Builder](https://app.slack.com/block-kit-builder/) which provides a preview of your Slack message.\n\nWithout diving too much into the details on the Block Kit, let's update our `SlackWebhookBot` class and add a method that adds a title block and a body block for our message.  Our subject line will appear in the notification itself, and also in the actual Slack message.\n\n```python\n# Add the `Dict` typing import to the existing typing imports\nfrom typing import Dict\n\ndef format_message(self, subject: str, body: str) -\u003e Dict:\n    \"\"\"Formats the subject and message body into Slack blocks.\n\n    Args:\n        subject: Subject that will appear on the notification popup.\n        body: The full message body.\n\n    Returns:\n        A dictionary payload with Slack block formatting.\n    \"\"\"\n    return {\n        'text': subject,\n        'blocks': [\n            {\n                'type': 'section',\n                'text': {\n                    'type': 'mrkdwn',\n                    'text': f'*{subject}*',\n                },\n            },\n            {\n                'type': 'section',\n                'text': {\n                    'type': 'mrkdwn',\n                    'text': body,\n                },\n            },\n        ],\n    }\n```\n\nNow we can tweak our `send` method to format a new message and accept a subject string as a Kwarg.\n\n```python\ndef send(self, message: str, subject: str = 'New message!') -\u003e bool:\n    \"\"\"Sends a formatted message to the webhook URL.\n\n    Args:\n        message: Plain text string to send to Slack.\n\n    Kwargs:\n        subject: The subject of the message that will appear in the notification\n            preview.\n\n    Returns:\n        A boolean representing if the request was successful.\n    \"\"\"\n    success = False\n    payload = self.format_message(subject, message)\n    try:\n        r = requests.post(\n            self.webhook_url,\n            headers=self.headers,\n            json=payload,\n            timeout=self.timeout\n        )\n    except requests.Timeout:\n        logger.error('Timeout occurred when trying to send message to Slack.')\n    except requests.RequestException as e:\n        logger.error(f'Error occurred when communicating with Slack: {e}.')\n    else:\n        success = True\n        logger.info('Successfully sent message to Slack.')\n\n    return success\n```\n\nAnd we can test our notification with a new subject line.\n\n```python\nhtml_string = '''\n    \u003cp\u003e\n        Here \u003ci\u003eis\u003c/i\u003e a \u003cstrike\u003eparagraph\u003c/strike\u003e with a \u003cb\u003elot\u003c/b\u003e of formatting.\n    \u003c/p\u003e\n    \u003cbr\u003e\n    \u003ccode\u003eCode sample\u003c/code\u003e \u0026 testing escape.\n    \u003cul\u003e\n        \u003cli\u003e\n            \u003ca href=\"https://www.google.com\"\u003eGoogle\u003c/a\u003e\n        \u003c/li\u003e\n        \u003cli\u003e\n            \u003ca href=\"https://www.amazon.com\"\u003eAmazon\u003c/a\u003e\n        \u003c/li\u003e\n    \u003c/ul\u003e\n'''\nwebhook_url = os.environ.get('SLACK_WEBHOOK_URL')\nparser = SlackHTMLParser()\nslack_message = parser.parse(html_string)\nslack = SlackWebhookBot(webhook_url)\nslack.send(slack_message, subject='You\\'ve completed the tutorial!')\n```\n\nYou should see a notification appear with the following preview\n\n![Slack notification {453x101}](/images/slack-webhook/slack-popup.jpg)\n\n\nand the following message in your channel.\n\n![Last message in Slack {680x159}](/images/slack-webhook/slack-last-message.jpg)\n\n\nWe have a custom Slack notification app!  You can place the `send` message calls all across your applications with related messages and now you can have a better pulse on user activity that developers and any other employees/stakeholders can easily access.\n\n---\n\nFor those wanting additional challenges or to continue developing their custom app, Slack has added a lot of really cool tools to the Block Kit.  There are a ton of really cool possibilities that can be added on by updating the `format_message` method in our `SlackWebhookBot` class.\n\nExplore the Slack's [Block Kit Builder](https://app.slack.com/block-kit-builder/) and see what you can make!\n\n---\n","title":"Setting up a Slack webhook for simple notifications","date":"2021-07-11","tags":["python","slack","webhook","api"],"description":"Setting up a Slack webhook to send plain text or simple HTML notifications to a Slack channel."}],"webhook":[{"id":"slack-webhook","contentHtml":"\u003ch2\u003etl;dr\u003c/h2\u003e\n\u003ch3\u003eGoal\u003c/h3\u003e\n\u003cp\u003e\u003cem\u003eTo set up a Slack webhook so we can send text and simple HTML notifications to receive in a Slack channel.\u003c/em\u003e\u003c/p\u003e\n\u003ch3\u003eProcess Overview\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003eSetting up a Slack webhook URL in your Slack workspace to post to a channel\u003c/li\u003e\n\u003cli\u003ePosting a notification to our webhook\u003c/li\u003e\n\u003cli\u003eCreating a simple HTML parser to match the custom Slack markdown flavor\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3\u003ePython Dependencies\u003c/h3\u003e\n\u003cpre\u003e\u003ccode\u003e# Python standard library\nfrom html.parser import HTMLParser\nimport logging\nimport os\nimport re\nfrom typing import Any, List, Tuple\n\n# 3rd Party\nimport requests\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003eAssumptions\u003c/h3\u003e\n\u003cp\u003eI'll assume you have a Slack account, a Slack workspace setup, Slack is installed, and you have knowledge of Python with a basic understanding of webhooks.\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003eIf you haven't heard of it before, \u003ca href=\"https://slack.com/\"\u003eSlack\u003c/a\u003e is a very popular team/workplace communication tool.  In addition to direct messaging, it allows you to separate discussion into various topics or \u003cstrong\u003echannels\u003c/strong\u003e for more focused team communication.\u003c/p\u003e\n\u003cp\u003eAnother great feature of Slack is that you can add 3rd party \u003ca href=\"https://slack.com/apps\"\u003eapps\u003c/a\u003e (or integrations) from your existing stack, or even develop your own!  I have seen this streamline my own productivity, and I personally use a number of Slack apps.\u003c/p\u003e\n\u003cp\u003eTo name a few, you may want to check out the following (assuming you use these tools) which I've found a lot of value in:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://slack.com/apps/A011MFBJEUU-sentry?tab=more_info\"\u003eSentry\u003c/a\u003e - for application monitoring\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://slack.com/apps/ADZ494LHY-google-calendar?tab=more_info\"\u003eGoogle Calendar\u003c/a\u003e - to stay on top of my meetings schedule\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://slack.com/apps/A01BP7R4KNY-github?tab=more_info\"\u003eGitHub\u003c/a\u003e - getting notified of pull requests and meaningful changes to important repositories\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://slack.com/apps/A2RPP3NFR-jira-cloud?tab=more_info\"\u003eJira Cloud\u003c/a\u003e - staying on top of changes to Jira tickets\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://slack.com/apps/A6L22LZNH-aws-chatbot?tab=more_info\"\u003eAWS Chatbot\u003c/a\u003e - alerts from CloudWatch alarms\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eYou can browse the \u003ca href=\"https://slack.com/apps\"\u003eSlack app directory\u003c/a\u003e for more integrations.\u003c/p\u003e\n\u003cp\u003eHowever, not every integration is going to provide the functionality you need.  This post will focus on creating our own custom Slack app with the goal of posting simple notifications to a Slack channel.\u003c/p\u003e\n\u003cp\u003eA common use case where we can apply our app will be sending notifications when any sort of user activity happens on a platform.  As a developer, being notified of when a user completes a certain task can provide a lot of transparency and understanding into the usage of our application, while also keeping a sales teams informed on relevant activity on the platform.  This is the use case we'll focus on.\u003c/p\u003e\n\u003cp\u003eWe will do this by posting to a webhook hosted by Slack.  For more information on webhooks, you can check out \u003ca href=\"https://zapier.com/blog/what-are-webhooks/\"\u003ethis article\u003c/a\u003e by Zapier.\u003c/p\u003e\n\u003cp\u003eLet's get started!\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003eSetting up the Slack App\u003c/h2\u003e\n\u003cp\u003eOpen Slack, click \u003cstrong\u003eAdd channels\u003c/strong\u003e, and create a new channel called \u003ccode\u003enotifications\u003c/code\u003e.  This is where our Slack app will post to once we set it up.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/slack-webhook/create-channel.jpg\" alt=\"Create a Slack channel {priority}{1004x580}\"\u003e\u003c/p\u003e\n\u003cp\u003eNow go to a web browser and head to https://api.slack.com/apps/.\u003c/p\u003e\n\u003cp\u003eClick on \u003cstrong\u003eCreate an App\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/slack-webhook/create-app.jpg\" alt=\"Create a Slack App {1004x497}\"\u003e\u003c/p\u003e\n\u003cp\u003eSelect \u003cstrong\u003eFrom scratch\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/slack-webhook/from-scratch.jpg\" alt=\"Select From Scratch {1004x497}\"\u003e\u003c/p\u003e\n\u003cp\u003eCreate a name for your app and select the workspace you just created your \u003ccode\u003enotifications\u003c/code\u003e channel in.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/slack-webhook/app-and-workspace.jpg\" alt=\"Choose an app name and workspace {1004x501}\"\u003e\u003c/p\u003e\n\u003cp\u003eThis will redirect you to the \u003cstrong\u003eBasic Information\u003c/strong\u003e tab for your app.  Here, we'll enable \u003cstrong\u003eIncoming Webhooks\u003c/strong\u003e.  As it states, this will enable us to post messages from an external source.  In this case, our platform.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/slack-webhook/add-webhooks.jpg\" alt=\"Enable incoming webhooks {1004x497}\"\u003e\u003c/p\u003e\n\u003cp\u003eTurn on \u003cstrong\u003eActivate Incoming Webhooks\u003c/strong\u003e and you will see additional details appear.  Towards the bottom, click on \u003cstrong\u003eAdd New Webhook to Workspace\u003c/strong\u003e.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/slack-webhook/add-new-webhook.jpg\" alt=\"Add a new webhook to your workspace {1004x485}\"\u003e\u003c/p\u003e\n\u003cp\u003eYou will be redirected again to select which channel to post to.  Select the \u003ccode\u003enotifications\u003c/code\u003e channel that we previously created and press \u003cstrong\u003eAllow\u003c/strong\u003e.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/slack-webhook/choose-channel.jpg\" alt=\"Select a channel for your app {1004x498}\"\u003e\u003c/p\u003e\n\u003cp\u003eThis will redirect you back to your app configuration and you will see a webhook URL you can now post to.  This will also include a simple curl POST request you can test with if you'd like.  Copy the webhook URL for later, and remember to \u003cstrong\u003ekeep it private\u003c/strong\u003e.  This is a public URL that anyone can post to.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/slack-webhook/copy-url.jpg\" alt=\"Copy your webhook URL {680x506}\"\u003e\u003c/p\u003e\n\u003cp\u003eYou can return to the \u003cstrong\u003eBasic Information\u003c/strong\u003e of your app settings in Slack to view more API credentials and also edit the look and feel of your new Slack bot.\u003c/p\u003e\n\u003cp\u003eNow we're ready to dive into the code to communicate with our webhook!\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003eCommunicating with our Webhook\u003c/h2\u003e\n\u003cp\u003eTo communicate with our webhook, we'll use the \u003ca href=\"https://docs.python-requests.org/en/master/\"\u003e\u003ccode\u003erequests\u003c/code\u003e\u003c/a\u003e Python library.  This is a third party library, so you'll want to have a Python virtual environment set up to handle your dependencies.  Virtual environments are out of the scope of this article, but you can read more on them \u003ca href=\"https://docs.python.org/3/tutorial/venv.html\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eInside your virtual environment, you can run the following to install the library.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003epip install requests\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eNow, we'll set up a class to communicate with our Slack endpoint.  We'll start by just sending a plain text message to Slack.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eimport logging\n\nimport requests\n\n\nlogger = logging.getLogger()\nlogger.setLevel(logging.INFO)\n\n\nclass SlackWebhookBot:\n    def __init__(self, webhook_url: str, timeout: int = 15):\n        \"\"\"Class to send messages to a provided Slack webhook URL.\n\n        You can read more about Slack's Incoming Webhooks here:\n            https://api.slack.com/messaging/webhooks\n        \n        Args:\n            webhook_url: The webhook URL to send a message to.  Typically\n                formatted like \"https://hooks.slack.com/services/...\".\n        \n        Kwargs:\n            timeout: Number of seconds before the request will timeout.\n                This is used to prevent a hang and is set to a default\n                value of 15 seconds.\n        \"\"\"\n        self.webhook_url = webhook_url\n        self.timeout = timeout\n        self.headers = {\n            'Content-Type': 'application/json',\n        }\n    \n\n    def send(self, message: str) -\u003e bool:\n        \"\"\"Sends a message to the webhook URL.\n\n        Per the Slack Incoming Webhook example.  The body of the request\n        (for plain text) should be formatted as follows:\n            `{\"text\": \"Hello, World!\"}`\n\n        Args:\n            message: Plain text string to send to Slack.\n\n        Returns:\n            A boolean representing if the request was successful.\n        \"\"\"\n        success = False\n        payload = {\n            'text': message,\n        }\n        try:\n            r = requests.post(\n                self.webhook_url,\n                headers=self.headers,\n                json=payload,\n                timeout=self.timeout\n            )\n        except requests.Timeout:\n            logger.error('Timeout occurred when trying to send message to Slack.')\n        except requests.RequestException as e:\n            logger.error(f'Error occurred when communicating with Slack: {e}.')\n        else:\n            success = True\n            logger.info('Successfully sent message to Slack.')\n\n        return success\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eAbove is the basic setup for communicating with the Slack webhook.  We can run a quick test by moving this code to a script and adding the following.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eimport os\n\nwebhook_url = os.environ.get('SLACK_WEBHOOK_URL')\nslack = SlackWebhookBot(webhook_url)\nslack.send('Hello, world!')\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eMake sure to set your Slack webhook URL to the \u003ccode\u003eSLACK_WEBHOOK_URL\u003c/code\u003e environment variable, and make sure you're in your virtual environment with the \u003ccode\u003erequests\u003c/code\u003e package installed before running the script.  This can be done on MacOS with the following.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eexport SLACK_WEBHOOK_URL=https://hooks.slack.com/services/...\npython slack_webhook.py\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eWhen you run this, you should see a message from you Slack bot appear in the \u003ccode\u003enotifications\u003c/code\u003e channel!\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/slack-webhook/slack-first-message.jpg\" alt=\"Hello world message in Slack {1004x675}\"\u003e\u003c/p\u003e\n\u003cp\u003eFor our notifications to be more helpful, we may want to add links or other formatting.  To do this, we will write our notifications with HTML tags, and then parse these tags and convert them to the \u003ca href=\"https://api.slack.com/reference/surfaces/formatting\"\u003eSlack flavored Markdown\u003c/a\u003e called \u003ccode\u003emrkdwn\u003c/code\u003e.\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003eAdding a simple HTML parser to our class\u003c/h2\u003e\n\u003cp\u003eFrom the \u003ca href=\"https://api.slack.com/reference/surfaces/formatting\"\u003eSlack formatting guide\u003c/a\u003e for messages, we can see all of the ways to format text in our messages.  For our purposes, we will focus on a primary list.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eMaking text \u003ccode\u003e_italicized_\u003c/code\u003e (\u003ccode\u003e\u0026#x3C;i\u003e\u003c/code\u003e)\u003c/li\u003e\n\u003cli\u003eMaking text \u003ccode\u003e*bold*\u003c/code\u003e (\u003ccode\u003e\u0026#x3C;b\u003e\u003c/code\u003e)\u003c/li\u003e\n\u003cli\u003eStriking through ~\u003ccode\u003etext\u003c/code\u003e~ (\u003ccode\u003e\u0026#x3C;strike\u003e\u003c/code\u003e)\u003c/li\u003e\n\u003cli\u003eAdding line breaks (\u003ccode\u003e\u0026#x3C;br\u003e\u003c/code\u003e)\u003c/li\u003e\n\u003cli\u003eAdding \u003ccode\u003eone-line code blocks\u003c/code\u003e using the backtick character (\u003ccode\u003e\u0026#x3C;code\u003e\u003c/code\u003e)\u003c/li\u003e\n\u003cli\u003eAdding unordered lists (line broken dashes) (\u003ccode\u003e\u0026#x3C;ul\u003e\u0026#x3C;li\u003e\u003c/code\u003e)\u003c/li\u003e\n\u003cli\u003eAdding external links \u003ccode\u003e\u0026#x3C;[external link]|[display text]\u003e\u003c/code\u003e (\u003ccode\u003e\u0026#x3C;a\u003e\u003c/code\u003e)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eAlso note that the Slack documentation says that \u003ca href=\"https://api.slack.com/reference/surfaces/formatting#escaping\"\u003ecertain characters need to be escaped\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eThere are a few more styles that could be implemented, but we'll focus on just this list for this post.\u003c/p\u003e\n\u003cp\u003eTo do this, we will utilize the \u003ca href=\"https://docs.python.org/3/library/html.html\"\u003e\u003ccode\u003ehtml\u003c/code\u003e\u003c/a\u003e module in the Python standard library to parse HTML tags, attributes, and values.\u003c/p\u003e\n\u003cp\u003eLet's write a class (we need to inherit functions for the \u003ccode\u003eHTMLParser\u003c/code\u003e class) where we will parse all of the tags and attributes, and escape the message text when needed.  The idea here is that we can construct a string from scratch and for each tag we care about we can \"replace\" the HTML tags with the relevant mrkdwn syntax.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003efrom html.parser import HTMLParser\nimport re\nfrom typing import Any, List, Tuple\n\n\nclass SlackHTMLParser(HTMLParser):\n    def __init__(self, *args, **kwargs):\n        \"\"\"Escapes and converts an HTML string to Slack flavored\n        Markdown (mrkdwn).\n\n        More about Slack's Markdown Flavor (mrkdwn) can be seen here:\n            https://api.slack.com/reference/surfaces/formatting\n        \n        Call using `SlackHTMLParser(message_body).parse()`.\n        \"\"\"\n        super().__init__(*args, **kwargs)\n        self.slack_message = ''\n        self.ignore_tag = False  # Used to skip tags we don't care about\n        self.line_break = '::LINE::BREAK::'  # Unique sequence for swapping a \u0026#x3C;br\u003e\n\n\n    def handle_starttag(self, tag: str, attrs: List[Tuple[str, Any]]):\n        \"\"\"Called when the opening of a tag is encountered.\n\n        The idea here is to swap out the tag with the respective mrkdwn\n        symbol.\n\n        Args:\n            tag: Lowercase name of the HTML tag.  E.G. `br` or `i`.\n            attrs: List of tuples with the tuple having the following form:\n                (attribute name, value).  E.G. ('href', 'www.example.com').\n        \"\"\"\n        if tag in ['i', 'em']:\n            self.slack_message += '_'\n        elif tag in ['b', 'strong']:\n            self.slack_message += '*'\n        elif tag == 'strike':\n            self.slack_message += '~'\n        elif tag in ['br', 'p', 'ul']:\n            self.slack_message += self.line_break\n        elif tag == 'li':\n            self.slack_message += f'{self.line_break}- '\n        elif tag == 'code':\n            self.slack_message += '`'\n        elif tag == 'a':\n            href = [x[1] for x in attrs if x[0] == 'href']\n            if len(href) \u003e 0:\n                self.slack_message += f'\u0026#x3C;{href[0]}|'\n        else:\n            self.ignore_tag = True\n\n\n    def handle_data(self, data: str):\n        \"\"\"Handles the data within a tag.\n\n        This is called after `handle_starttag` and before `handle_endtag`.\n\n        We will also escape the following text per Slack's documentation:\n        - '\u0026#x26;' -\u003e '\u0026#x26;amp;'\n        - '\u0026#x3C;' -\u003e '\u0026#x26;lt;'\n        - '\u003e' -\u003e '\u0026#x26;gt;'\n\n        Args:\n            data: The data/string within the HTML tag.\n        \"\"\"\n        if not self.ignore_tag:\n            self.slack_message += data\\\n                .replace('\u0026#x26;', '\u0026#x26;amp;')\\\n                .replace('\u0026#x3C;', '\u0026#x26;lt;')\\\n                .replace('\u003e', '\u0026#x26;gt;')\n\n\n    def handle_endtag(self, tag: str):\n        \"\"\"Called when the closing of a tag is encountered.\n\n        The idea here is to swap out the tag with the respective mrkdwn\n        symbol.  This is basically the same as the handle_starttag.\n\n        Args:\n            tag: Lowercase name of the HTML tag.  E.G. `br` or `i`.\n        \"\"\"\n        if tag in ['i', 'em']:\n            self.slack_message += '_'\n        elif tag in ['b', 'strong']:\n            self.slack_message += '*'\n        elif tag == 'strike':\n            self.slack_message += '~'\n        elif tag == 'p':\n            self.slack_message += self.line_break\n        elif tag == 'code':\n            self.slack_message += '`'\n        elif tag == 'a':\n            self.slack_message += '\u003e'\n        \n        self.ignore_tag = False\n\n\n    def parse(self, html_string: str) -\u003e str:\n        \"\"\"Parses a given HTML string and applies simple formatting.\n        \n        Note that we need to apply the line break replacing here\n        instead of with the handle tag methods.\n\n        Args:\n            html_string: The HTML string to convert to Slack mrkdwn.\n\n        Returns:\n            A formatted Slack mrkdwn string.\n        \"\"\"\n        self.feed(html_string)\n        return re.sub(\n            r'^(\\n)+',  # Remove the leading line breaks\n            '',\n            ' '.join(self.slack_message.split()).replace(self.line_break, '\\n')\n        )\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eWe can test our class out with the following code.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ehtml_string = '''\n    \u0026#x3C;p\u003e\n        Here \u0026#x3C;i\u003eis\u0026#x3C;/i\u003e a \u0026#x3C;strike\u003eparagraph\u0026#x3C;/strike\u003e with a \u0026#x3C;b\u003elot\u0026#x3C;/b\u003e of formatting.\n    \u0026#x3C;/p\u003e\n    \u0026#x3C;br\u003e\n    \u0026#x3C;code\u003eCode sample\u0026#x3C;/code\u003e \u0026#x26; testing escape.\n    \u0026#x3C;ul\u003e\n        \u0026#x3C;li\u003e\n            \u0026#x3C;a href=\"https://www.google.com\"\u003eGoogle\u0026#x3C;/a\u003e\n        \u0026#x3C;/li\u003e\n        \u0026#x3C;li\u003e\n            \u0026#x3C;a href=\"https://www.amazon.com\"\u003eAmazon\u0026#x3C;/a\u003e\n        \u0026#x3C;/li\u003e\n    \u0026#x3C;/ul\u003e\n'''\nparser = SlackHTMLParser()\nslack_message = parser.parse(html_string)\nprint(slack_message)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eNow we can test our formatter in an actual Slack message!  Import your formatter class or add it to your existing code so you're able to do the following.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ehtml_string = '''\n    \u0026#x3C;p\u003e\n        Here \u0026#x3C;i\u003eis\u0026#x3C;/i\u003e a \u0026#x3C;strike\u003eparagraph\u0026#x3C;/strike\u003e with a \u0026#x3C;b\u003elot\u0026#x3C;/b\u003e of formatting.\n    \u0026#x3C;/p\u003e\n    \u0026#x3C;br\u003e\n    \u0026#x3C;code\u003eCode sample\u0026#x3C;/code\u003e \u0026#x26; testing escape.\n    \u0026#x3C;ul\u003e\n        \u0026#x3C;li\u003e\n            \u0026#x3C;a href=\"https://www.google.com\"\u003eGoogle\u0026#x3C;/a\u003e\n        \u0026#x3C;/li\u003e\n        \u0026#x3C;li\u003e\n            \u0026#x3C;a href=\"https://www.amazon.com\"\u003eAmazon\u0026#x3C;/a\u003e\n        \u0026#x3C;/li\u003e\n    \u0026#x3C;/ul\u003e\n'''\nwebhook_url = os.environ.get('SLACK_WEBHOOK_URL')\nparser = SlackHTMLParser()\nslack_message = parser.parse(html_string)\nslack = SlackWebhookBot(webhook_url)\nslack.send(slack_message)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eYou should see the following message in your notifications channel.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/slack-webhook/slack-format-message.jpg\" alt=\"Second message in Slack {680x140}\"\u003e\u003c/p\u003e\n\u003cp\u003eLooks pretty good!  \u003cem\u003eNote that you can still send plain text messages, you don't need to use HTML.\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003eFor some final adjustments, you may have noticed that the message preview on the notification that popped up showed the actual \u003ccode\u003emrkdwn\u003c/code\u003e characters as opposed to a formatted notification.  This looks a little sloppy, so let's make a new notification title that is similar to an email subject line.\u003c/p\u003e\n\u003cp\u003eWe will briefly look at the basics of Slack's \u003ca href=\"https://api.slack.com/block-kit\"\u003eBlock Kit\u003c/a\u003e, which is a powerful way to add lots of customization to your Slack messages.  You can also explore Block Kit with Slack's \u003ca href=\"https://app.slack.com/block-kit-builder/\"\u003eBlock Kit Builder\u003c/a\u003e which provides a preview of your Slack message.\u003c/p\u003e\n\u003cp\u003eWithout diving too much into the details on the Block Kit, let's update our \u003ccode\u003eSlackWebhookBot\u003c/code\u003e class and add a method that adds a title block and a body block for our message.  Our subject line will appear in the notification itself, and also in the actual Slack message.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e# Add the `Dict` typing import to the existing typing imports\nfrom typing import Dict\n\ndef format_message(self, subject: str, body: str) -\u003e Dict:\n    \"\"\"Formats the subject and message body into Slack blocks.\n\n    Args:\n        subject: Subject that will appear on the notification popup.\n        body: The full message body.\n\n    Returns:\n        A dictionary payload with Slack block formatting.\n    \"\"\"\n    return {\n        'text': subject,\n        'blocks': [\n            {\n                'type': 'section',\n                'text': {\n                    'type': 'mrkdwn',\n                    'text': f'*{subject}*',\n                },\n            },\n            {\n                'type': 'section',\n                'text': {\n                    'type': 'mrkdwn',\n                    'text': body,\n                },\n            },\n        ],\n    }\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eNow we can tweak our \u003ccode\u003esend\u003c/code\u003e method to format a new message and accept a subject string as a Kwarg.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003edef send(self, message: str, subject: str = 'New message!') -\u003e bool:\n    \"\"\"Sends a formatted message to the webhook URL.\n\n    Args:\n        message: Plain text string to send to Slack.\n\n    Kwargs:\n        subject: The subject of the message that will appear in the notification\n            preview.\n\n    Returns:\n        A boolean representing if the request was successful.\n    \"\"\"\n    success = False\n    payload = self.format_message(subject, message)\n    try:\n        r = requests.post(\n            self.webhook_url,\n            headers=self.headers,\n            json=payload,\n            timeout=self.timeout\n        )\n    except requests.Timeout:\n        logger.error('Timeout occurred when trying to send message to Slack.')\n    except requests.RequestException as e:\n        logger.error(f'Error occurred when communicating with Slack: {e}.')\n    else:\n        success = True\n        logger.info('Successfully sent message to Slack.')\n\n    return success\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eAnd we can test our notification with a new subject line.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ehtml_string = '''\n    \u0026#x3C;p\u003e\n        Here \u0026#x3C;i\u003eis\u0026#x3C;/i\u003e a \u0026#x3C;strike\u003eparagraph\u0026#x3C;/strike\u003e with a \u0026#x3C;b\u003elot\u0026#x3C;/b\u003e of formatting.\n    \u0026#x3C;/p\u003e\n    \u0026#x3C;br\u003e\n    \u0026#x3C;code\u003eCode sample\u0026#x3C;/code\u003e \u0026#x26; testing escape.\n    \u0026#x3C;ul\u003e\n        \u0026#x3C;li\u003e\n            \u0026#x3C;a href=\"https://www.google.com\"\u003eGoogle\u0026#x3C;/a\u003e\n        \u0026#x3C;/li\u003e\n        \u0026#x3C;li\u003e\n            \u0026#x3C;a href=\"https://www.amazon.com\"\u003eAmazon\u0026#x3C;/a\u003e\n        \u0026#x3C;/li\u003e\n    \u0026#x3C;/ul\u003e\n'''\nwebhook_url = os.environ.get('SLACK_WEBHOOK_URL')\nparser = SlackHTMLParser()\nslack_message = parser.parse(html_string)\nslack = SlackWebhookBot(webhook_url)\nslack.send(slack_message, subject='You\\'ve completed the tutorial!')\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eYou should see a notification appear with the following preview\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/slack-webhook/slack-popup.jpg\" alt=\"Slack notification {453x101}\"\u003e\u003c/p\u003e\n\u003cp\u003eand the following message in your channel.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/slack-webhook/slack-last-message.jpg\" alt=\"Last message in Slack {680x159}\"\u003e\u003c/p\u003e\n\u003cp\u003eWe have a custom Slack notification app!  You can place the \u003ccode\u003esend\u003c/code\u003e message calls all across your applications with related messages and now you can have a better pulse on user activity that developers and any other employees/stakeholders can easily access.\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003eFor those wanting additional challenges or to continue developing their custom app, Slack has added a lot of really cool tools to the Block Kit.  There are a ton of really cool possibilities that can be added on by updating the \u003ccode\u003eformat_message\u003c/code\u003e method in our \u003ccode\u003eSlackWebhookBot\u003c/code\u003e class.\u003c/p\u003e\n\u003cp\u003eExplore the Slack's \u003ca href=\"https://app.slack.com/block-kit-builder/\"\u003eBlock Kit Builder\u003c/a\u003e and see what you can make!\u003c/p\u003e\n\u003chr\u003e\n","markdown":"\n## tl;dr\n\n### Goal\n_To set up a Slack webhook so we can send text and simple HTML notifications to receive in a Slack channel._\n\n### Process Overview\n1. Setting up a Slack webhook URL in your Slack workspace to post to a channel\n2. Posting a notification to our webhook\n3. Creating a simple HTML parser to match the custom Slack markdown flavor\n\n### Python Dependencies\n```python\n# Python standard library\nfrom html.parser import HTMLParser\nimport logging\nimport os\nimport re\nfrom typing import Any, List, Tuple\n\n# 3rd Party\nimport requests\n```\n\n### Assumptions\nI'll assume you have a Slack account, a Slack workspace setup, Slack is installed, and you have knowledge of Python with a basic understanding of webhooks.\n\n---\n\nIf you haven't heard of it before, [Slack](https://slack.com/) is a very popular team/workplace communication tool.  In addition to direct messaging, it allows you to separate discussion into various topics or **channels** for more focused team communication.\n\nAnother great feature of Slack is that you can add 3rd party [apps](https://slack.com/apps) (or integrations) from your existing stack, or even develop your own!  I have seen this streamline my own productivity, and I personally use a number of Slack apps.\n\nTo name a few, you may want to check out the following (assuming you use these tools) which I've found a lot of value in:\n- [Sentry](https://slack.com/apps/A011MFBJEUU-sentry?tab=more_info) - for application monitoring\n- [Google Calendar](https://slack.com/apps/ADZ494LHY-google-calendar?tab=more_info) - to stay on top of my meetings schedule\n- [GitHub](https://slack.com/apps/A01BP7R4KNY-github?tab=more_info) - getting notified of pull requests and meaningful changes to important repositories\n- [Jira Cloud](https://slack.com/apps/A2RPP3NFR-jira-cloud?tab=more_info) - staying on top of changes to Jira tickets\n- [AWS Chatbot](https://slack.com/apps/A6L22LZNH-aws-chatbot?tab=more_info) - alerts from CloudWatch alarms\n\nYou can browse the [Slack app directory](https://slack.com/apps) for more integrations.\n\nHowever, not every integration is going to provide the functionality you need.  This post will focus on creating our own custom Slack app with the goal of posting simple notifications to a Slack channel.\n\nA common use case where we can apply our app will be sending notifications when any sort of user activity happens on a platform.  As a developer, being notified of when a user completes a certain task can provide a lot of transparency and understanding into the usage of our application, while also keeping a sales teams informed on relevant activity on the platform.  This is the use case we'll focus on.\n\nWe will do this by posting to a webhook hosted by Slack.  For more information on webhooks, you can check out [this article](https://zapier.com/blog/what-are-webhooks/) by Zapier.\n\nLet's get started!\n\n---\n\n## Setting up the Slack App\nOpen Slack, click **Add channels**, and create a new channel called `notifications`.  This is where our Slack app will post to once we set it up.\n\n![Create a Slack channel {priority}{1004x580}](/images/slack-webhook/create-channel.jpg)\n\nNow go to a web browser and head to https://api.slack.com/apps/.\n\nClick on **Create an App**\n\n![Create a Slack App {1004x497}](/images/slack-webhook/create-app.jpg)\n\nSelect **From scratch**\n\n![Select From Scratch {1004x497}](/images/slack-webhook/from-scratch.jpg)\n\nCreate a name for your app and select the workspace you just created your `notifications` channel in.\n\n![Choose an app name and workspace {1004x501}](/images/slack-webhook/app-and-workspace.jpg)\n\n\nThis will redirect you to the **Basic Information** tab for your app.  Here, we'll enable **Incoming Webhooks**.  As it states, this will enable us to post messages from an external source.  In this case, our platform.\n\n![Enable incoming webhooks {1004x497}](/images/slack-webhook/add-webhooks.jpg)\n\n\nTurn on **Activate Incoming Webhooks** and you will see additional details appear.  Towards the bottom, click on **Add New Webhook to Workspace**.\n\n![Add a new webhook to your workspace {1004x485}](/images/slack-webhook/add-new-webhook.jpg)\n\nYou will be redirected again to select which channel to post to.  Select the `notifications` channel that we previously created and press **Allow**.\n\n![Select a channel for your app {1004x498}](/images/slack-webhook/choose-channel.jpg)\n\n\nThis will redirect you back to your app configuration and you will see a webhook URL you can now post to.  This will also include a simple curl POST request you can test with if you'd like.  Copy the webhook URL for later, and remember to **keep it private**.  This is a public URL that anyone can post to.\n\n![Copy your webhook URL {680x506}](/images/slack-webhook/copy-url.jpg)\n\n\nYou can return to the **Basic Information** of your app settings in Slack to view more API credentials and also edit the look and feel of your new Slack bot.\n\nNow we're ready to dive into the code to communicate with our webhook!\n\n---\n\n## Communicating with our Webhook\nTo communicate with our webhook, we'll use the [`requests`](https://docs.python-requests.org/en/master/) Python library.  This is a third party library, so you'll want to have a Python virtual environment set up to handle your dependencies.  Virtual environments are out of the scope of this article, but you can read more on them [here](https://docs.python.org/3/tutorial/venv.html).\n\nInside your virtual environment, you can run the following to install the library.\n```bash\npip install requests\n```\n\nNow, we'll set up a class to communicate with our Slack endpoint.  We'll start by just sending a plain text message to Slack.\n\n```python\nimport logging\n\nimport requests\n\n\nlogger = logging.getLogger()\nlogger.setLevel(logging.INFO)\n\n\nclass SlackWebhookBot:\n    def __init__(self, webhook_url: str, timeout: int = 15):\n        \"\"\"Class to send messages to a provided Slack webhook URL.\n\n        You can read more about Slack's Incoming Webhooks here:\n            https://api.slack.com/messaging/webhooks\n        \n        Args:\n            webhook_url: The webhook URL to send a message to.  Typically\n                formatted like \"https://hooks.slack.com/services/...\".\n        \n        Kwargs:\n            timeout: Number of seconds before the request will timeout.\n                This is used to prevent a hang and is set to a default\n                value of 15 seconds.\n        \"\"\"\n        self.webhook_url = webhook_url\n        self.timeout = timeout\n        self.headers = {\n            'Content-Type': 'application/json',\n        }\n    \n\n    def send(self, message: str) -\u003e bool:\n        \"\"\"Sends a message to the webhook URL.\n\n        Per the Slack Incoming Webhook example.  The body of the request\n        (for plain text) should be formatted as follows:\n            `{\"text\": \"Hello, World!\"}`\n\n        Args:\n            message: Plain text string to send to Slack.\n\n        Returns:\n            A boolean representing if the request was successful.\n        \"\"\"\n        success = False\n        payload = {\n            'text': message,\n        }\n        try:\n            r = requests.post(\n                self.webhook_url,\n                headers=self.headers,\n                json=payload,\n                timeout=self.timeout\n            )\n        except requests.Timeout:\n            logger.error('Timeout occurred when trying to send message to Slack.')\n        except requests.RequestException as e:\n            logger.error(f'Error occurred when communicating with Slack: {e}.')\n        else:\n            success = True\n            logger.info('Successfully sent message to Slack.')\n\n        return success\n```\n\nAbove is the basic setup for communicating with the Slack webhook.  We can run a quick test by moving this code to a script and adding the following.\n```python\nimport os\n\nwebhook_url = os.environ.get('SLACK_WEBHOOK_URL')\nslack = SlackWebhookBot(webhook_url)\nslack.send('Hello, world!')\n```\n\nMake sure to set your Slack webhook URL to the `SLACK_WEBHOOK_URL` environment variable, and make sure you're in your virtual environment with the `requests` package installed before running the script.  This can be done on MacOS with the following.\n```bash\nexport SLACK_WEBHOOK_URL=https://hooks.slack.com/services/...\npython slack_webhook.py\n```\n\nWhen you run this, you should see a message from you Slack bot appear in the `notifications` channel!\n\n![Hello world message in Slack {1004x675}](/images/slack-webhook/slack-first-message.jpg)\n\n\nFor our notifications to be more helpful, we may want to add links or other formatting.  To do this, we will write our notifications with HTML tags, and then parse these tags and convert them to the [Slack flavored Markdown](https://api.slack.com/reference/surfaces/formatting) called `mrkdwn`.\n\n---\n\n## Adding a simple HTML parser to our class\nFrom the [Slack formatting guide](https://api.slack.com/reference/surfaces/formatting) for messages, we can see all of the ways to format text in our messages.  For our purposes, we will focus on a primary list.\n\n- Making text \u003ci\u003e`_italicized_`\u003c/i\u003e (`\u003ci\u003e`)\n- Making text \u003cb\u003e`*bold*`\u003c/b\u003e (`\u003cb\u003e`)\n- Striking through ~\u003cstrike\u003e`text`\u003c/strike\u003e~ (`\u003cstrike\u003e`)\n- Adding line breaks (`\u003cbr\u003e`)\n- Adding `one-line code blocks` using the backtick character (`\u003ccode\u003e`)\n- Adding unordered lists (line broken dashes) (`\u003cul\u003e\u003cli\u003e`)\n- Adding external links `\u003c[external link]|[display text]\u003e` (`\u003ca\u003e`)\n\nAlso note that the Slack documentation says that [certain characters need to be escaped](https://api.slack.com/reference/surfaces/formatting#escaping).\n\nThere are a few more styles that could be implemented, but we'll focus on just this list for this post.\n\nTo do this, we will utilize the [`html`](https://docs.python.org/3/library/html.html) module in the Python standard library to parse HTML tags, attributes, and values.\n\nLet's write a class (we need to inherit functions for the `HTMLParser` class) where we will parse all of the tags and attributes, and escape the message text when needed.  The idea here is that we can construct a string from scratch and for each tag we care about we can \"replace\" the HTML tags with the relevant mrkdwn syntax.\n\n```python\nfrom html.parser import HTMLParser\nimport re\nfrom typing import Any, List, Tuple\n\n\nclass SlackHTMLParser(HTMLParser):\n    def __init__(self, *args, **kwargs):\n        \"\"\"Escapes and converts an HTML string to Slack flavored\n        Markdown (mrkdwn).\n\n        More about Slack's Markdown Flavor (mrkdwn) can be seen here:\n            https://api.slack.com/reference/surfaces/formatting\n        \n        Call using `SlackHTMLParser(message_body).parse()`.\n        \"\"\"\n        super().__init__(*args, **kwargs)\n        self.slack_message = ''\n        self.ignore_tag = False  # Used to skip tags we don't care about\n        self.line_break = '::LINE::BREAK::'  # Unique sequence for swapping a \u003cbr\u003e\n\n\n    def handle_starttag(self, tag: str, attrs: List[Tuple[str, Any]]):\n        \"\"\"Called when the opening of a tag is encountered.\n\n        The idea here is to swap out the tag with the respective mrkdwn\n        symbol.\n\n        Args:\n            tag: Lowercase name of the HTML tag.  E.G. `br` or `i`.\n            attrs: List of tuples with the tuple having the following form:\n                (attribute name, value).  E.G. ('href', 'www.example.com').\n        \"\"\"\n        if tag in ['i', 'em']:\n            self.slack_message += '_'\n        elif tag in ['b', 'strong']:\n            self.slack_message += '*'\n        elif tag == 'strike':\n            self.slack_message += '~'\n        elif tag in ['br', 'p', 'ul']:\n            self.slack_message += self.line_break\n        elif tag == 'li':\n            self.slack_message += f'{self.line_break}- '\n        elif tag == 'code':\n            self.slack_message += '`'\n        elif tag == 'a':\n            href = [x[1] for x in attrs if x[0] == 'href']\n            if len(href) \u003e 0:\n                self.slack_message += f'\u003c{href[0]}|'\n        else:\n            self.ignore_tag = True\n\n\n    def handle_data(self, data: str):\n        \"\"\"Handles the data within a tag.\n\n        This is called after `handle_starttag` and before `handle_endtag`.\n\n        We will also escape the following text per Slack's documentation:\n        - '\u0026' -\u003e '\u0026amp;'\n        - '\u003c' -\u003e '\u0026lt;'\n        - '\u003e' -\u003e '\u0026gt;'\n\n        Args:\n            data: The data/string within the HTML tag.\n        \"\"\"\n        if not self.ignore_tag:\n            self.slack_message += data\\\n                .replace('\u0026', '\u0026amp;')\\\n                .replace('\u003c', '\u0026lt;')\\\n                .replace('\u003e', '\u0026gt;')\n\n\n    def handle_endtag(self, tag: str):\n        \"\"\"Called when the closing of a tag is encountered.\n\n        The idea here is to swap out the tag with the respective mrkdwn\n        symbol.  This is basically the same as the handle_starttag.\n\n        Args:\n            tag: Lowercase name of the HTML tag.  E.G. `br` or `i`.\n        \"\"\"\n        if tag in ['i', 'em']:\n            self.slack_message += '_'\n        elif tag in ['b', 'strong']:\n            self.slack_message += '*'\n        elif tag == 'strike':\n            self.slack_message += '~'\n        elif tag == 'p':\n            self.slack_message += self.line_break\n        elif tag == 'code':\n            self.slack_message += '`'\n        elif tag == 'a':\n            self.slack_message += '\u003e'\n        \n        self.ignore_tag = False\n\n\n    def parse(self, html_string: str) -\u003e str:\n        \"\"\"Parses a given HTML string and applies simple formatting.\n        \n        Note that we need to apply the line break replacing here\n        instead of with the handle tag methods.\n\n        Args:\n            html_string: The HTML string to convert to Slack mrkdwn.\n\n        Returns:\n            A formatted Slack mrkdwn string.\n        \"\"\"\n        self.feed(html_string)\n        return re.sub(\n            r'^(\\n)+',  # Remove the leading line breaks\n            '',\n            ' '.join(self.slack_message.split()).replace(self.line_break, '\\n')\n        )\n```\n\nWe can test our class out with the following code.\n\n```python\nhtml_string = '''\n    \u003cp\u003e\n        Here \u003ci\u003eis\u003c/i\u003e a \u003cstrike\u003eparagraph\u003c/strike\u003e with a \u003cb\u003elot\u003c/b\u003e of formatting.\n    \u003c/p\u003e\n    \u003cbr\u003e\n    \u003ccode\u003eCode sample\u003c/code\u003e \u0026 testing escape.\n    \u003cul\u003e\n        \u003cli\u003e\n            \u003ca href=\"https://www.google.com\"\u003eGoogle\u003c/a\u003e\n        \u003c/li\u003e\n        \u003cli\u003e\n            \u003ca href=\"https://www.amazon.com\"\u003eAmazon\u003c/a\u003e\n        \u003c/li\u003e\n    \u003c/ul\u003e\n'''\nparser = SlackHTMLParser()\nslack_message = parser.parse(html_string)\nprint(slack_message)\n```\n\nNow we can test our formatter in an actual Slack message!  Import your formatter class or add it to your existing code so you're able to do the following.\n\n```python\nhtml_string = '''\n    \u003cp\u003e\n        Here \u003ci\u003eis\u003c/i\u003e a \u003cstrike\u003eparagraph\u003c/strike\u003e with a \u003cb\u003elot\u003c/b\u003e of formatting.\n    \u003c/p\u003e\n    \u003cbr\u003e\n    \u003ccode\u003eCode sample\u003c/code\u003e \u0026 testing escape.\n    \u003cul\u003e\n        \u003cli\u003e\n            \u003ca href=\"https://www.google.com\"\u003eGoogle\u003c/a\u003e\n        \u003c/li\u003e\n        \u003cli\u003e\n            \u003ca href=\"https://www.amazon.com\"\u003eAmazon\u003c/a\u003e\n        \u003c/li\u003e\n    \u003c/ul\u003e\n'''\nwebhook_url = os.environ.get('SLACK_WEBHOOK_URL')\nparser = SlackHTMLParser()\nslack_message = parser.parse(html_string)\nslack = SlackWebhookBot(webhook_url)\nslack.send(slack_message)\n```\n\nYou should see the following message in your notifications channel.\n\n![Second message in Slack {680x140}](/images/slack-webhook/slack-format-message.jpg)\n\nLooks pretty good!  _Note that you can still send plain text messages, you don't need to use HTML._\n\nFor some final adjustments, you may have noticed that the message preview on the notification that popped up showed the actual `mrkdwn` characters as opposed to a formatted notification.  This looks a little sloppy, so let's make a new notification title that is similar to an email subject line.\n\nWe will briefly look at the basics of Slack's [Block Kit](https://api.slack.com/block-kit), which is a powerful way to add lots of customization to your Slack messages.  You can also explore Block Kit with Slack's [Block Kit Builder](https://app.slack.com/block-kit-builder/) which provides a preview of your Slack message.\n\nWithout diving too much into the details on the Block Kit, let's update our `SlackWebhookBot` class and add a method that adds a title block and a body block for our message.  Our subject line will appear in the notification itself, and also in the actual Slack message.\n\n```python\n# Add the `Dict` typing import to the existing typing imports\nfrom typing import Dict\n\ndef format_message(self, subject: str, body: str) -\u003e Dict:\n    \"\"\"Formats the subject and message body into Slack blocks.\n\n    Args:\n        subject: Subject that will appear on the notification popup.\n        body: The full message body.\n\n    Returns:\n        A dictionary payload with Slack block formatting.\n    \"\"\"\n    return {\n        'text': subject,\n        'blocks': [\n            {\n                'type': 'section',\n                'text': {\n                    'type': 'mrkdwn',\n                    'text': f'*{subject}*',\n                },\n            },\n            {\n                'type': 'section',\n                'text': {\n                    'type': 'mrkdwn',\n                    'text': body,\n                },\n            },\n        ],\n    }\n```\n\nNow we can tweak our `send` method to format a new message and accept a subject string as a Kwarg.\n\n```python\ndef send(self, message: str, subject: str = 'New message!') -\u003e bool:\n    \"\"\"Sends a formatted message to the webhook URL.\n\n    Args:\n        message: Plain text string to send to Slack.\n\n    Kwargs:\n        subject: The subject of the message that will appear in the notification\n            preview.\n\n    Returns:\n        A boolean representing if the request was successful.\n    \"\"\"\n    success = False\n    payload = self.format_message(subject, message)\n    try:\n        r = requests.post(\n            self.webhook_url,\n            headers=self.headers,\n            json=payload,\n            timeout=self.timeout\n        )\n    except requests.Timeout:\n        logger.error('Timeout occurred when trying to send message to Slack.')\n    except requests.RequestException as e:\n        logger.error(f'Error occurred when communicating with Slack: {e}.')\n    else:\n        success = True\n        logger.info('Successfully sent message to Slack.')\n\n    return success\n```\n\nAnd we can test our notification with a new subject line.\n\n```python\nhtml_string = '''\n    \u003cp\u003e\n        Here \u003ci\u003eis\u003c/i\u003e a \u003cstrike\u003eparagraph\u003c/strike\u003e with a \u003cb\u003elot\u003c/b\u003e of formatting.\n    \u003c/p\u003e\n    \u003cbr\u003e\n    \u003ccode\u003eCode sample\u003c/code\u003e \u0026 testing escape.\n    \u003cul\u003e\n        \u003cli\u003e\n            \u003ca href=\"https://www.google.com\"\u003eGoogle\u003c/a\u003e\n        \u003c/li\u003e\n        \u003cli\u003e\n            \u003ca href=\"https://www.amazon.com\"\u003eAmazon\u003c/a\u003e\n        \u003c/li\u003e\n    \u003c/ul\u003e\n'''\nwebhook_url = os.environ.get('SLACK_WEBHOOK_URL')\nparser = SlackHTMLParser()\nslack_message = parser.parse(html_string)\nslack = SlackWebhookBot(webhook_url)\nslack.send(slack_message, subject='You\\'ve completed the tutorial!')\n```\n\nYou should see a notification appear with the following preview\n\n![Slack notification {453x101}](/images/slack-webhook/slack-popup.jpg)\n\n\nand the following message in your channel.\n\n![Last message in Slack {680x159}](/images/slack-webhook/slack-last-message.jpg)\n\n\nWe have a custom Slack notification app!  You can place the `send` message calls all across your applications with related messages and now you can have a better pulse on user activity that developers and any other employees/stakeholders can easily access.\n\n---\n\nFor those wanting additional challenges or to continue developing their custom app, Slack has added a lot of really cool tools to the Block Kit.  There are a ton of really cool possibilities that can be added on by updating the `format_message` method in our `SlackWebhookBot` class.\n\nExplore the Slack's [Block Kit Builder](https://app.slack.com/block-kit-builder/) and see what you can make!\n\n---\n","title":"Setting up a Slack webhook for simple notifications","date":"2021-07-11","tags":["python","slack","webhook","api"],"description":"Setting up a Slack webhook to send plain text or simple HTML notifications to a Slack channel."}],"api":[{"id":"slack-webhook","contentHtml":"\u003ch2\u003etl;dr\u003c/h2\u003e\n\u003ch3\u003eGoal\u003c/h3\u003e\n\u003cp\u003e\u003cem\u003eTo set up a Slack webhook so we can send text and simple HTML notifications to receive in a Slack channel.\u003c/em\u003e\u003c/p\u003e\n\u003ch3\u003eProcess Overview\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003eSetting up a Slack webhook URL in your Slack workspace to post to a channel\u003c/li\u003e\n\u003cli\u003ePosting a notification to our webhook\u003c/li\u003e\n\u003cli\u003eCreating a simple HTML parser to match the custom Slack markdown flavor\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3\u003ePython Dependencies\u003c/h3\u003e\n\u003cpre\u003e\u003ccode\u003e# Python standard library\nfrom html.parser import HTMLParser\nimport logging\nimport os\nimport re\nfrom typing import Any, List, Tuple\n\n# 3rd Party\nimport requests\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003eAssumptions\u003c/h3\u003e\n\u003cp\u003eI'll assume you have a Slack account, a Slack workspace setup, Slack is installed, and you have knowledge of Python with a basic understanding of webhooks.\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003eIf you haven't heard of it before, \u003ca href=\"https://slack.com/\"\u003eSlack\u003c/a\u003e is a very popular team/workplace communication tool.  In addition to direct messaging, it allows you to separate discussion into various topics or \u003cstrong\u003echannels\u003c/strong\u003e for more focused team communication.\u003c/p\u003e\n\u003cp\u003eAnother great feature of Slack is that you can add 3rd party \u003ca href=\"https://slack.com/apps\"\u003eapps\u003c/a\u003e (or integrations) from your existing stack, or even develop your own!  I have seen this streamline my own productivity, and I personally use a number of Slack apps.\u003c/p\u003e\n\u003cp\u003eTo name a few, you may want to check out the following (assuming you use these tools) which I've found a lot of value in:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://slack.com/apps/A011MFBJEUU-sentry?tab=more_info\"\u003eSentry\u003c/a\u003e - for application monitoring\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://slack.com/apps/ADZ494LHY-google-calendar?tab=more_info\"\u003eGoogle Calendar\u003c/a\u003e - to stay on top of my meetings schedule\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://slack.com/apps/A01BP7R4KNY-github?tab=more_info\"\u003eGitHub\u003c/a\u003e - getting notified of pull requests and meaningful changes to important repositories\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://slack.com/apps/A2RPP3NFR-jira-cloud?tab=more_info\"\u003eJira Cloud\u003c/a\u003e - staying on top of changes to Jira tickets\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://slack.com/apps/A6L22LZNH-aws-chatbot?tab=more_info\"\u003eAWS Chatbot\u003c/a\u003e - alerts from CloudWatch alarms\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eYou can browse the \u003ca href=\"https://slack.com/apps\"\u003eSlack app directory\u003c/a\u003e for more integrations.\u003c/p\u003e\n\u003cp\u003eHowever, not every integration is going to provide the functionality you need.  This post will focus on creating our own custom Slack app with the goal of posting simple notifications to a Slack channel.\u003c/p\u003e\n\u003cp\u003eA common use case where we can apply our app will be sending notifications when any sort of user activity happens on a platform.  As a developer, being notified of when a user completes a certain task can provide a lot of transparency and understanding into the usage of our application, while also keeping a sales teams informed on relevant activity on the platform.  This is the use case we'll focus on.\u003c/p\u003e\n\u003cp\u003eWe will do this by posting to a webhook hosted by Slack.  For more information on webhooks, you can check out \u003ca href=\"https://zapier.com/blog/what-are-webhooks/\"\u003ethis article\u003c/a\u003e by Zapier.\u003c/p\u003e\n\u003cp\u003eLet's get started!\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003eSetting up the Slack App\u003c/h2\u003e\n\u003cp\u003eOpen Slack, click \u003cstrong\u003eAdd channels\u003c/strong\u003e, and create a new channel called \u003ccode\u003enotifications\u003c/code\u003e.  This is where our Slack app will post to once we set it up.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/slack-webhook/create-channel.jpg\" alt=\"Create a Slack channel {priority}{1004x580}\"\u003e\u003c/p\u003e\n\u003cp\u003eNow go to a web browser and head to https://api.slack.com/apps/.\u003c/p\u003e\n\u003cp\u003eClick on \u003cstrong\u003eCreate an App\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/slack-webhook/create-app.jpg\" alt=\"Create a Slack App {1004x497}\"\u003e\u003c/p\u003e\n\u003cp\u003eSelect \u003cstrong\u003eFrom scratch\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/slack-webhook/from-scratch.jpg\" alt=\"Select From Scratch {1004x497}\"\u003e\u003c/p\u003e\n\u003cp\u003eCreate a name for your app and select the workspace you just created your \u003ccode\u003enotifications\u003c/code\u003e channel in.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/slack-webhook/app-and-workspace.jpg\" alt=\"Choose an app name and workspace {1004x501}\"\u003e\u003c/p\u003e\n\u003cp\u003eThis will redirect you to the \u003cstrong\u003eBasic Information\u003c/strong\u003e tab for your app.  Here, we'll enable \u003cstrong\u003eIncoming Webhooks\u003c/strong\u003e.  As it states, this will enable us to post messages from an external source.  In this case, our platform.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/slack-webhook/add-webhooks.jpg\" alt=\"Enable incoming webhooks {1004x497}\"\u003e\u003c/p\u003e\n\u003cp\u003eTurn on \u003cstrong\u003eActivate Incoming Webhooks\u003c/strong\u003e and you will see additional details appear.  Towards the bottom, click on \u003cstrong\u003eAdd New Webhook to Workspace\u003c/strong\u003e.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/slack-webhook/add-new-webhook.jpg\" alt=\"Add a new webhook to your workspace {1004x485}\"\u003e\u003c/p\u003e\n\u003cp\u003eYou will be redirected again to select which channel to post to.  Select the \u003ccode\u003enotifications\u003c/code\u003e channel that we previously created and press \u003cstrong\u003eAllow\u003c/strong\u003e.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/slack-webhook/choose-channel.jpg\" alt=\"Select a channel for your app {1004x498}\"\u003e\u003c/p\u003e\n\u003cp\u003eThis will redirect you back to your app configuration and you will see a webhook URL you can now post to.  This will also include a simple curl POST request you can test with if you'd like.  Copy the webhook URL for later, and remember to \u003cstrong\u003ekeep it private\u003c/strong\u003e.  This is a public URL that anyone can post to.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/slack-webhook/copy-url.jpg\" alt=\"Copy your webhook URL {680x506}\"\u003e\u003c/p\u003e\n\u003cp\u003eYou can return to the \u003cstrong\u003eBasic Information\u003c/strong\u003e of your app settings in Slack to view more API credentials and also edit the look and feel of your new Slack bot.\u003c/p\u003e\n\u003cp\u003eNow we're ready to dive into the code to communicate with our webhook!\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003eCommunicating with our Webhook\u003c/h2\u003e\n\u003cp\u003eTo communicate with our webhook, we'll use the \u003ca href=\"https://docs.python-requests.org/en/master/\"\u003e\u003ccode\u003erequests\u003c/code\u003e\u003c/a\u003e Python library.  This is a third party library, so you'll want to have a Python virtual environment set up to handle your dependencies.  Virtual environments are out of the scope of this article, but you can read more on them \u003ca href=\"https://docs.python.org/3/tutorial/venv.html\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eInside your virtual environment, you can run the following to install the library.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003epip install requests\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eNow, we'll set up a class to communicate with our Slack endpoint.  We'll start by just sending a plain text message to Slack.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eimport logging\n\nimport requests\n\n\nlogger = logging.getLogger()\nlogger.setLevel(logging.INFO)\n\n\nclass SlackWebhookBot:\n    def __init__(self, webhook_url: str, timeout: int = 15):\n        \"\"\"Class to send messages to a provided Slack webhook URL.\n\n        You can read more about Slack's Incoming Webhooks here:\n            https://api.slack.com/messaging/webhooks\n        \n        Args:\n            webhook_url: The webhook URL to send a message to.  Typically\n                formatted like \"https://hooks.slack.com/services/...\".\n        \n        Kwargs:\n            timeout: Number of seconds before the request will timeout.\n                This is used to prevent a hang and is set to a default\n                value of 15 seconds.\n        \"\"\"\n        self.webhook_url = webhook_url\n        self.timeout = timeout\n        self.headers = {\n            'Content-Type': 'application/json',\n        }\n    \n\n    def send(self, message: str) -\u003e bool:\n        \"\"\"Sends a message to the webhook URL.\n\n        Per the Slack Incoming Webhook example.  The body of the request\n        (for plain text) should be formatted as follows:\n            `{\"text\": \"Hello, World!\"}`\n\n        Args:\n            message: Plain text string to send to Slack.\n\n        Returns:\n            A boolean representing if the request was successful.\n        \"\"\"\n        success = False\n        payload = {\n            'text': message,\n        }\n        try:\n            r = requests.post(\n                self.webhook_url,\n                headers=self.headers,\n                json=payload,\n                timeout=self.timeout\n            )\n        except requests.Timeout:\n            logger.error('Timeout occurred when trying to send message to Slack.')\n        except requests.RequestException as e:\n            logger.error(f'Error occurred when communicating with Slack: {e}.')\n        else:\n            success = True\n            logger.info('Successfully sent message to Slack.')\n\n        return success\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eAbove is the basic setup for communicating with the Slack webhook.  We can run a quick test by moving this code to a script and adding the following.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eimport os\n\nwebhook_url = os.environ.get('SLACK_WEBHOOK_URL')\nslack = SlackWebhookBot(webhook_url)\nslack.send('Hello, world!')\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eMake sure to set your Slack webhook URL to the \u003ccode\u003eSLACK_WEBHOOK_URL\u003c/code\u003e environment variable, and make sure you're in your virtual environment with the \u003ccode\u003erequests\u003c/code\u003e package installed before running the script.  This can be done on MacOS with the following.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eexport SLACK_WEBHOOK_URL=https://hooks.slack.com/services/...\npython slack_webhook.py\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eWhen you run this, you should see a message from you Slack bot appear in the \u003ccode\u003enotifications\u003c/code\u003e channel!\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/slack-webhook/slack-first-message.jpg\" alt=\"Hello world message in Slack {1004x675}\"\u003e\u003c/p\u003e\n\u003cp\u003eFor our notifications to be more helpful, we may want to add links or other formatting.  To do this, we will write our notifications with HTML tags, and then parse these tags and convert them to the \u003ca href=\"https://api.slack.com/reference/surfaces/formatting\"\u003eSlack flavored Markdown\u003c/a\u003e called \u003ccode\u003emrkdwn\u003c/code\u003e.\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003eAdding a simple HTML parser to our class\u003c/h2\u003e\n\u003cp\u003eFrom the \u003ca href=\"https://api.slack.com/reference/surfaces/formatting\"\u003eSlack formatting guide\u003c/a\u003e for messages, we can see all of the ways to format text in our messages.  For our purposes, we will focus on a primary list.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eMaking text \u003ccode\u003e_italicized_\u003c/code\u003e (\u003ccode\u003e\u0026#x3C;i\u003e\u003c/code\u003e)\u003c/li\u003e\n\u003cli\u003eMaking text \u003ccode\u003e*bold*\u003c/code\u003e (\u003ccode\u003e\u0026#x3C;b\u003e\u003c/code\u003e)\u003c/li\u003e\n\u003cli\u003eStriking through ~\u003ccode\u003etext\u003c/code\u003e~ (\u003ccode\u003e\u0026#x3C;strike\u003e\u003c/code\u003e)\u003c/li\u003e\n\u003cli\u003eAdding line breaks (\u003ccode\u003e\u0026#x3C;br\u003e\u003c/code\u003e)\u003c/li\u003e\n\u003cli\u003eAdding \u003ccode\u003eone-line code blocks\u003c/code\u003e using the backtick character (\u003ccode\u003e\u0026#x3C;code\u003e\u003c/code\u003e)\u003c/li\u003e\n\u003cli\u003eAdding unordered lists (line broken dashes) (\u003ccode\u003e\u0026#x3C;ul\u003e\u0026#x3C;li\u003e\u003c/code\u003e)\u003c/li\u003e\n\u003cli\u003eAdding external links \u003ccode\u003e\u0026#x3C;[external link]|[display text]\u003e\u003c/code\u003e (\u003ccode\u003e\u0026#x3C;a\u003e\u003c/code\u003e)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eAlso note that the Slack documentation says that \u003ca href=\"https://api.slack.com/reference/surfaces/formatting#escaping\"\u003ecertain characters need to be escaped\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eThere are a few more styles that could be implemented, but we'll focus on just this list for this post.\u003c/p\u003e\n\u003cp\u003eTo do this, we will utilize the \u003ca href=\"https://docs.python.org/3/library/html.html\"\u003e\u003ccode\u003ehtml\u003c/code\u003e\u003c/a\u003e module in the Python standard library to parse HTML tags, attributes, and values.\u003c/p\u003e\n\u003cp\u003eLet's write a class (we need to inherit functions for the \u003ccode\u003eHTMLParser\u003c/code\u003e class) where we will parse all of the tags and attributes, and escape the message text when needed.  The idea here is that we can construct a string from scratch and for each tag we care about we can \"replace\" the HTML tags with the relevant mrkdwn syntax.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003efrom html.parser import HTMLParser\nimport re\nfrom typing import Any, List, Tuple\n\n\nclass SlackHTMLParser(HTMLParser):\n    def __init__(self, *args, **kwargs):\n        \"\"\"Escapes and converts an HTML string to Slack flavored\n        Markdown (mrkdwn).\n\n        More about Slack's Markdown Flavor (mrkdwn) can be seen here:\n            https://api.slack.com/reference/surfaces/formatting\n        \n        Call using `SlackHTMLParser(message_body).parse()`.\n        \"\"\"\n        super().__init__(*args, **kwargs)\n        self.slack_message = ''\n        self.ignore_tag = False  # Used to skip tags we don't care about\n        self.line_break = '::LINE::BREAK::'  # Unique sequence for swapping a \u0026#x3C;br\u003e\n\n\n    def handle_starttag(self, tag: str, attrs: List[Tuple[str, Any]]):\n        \"\"\"Called when the opening of a tag is encountered.\n\n        The idea here is to swap out the tag with the respective mrkdwn\n        symbol.\n\n        Args:\n            tag: Lowercase name of the HTML tag.  E.G. `br` or `i`.\n            attrs: List of tuples with the tuple having the following form:\n                (attribute name, value).  E.G. ('href', 'www.example.com').\n        \"\"\"\n        if tag in ['i', 'em']:\n            self.slack_message += '_'\n        elif tag in ['b', 'strong']:\n            self.slack_message += '*'\n        elif tag == 'strike':\n            self.slack_message += '~'\n        elif tag in ['br', 'p', 'ul']:\n            self.slack_message += self.line_break\n        elif tag == 'li':\n            self.slack_message += f'{self.line_break}- '\n        elif tag == 'code':\n            self.slack_message += '`'\n        elif tag == 'a':\n            href = [x[1] for x in attrs if x[0] == 'href']\n            if len(href) \u003e 0:\n                self.slack_message += f'\u0026#x3C;{href[0]}|'\n        else:\n            self.ignore_tag = True\n\n\n    def handle_data(self, data: str):\n        \"\"\"Handles the data within a tag.\n\n        This is called after `handle_starttag` and before `handle_endtag`.\n\n        We will also escape the following text per Slack's documentation:\n        - '\u0026#x26;' -\u003e '\u0026#x26;amp;'\n        - '\u0026#x3C;' -\u003e '\u0026#x26;lt;'\n        - '\u003e' -\u003e '\u0026#x26;gt;'\n\n        Args:\n            data: The data/string within the HTML tag.\n        \"\"\"\n        if not self.ignore_tag:\n            self.slack_message += data\\\n                .replace('\u0026#x26;', '\u0026#x26;amp;')\\\n                .replace('\u0026#x3C;', '\u0026#x26;lt;')\\\n                .replace('\u003e', '\u0026#x26;gt;')\n\n\n    def handle_endtag(self, tag: str):\n        \"\"\"Called when the closing of a tag is encountered.\n\n        The idea here is to swap out the tag with the respective mrkdwn\n        symbol.  This is basically the same as the handle_starttag.\n\n        Args:\n            tag: Lowercase name of the HTML tag.  E.G. `br` or `i`.\n        \"\"\"\n        if tag in ['i', 'em']:\n            self.slack_message += '_'\n        elif tag in ['b', 'strong']:\n            self.slack_message += '*'\n        elif tag == 'strike':\n            self.slack_message += '~'\n        elif tag == 'p':\n            self.slack_message += self.line_break\n        elif tag == 'code':\n            self.slack_message += '`'\n        elif tag == 'a':\n            self.slack_message += '\u003e'\n        \n        self.ignore_tag = False\n\n\n    def parse(self, html_string: str) -\u003e str:\n        \"\"\"Parses a given HTML string and applies simple formatting.\n        \n        Note that we need to apply the line break replacing here\n        instead of with the handle tag methods.\n\n        Args:\n            html_string: The HTML string to convert to Slack mrkdwn.\n\n        Returns:\n            A formatted Slack mrkdwn string.\n        \"\"\"\n        self.feed(html_string)\n        return re.sub(\n            r'^(\\n)+',  # Remove the leading line breaks\n            '',\n            ' '.join(self.slack_message.split()).replace(self.line_break, '\\n')\n        )\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eWe can test our class out with the following code.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ehtml_string = '''\n    \u0026#x3C;p\u003e\n        Here \u0026#x3C;i\u003eis\u0026#x3C;/i\u003e a \u0026#x3C;strike\u003eparagraph\u0026#x3C;/strike\u003e with a \u0026#x3C;b\u003elot\u0026#x3C;/b\u003e of formatting.\n    \u0026#x3C;/p\u003e\n    \u0026#x3C;br\u003e\n    \u0026#x3C;code\u003eCode sample\u0026#x3C;/code\u003e \u0026#x26; testing escape.\n    \u0026#x3C;ul\u003e\n        \u0026#x3C;li\u003e\n            \u0026#x3C;a href=\"https://www.google.com\"\u003eGoogle\u0026#x3C;/a\u003e\n        \u0026#x3C;/li\u003e\n        \u0026#x3C;li\u003e\n            \u0026#x3C;a href=\"https://www.amazon.com\"\u003eAmazon\u0026#x3C;/a\u003e\n        \u0026#x3C;/li\u003e\n    \u0026#x3C;/ul\u003e\n'''\nparser = SlackHTMLParser()\nslack_message = parser.parse(html_string)\nprint(slack_message)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eNow we can test our formatter in an actual Slack message!  Import your formatter class or add it to your existing code so you're able to do the following.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ehtml_string = '''\n    \u0026#x3C;p\u003e\n        Here \u0026#x3C;i\u003eis\u0026#x3C;/i\u003e a \u0026#x3C;strike\u003eparagraph\u0026#x3C;/strike\u003e with a \u0026#x3C;b\u003elot\u0026#x3C;/b\u003e of formatting.\n    \u0026#x3C;/p\u003e\n    \u0026#x3C;br\u003e\n    \u0026#x3C;code\u003eCode sample\u0026#x3C;/code\u003e \u0026#x26; testing escape.\n    \u0026#x3C;ul\u003e\n        \u0026#x3C;li\u003e\n            \u0026#x3C;a href=\"https://www.google.com\"\u003eGoogle\u0026#x3C;/a\u003e\n        \u0026#x3C;/li\u003e\n        \u0026#x3C;li\u003e\n            \u0026#x3C;a href=\"https://www.amazon.com\"\u003eAmazon\u0026#x3C;/a\u003e\n        \u0026#x3C;/li\u003e\n    \u0026#x3C;/ul\u003e\n'''\nwebhook_url = os.environ.get('SLACK_WEBHOOK_URL')\nparser = SlackHTMLParser()\nslack_message = parser.parse(html_string)\nslack = SlackWebhookBot(webhook_url)\nslack.send(slack_message)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eYou should see the following message in your notifications channel.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/slack-webhook/slack-format-message.jpg\" alt=\"Second message in Slack {680x140}\"\u003e\u003c/p\u003e\n\u003cp\u003eLooks pretty good!  \u003cem\u003eNote that you can still send plain text messages, you don't need to use HTML.\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003eFor some final adjustments, you may have noticed that the message preview on the notification that popped up showed the actual \u003ccode\u003emrkdwn\u003c/code\u003e characters as opposed to a formatted notification.  This looks a little sloppy, so let's make a new notification title that is similar to an email subject line.\u003c/p\u003e\n\u003cp\u003eWe will briefly look at the basics of Slack's \u003ca href=\"https://api.slack.com/block-kit\"\u003eBlock Kit\u003c/a\u003e, which is a powerful way to add lots of customization to your Slack messages.  You can also explore Block Kit with Slack's \u003ca href=\"https://app.slack.com/block-kit-builder/\"\u003eBlock Kit Builder\u003c/a\u003e which provides a preview of your Slack message.\u003c/p\u003e\n\u003cp\u003eWithout diving too much into the details on the Block Kit, let's update our \u003ccode\u003eSlackWebhookBot\u003c/code\u003e class and add a method that adds a title block and a body block for our message.  Our subject line will appear in the notification itself, and also in the actual Slack message.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e# Add the `Dict` typing import to the existing typing imports\nfrom typing import Dict\n\ndef format_message(self, subject: str, body: str) -\u003e Dict:\n    \"\"\"Formats the subject and message body into Slack blocks.\n\n    Args:\n        subject: Subject that will appear on the notification popup.\n        body: The full message body.\n\n    Returns:\n        A dictionary payload with Slack block formatting.\n    \"\"\"\n    return {\n        'text': subject,\n        'blocks': [\n            {\n                'type': 'section',\n                'text': {\n                    'type': 'mrkdwn',\n                    'text': f'*{subject}*',\n                },\n            },\n            {\n                'type': 'section',\n                'text': {\n                    'type': 'mrkdwn',\n                    'text': body,\n                },\n            },\n        ],\n    }\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eNow we can tweak our \u003ccode\u003esend\u003c/code\u003e method to format a new message and accept a subject string as a Kwarg.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003edef send(self, message: str, subject: str = 'New message!') -\u003e bool:\n    \"\"\"Sends a formatted message to the webhook URL.\n\n    Args:\n        message: Plain text string to send to Slack.\n\n    Kwargs:\n        subject: The subject of the message that will appear in the notification\n            preview.\n\n    Returns:\n        A boolean representing if the request was successful.\n    \"\"\"\n    success = False\n    payload = self.format_message(subject, message)\n    try:\n        r = requests.post(\n            self.webhook_url,\n            headers=self.headers,\n            json=payload,\n            timeout=self.timeout\n        )\n    except requests.Timeout:\n        logger.error('Timeout occurred when trying to send message to Slack.')\n    except requests.RequestException as e:\n        logger.error(f'Error occurred when communicating with Slack: {e}.')\n    else:\n        success = True\n        logger.info('Successfully sent message to Slack.')\n\n    return success\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eAnd we can test our notification with a new subject line.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ehtml_string = '''\n    \u0026#x3C;p\u003e\n        Here \u0026#x3C;i\u003eis\u0026#x3C;/i\u003e a \u0026#x3C;strike\u003eparagraph\u0026#x3C;/strike\u003e with a \u0026#x3C;b\u003elot\u0026#x3C;/b\u003e of formatting.\n    \u0026#x3C;/p\u003e\n    \u0026#x3C;br\u003e\n    \u0026#x3C;code\u003eCode sample\u0026#x3C;/code\u003e \u0026#x26; testing escape.\n    \u0026#x3C;ul\u003e\n        \u0026#x3C;li\u003e\n            \u0026#x3C;a href=\"https://www.google.com\"\u003eGoogle\u0026#x3C;/a\u003e\n        \u0026#x3C;/li\u003e\n        \u0026#x3C;li\u003e\n            \u0026#x3C;a href=\"https://www.amazon.com\"\u003eAmazon\u0026#x3C;/a\u003e\n        \u0026#x3C;/li\u003e\n    \u0026#x3C;/ul\u003e\n'''\nwebhook_url = os.environ.get('SLACK_WEBHOOK_URL')\nparser = SlackHTMLParser()\nslack_message = parser.parse(html_string)\nslack = SlackWebhookBot(webhook_url)\nslack.send(slack_message, subject='You\\'ve completed the tutorial!')\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eYou should see a notification appear with the following preview\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/slack-webhook/slack-popup.jpg\" alt=\"Slack notification {453x101}\"\u003e\u003c/p\u003e\n\u003cp\u003eand the following message in your channel.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/slack-webhook/slack-last-message.jpg\" alt=\"Last message in Slack {680x159}\"\u003e\u003c/p\u003e\n\u003cp\u003eWe have a custom Slack notification app!  You can place the \u003ccode\u003esend\u003c/code\u003e message calls all across your applications with related messages and now you can have a better pulse on user activity that developers and any other employees/stakeholders can easily access.\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003eFor those wanting additional challenges or to continue developing their custom app, Slack has added a lot of really cool tools to the Block Kit.  There are a ton of really cool possibilities that can be added on by updating the \u003ccode\u003eformat_message\u003c/code\u003e method in our \u003ccode\u003eSlackWebhookBot\u003c/code\u003e class.\u003c/p\u003e\n\u003cp\u003eExplore the Slack's \u003ca href=\"https://app.slack.com/block-kit-builder/\"\u003eBlock Kit Builder\u003c/a\u003e and see what you can make!\u003c/p\u003e\n\u003chr\u003e\n","markdown":"\n## tl;dr\n\n### Goal\n_To set up a Slack webhook so we can send text and simple HTML notifications to receive in a Slack channel._\n\n### Process Overview\n1. Setting up a Slack webhook URL in your Slack workspace to post to a channel\n2. Posting a notification to our webhook\n3. Creating a simple HTML parser to match the custom Slack markdown flavor\n\n### Python Dependencies\n```python\n# Python standard library\nfrom html.parser import HTMLParser\nimport logging\nimport os\nimport re\nfrom typing import Any, List, Tuple\n\n# 3rd Party\nimport requests\n```\n\n### Assumptions\nI'll assume you have a Slack account, a Slack workspace setup, Slack is installed, and you have knowledge of Python with a basic understanding of webhooks.\n\n---\n\nIf you haven't heard of it before, [Slack](https://slack.com/) is a very popular team/workplace communication tool.  In addition to direct messaging, it allows you to separate discussion into various topics or **channels** for more focused team communication.\n\nAnother great feature of Slack is that you can add 3rd party [apps](https://slack.com/apps) (or integrations) from your existing stack, or even develop your own!  I have seen this streamline my own productivity, and I personally use a number of Slack apps.\n\nTo name a few, you may want to check out the following (assuming you use these tools) which I've found a lot of value in:\n- [Sentry](https://slack.com/apps/A011MFBJEUU-sentry?tab=more_info) - for application monitoring\n- [Google Calendar](https://slack.com/apps/ADZ494LHY-google-calendar?tab=more_info) - to stay on top of my meetings schedule\n- [GitHub](https://slack.com/apps/A01BP7R4KNY-github?tab=more_info) - getting notified of pull requests and meaningful changes to important repositories\n- [Jira Cloud](https://slack.com/apps/A2RPP3NFR-jira-cloud?tab=more_info) - staying on top of changes to Jira tickets\n- [AWS Chatbot](https://slack.com/apps/A6L22LZNH-aws-chatbot?tab=more_info) - alerts from CloudWatch alarms\n\nYou can browse the [Slack app directory](https://slack.com/apps) for more integrations.\n\nHowever, not every integration is going to provide the functionality you need.  This post will focus on creating our own custom Slack app with the goal of posting simple notifications to a Slack channel.\n\nA common use case where we can apply our app will be sending notifications when any sort of user activity happens on a platform.  As a developer, being notified of when a user completes a certain task can provide a lot of transparency and understanding into the usage of our application, while also keeping a sales teams informed on relevant activity on the platform.  This is the use case we'll focus on.\n\nWe will do this by posting to a webhook hosted by Slack.  For more information on webhooks, you can check out [this article](https://zapier.com/blog/what-are-webhooks/) by Zapier.\n\nLet's get started!\n\n---\n\n## Setting up the Slack App\nOpen Slack, click **Add channels**, and create a new channel called `notifications`.  This is where our Slack app will post to once we set it up.\n\n![Create a Slack channel {priority}{1004x580}](/images/slack-webhook/create-channel.jpg)\n\nNow go to a web browser and head to https://api.slack.com/apps/.\n\nClick on **Create an App**\n\n![Create a Slack App {1004x497}](/images/slack-webhook/create-app.jpg)\n\nSelect **From scratch**\n\n![Select From Scratch {1004x497}](/images/slack-webhook/from-scratch.jpg)\n\nCreate a name for your app and select the workspace you just created your `notifications` channel in.\n\n![Choose an app name and workspace {1004x501}](/images/slack-webhook/app-and-workspace.jpg)\n\n\nThis will redirect you to the **Basic Information** tab for your app.  Here, we'll enable **Incoming Webhooks**.  As it states, this will enable us to post messages from an external source.  In this case, our platform.\n\n![Enable incoming webhooks {1004x497}](/images/slack-webhook/add-webhooks.jpg)\n\n\nTurn on **Activate Incoming Webhooks** and you will see additional details appear.  Towards the bottom, click on **Add New Webhook to Workspace**.\n\n![Add a new webhook to your workspace {1004x485}](/images/slack-webhook/add-new-webhook.jpg)\n\nYou will be redirected again to select which channel to post to.  Select the `notifications` channel that we previously created and press **Allow**.\n\n![Select a channel for your app {1004x498}](/images/slack-webhook/choose-channel.jpg)\n\n\nThis will redirect you back to your app configuration and you will see a webhook URL you can now post to.  This will also include a simple curl POST request you can test with if you'd like.  Copy the webhook URL for later, and remember to **keep it private**.  This is a public URL that anyone can post to.\n\n![Copy your webhook URL {680x506}](/images/slack-webhook/copy-url.jpg)\n\n\nYou can return to the **Basic Information** of your app settings in Slack to view more API credentials and also edit the look and feel of your new Slack bot.\n\nNow we're ready to dive into the code to communicate with our webhook!\n\n---\n\n## Communicating with our Webhook\nTo communicate with our webhook, we'll use the [`requests`](https://docs.python-requests.org/en/master/) Python library.  This is a third party library, so you'll want to have a Python virtual environment set up to handle your dependencies.  Virtual environments are out of the scope of this article, but you can read more on them [here](https://docs.python.org/3/tutorial/venv.html).\n\nInside your virtual environment, you can run the following to install the library.\n```bash\npip install requests\n```\n\nNow, we'll set up a class to communicate with our Slack endpoint.  We'll start by just sending a plain text message to Slack.\n\n```python\nimport logging\n\nimport requests\n\n\nlogger = logging.getLogger()\nlogger.setLevel(logging.INFO)\n\n\nclass SlackWebhookBot:\n    def __init__(self, webhook_url: str, timeout: int = 15):\n        \"\"\"Class to send messages to a provided Slack webhook URL.\n\n        You can read more about Slack's Incoming Webhooks here:\n            https://api.slack.com/messaging/webhooks\n        \n        Args:\n            webhook_url: The webhook URL to send a message to.  Typically\n                formatted like \"https://hooks.slack.com/services/...\".\n        \n        Kwargs:\n            timeout: Number of seconds before the request will timeout.\n                This is used to prevent a hang and is set to a default\n                value of 15 seconds.\n        \"\"\"\n        self.webhook_url = webhook_url\n        self.timeout = timeout\n        self.headers = {\n            'Content-Type': 'application/json',\n        }\n    \n\n    def send(self, message: str) -\u003e bool:\n        \"\"\"Sends a message to the webhook URL.\n\n        Per the Slack Incoming Webhook example.  The body of the request\n        (for plain text) should be formatted as follows:\n            `{\"text\": \"Hello, World!\"}`\n\n        Args:\n            message: Plain text string to send to Slack.\n\n        Returns:\n            A boolean representing if the request was successful.\n        \"\"\"\n        success = False\n        payload = {\n            'text': message,\n        }\n        try:\n            r = requests.post(\n                self.webhook_url,\n                headers=self.headers,\n                json=payload,\n                timeout=self.timeout\n            )\n        except requests.Timeout:\n            logger.error('Timeout occurred when trying to send message to Slack.')\n        except requests.RequestException as e:\n            logger.error(f'Error occurred when communicating with Slack: {e}.')\n        else:\n            success = True\n            logger.info('Successfully sent message to Slack.')\n\n        return success\n```\n\nAbove is the basic setup for communicating with the Slack webhook.  We can run a quick test by moving this code to a script and adding the following.\n```python\nimport os\n\nwebhook_url = os.environ.get('SLACK_WEBHOOK_URL')\nslack = SlackWebhookBot(webhook_url)\nslack.send('Hello, world!')\n```\n\nMake sure to set your Slack webhook URL to the `SLACK_WEBHOOK_URL` environment variable, and make sure you're in your virtual environment with the `requests` package installed before running the script.  This can be done on MacOS with the following.\n```bash\nexport SLACK_WEBHOOK_URL=https://hooks.slack.com/services/...\npython slack_webhook.py\n```\n\nWhen you run this, you should see a message from you Slack bot appear in the `notifications` channel!\n\n![Hello world message in Slack {1004x675}](/images/slack-webhook/slack-first-message.jpg)\n\n\nFor our notifications to be more helpful, we may want to add links or other formatting.  To do this, we will write our notifications with HTML tags, and then parse these tags and convert them to the [Slack flavored Markdown](https://api.slack.com/reference/surfaces/formatting) called `mrkdwn`.\n\n---\n\n## Adding a simple HTML parser to our class\nFrom the [Slack formatting guide](https://api.slack.com/reference/surfaces/formatting) for messages, we can see all of the ways to format text in our messages.  For our purposes, we will focus on a primary list.\n\n- Making text \u003ci\u003e`_italicized_`\u003c/i\u003e (`\u003ci\u003e`)\n- Making text \u003cb\u003e`*bold*`\u003c/b\u003e (`\u003cb\u003e`)\n- Striking through ~\u003cstrike\u003e`text`\u003c/strike\u003e~ (`\u003cstrike\u003e`)\n- Adding line breaks (`\u003cbr\u003e`)\n- Adding `one-line code blocks` using the backtick character (`\u003ccode\u003e`)\n- Adding unordered lists (line broken dashes) (`\u003cul\u003e\u003cli\u003e`)\n- Adding external links `\u003c[external link]|[display text]\u003e` (`\u003ca\u003e`)\n\nAlso note that the Slack documentation says that [certain characters need to be escaped](https://api.slack.com/reference/surfaces/formatting#escaping).\n\nThere are a few more styles that could be implemented, but we'll focus on just this list for this post.\n\nTo do this, we will utilize the [`html`](https://docs.python.org/3/library/html.html) module in the Python standard library to parse HTML tags, attributes, and values.\n\nLet's write a class (we need to inherit functions for the `HTMLParser` class) where we will parse all of the tags and attributes, and escape the message text when needed.  The idea here is that we can construct a string from scratch and for each tag we care about we can \"replace\" the HTML tags with the relevant mrkdwn syntax.\n\n```python\nfrom html.parser import HTMLParser\nimport re\nfrom typing import Any, List, Tuple\n\n\nclass SlackHTMLParser(HTMLParser):\n    def __init__(self, *args, **kwargs):\n        \"\"\"Escapes and converts an HTML string to Slack flavored\n        Markdown (mrkdwn).\n\n        More about Slack's Markdown Flavor (mrkdwn) can be seen here:\n            https://api.slack.com/reference/surfaces/formatting\n        \n        Call using `SlackHTMLParser(message_body).parse()`.\n        \"\"\"\n        super().__init__(*args, **kwargs)\n        self.slack_message = ''\n        self.ignore_tag = False  # Used to skip tags we don't care about\n        self.line_break = '::LINE::BREAK::'  # Unique sequence for swapping a \u003cbr\u003e\n\n\n    def handle_starttag(self, tag: str, attrs: List[Tuple[str, Any]]):\n        \"\"\"Called when the opening of a tag is encountered.\n\n        The idea here is to swap out the tag with the respective mrkdwn\n        symbol.\n\n        Args:\n            tag: Lowercase name of the HTML tag.  E.G. `br` or `i`.\n            attrs: List of tuples with the tuple having the following form:\n                (attribute name, value).  E.G. ('href', 'www.example.com').\n        \"\"\"\n        if tag in ['i', 'em']:\n            self.slack_message += '_'\n        elif tag in ['b', 'strong']:\n            self.slack_message += '*'\n        elif tag == 'strike':\n            self.slack_message += '~'\n        elif tag in ['br', 'p', 'ul']:\n            self.slack_message += self.line_break\n        elif tag == 'li':\n            self.slack_message += f'{self.line_break}- '\n        elif tag == 'code':\n            self.slack_message += '`'\n        elif tag == 'a':\n            href = [x[1] for x in attrs if x[0] == 'href']\n            if len(href) \u003e 0:\n                self.slack_message += f'\u003c{href[0]}|'\n        else:\n            self.ignore_tag = True\n\n\n    def handle_data(self, data: str):\n        \"\"\"Handles the data within a tag.\n\n        This is called after `handle_starttag` and before `handle_endtag`.\n\n        We will also escape the following text per Slack's documentation:\n        - '\u0026' -\u003e '\u0026amp;'\n        - '\u003c' -\u003e '\u0026lt;'\n        - '\u003e' -\u003e '\u0026gt;'\n\n        Args:\n            data: The data/string within the HTML tag.\n        \"\"\"\n        if not self.ignore_tag:\n            self.slack_message += data\\\n                .replace('\u0026', '\u0026amp;')\\\n                .replace('\u003c', '\u0026lt;')\\\n                .replace('\u003e', '\u0026gt;')\n\n\n    def handle_endtag(self, tag: str):\n        \"\"\"Called when the closing of a tag is encountered.\n\n        The idea here is to swap out the tag with the respective mrkdwn\n        symbol.  This is basically the same as the handle_starttag.\n\n        Args:\n            tag: Lowercase name of the HTML tag.  E.G. `br` or `i`.\n        \"\"\"\n        if tag in ['i', 'em']:\n            self.slack_message += '_'\n        elif tag in ['b', 'strong']:\n            self.slack_message += '*'\n        elif tag == 'strike':\n            self.slack_message += '~'\n        elif tag == 'p':\n            self.slack_message += self.line_break\n        elif tag == 'code':\n            self.slack_message += '`'\n        elif tag == 'a':\n            self.slack_message += '\u003e'\n        \n        self.ignore_tag = False\n\n\n    def parse(self, html_string: str) -\u003e str:\n        \"\"\"Parses a given HTML string and applies simple formatting.\n        \n        Note that we need to apply the line break replacing here\n        instead of with the handle tag methods.\n\n        Args:\n            html_string: The HTML string to convert to Slack mrkdwn.\n\n        Returns:\n            A formatted Slack mrkdwn string.\n        \"\"\"\n        self.feed(html_string)\n        return re.sub(\n            r'^(\\n)+',  # Remove the leading line breaks\n            '',\n            ' '.join(self.slack_message.split()).replace(self.line_break, '\\n')\n        )\n```\n\nWe can test our class out with the following code.\n\n```python\nhtml_string = '''\n    \u003cp\u003e\n        Here \u003ci\u003eis\u003c/i\u003e a \u003cstrike\u003eparagraph\u003c/strike\u003e with a \u003cb\u003elot\u003c/b\u003e of formatting.\n    \u003c/p\u003e\n    \u003cbr\u003e\n    \u003ccode\u003eCode sample\u003c/code\u003e \u0026 testing escape.\n    \u003cul\u003e\n        \u003cli\u003e\n            \u003ca href=\"https://www.google.com\"\u003eGoogle\u003c/a\u003e\n        \u003c/li\u003e\n        \u003cli\u003e\n            \u003ca href=\"https://www.amazon.com\"\u003eAmazon\u003c/a\u003e\n        \u003c/li\u003e\n    \u003c/ul\u003e\n'''\nparser = SlackHTMLParser()\nslack_message = parser.parse(html_string)\nprint(slack_message)\n```\n\nNow we can test our formatter in an actual Slack message!  Import your formatter class or add it to your existing code so you're able to do the following.\n\n```python\nhtml_string = '''\n    \u003cp\u003e\n        Here \u003ci\u003eis\u003c/i\u003e a \u003cstrike\u003eparagraph\u003c/strike\u003e with a \u003cb\u003elot\u003c/b\u003e of formatting.\n    \u003c/p\u003e\n    \u003cbr\u003e\n    \u003ccode\u003eCode sample\u003c/code\u003e \u0026 testing escape.\n    \u003cul\u003e\n        \u003cli\u003e\n            \u003ca href=\"https://www.google.com\"\u003eGoogle\u003c/a\u003e\n        \u003c/li\u003e\n        \u003cli\u003e\n            \u003ca href=\"https://www.amazon.com\"\u003eAmazon\u003c/a\u003e\n        \u003c/li\u003e\n    \u003c/ul\u003e\n'''\nwebhook_url = os.environ.get('SLACK_WEBHOOK_URL')\nparser = SlackHTMLParser()\nslack_message = parser.parse(html_string)\nslack = SlackWebhookBot(webhook_url)\nslack.send(slack_message)\n```\n\nYou should see the following message in your notifications channel.\n\n![Second message in Slack {680x140}](/images/slack-webhook/slack-format-message.jpg)\n\nLooks pretty good!  _Note that you can still send plain text messages, you don't need to use HTML._\n\nFor some final adjustments, you may have noticed that the message preview on the notification that popped up showed the actual `mrkdwn` characters as opposed to a formatted notification.  This looks a little sloppy, so let's make a new notification title that is similar to an email subject line.\n\nWe will briefly look at the basics of Slack's [Block Kit](https://api.slack.com/block-kit), which is a powerful way to add lots of customization to your Slack messages.  You can also explore Block Kit with Slack's [Block Kit Builder](https://app.slack.com/block-kit-builder/) which provides a preview of your Slack message.\n\nWithout diving too much into the details on the Block Kit, let's update our `SlackWebhookBot` class and add a method that adds a title block and a body block for our message.  Our subject line will appear in the notification itself, and also in the actual Slack message.\n\n```python\n# Add the `Dict` typing import to the existing typing imports\nfrom typing import Dict\n\ndef format_message(self, subject: str, body: str) -\u003e Dict:\n    \"\"\"Formats the subject and message body into Slack blocks.\n\n    Args:\n        subject: Subject that will appear on the notification popup.\n        body: The full message body.\n\n    Returns:\n        A dictionary payload with Slack block formatting.\n    \"\"\"\n    return {\n        'text': subject,\n        'blocks': [\n            {\n                'type': 'section',\n                'text': {\n                    'type': 'mrkdwn',\n                    'text': f'*{subject}*',\n                },\n            },\n            {\n                'type': 'section',\n                'text': {\n                    'type': 'mrkdwn',\n                    'text': body,\n                },\n            },\n        ],\n    }\n```\n\nNow we can tweak our `send` method to format a new message and accept a subject string as a Kwarg.\n\n```python\ndef send(self, message: str, subject: str = 'New message!') -\u003e bool:\n    \"\"\"Sends a formatted message to the webhook URL.\n\n    Args:\n        message: Plain text string to send to Slack.\n\n    Kwargs:\n        subject: The subject of the message that will appear in the notification\n            preview.\n\n    Returns:\n        A boolean representing if the request was successful.\n    \"\"\"\n    success = False\n    payload = self.format_message(subject, message)\n    try:\n        r = requests.post(\n            self.webhook_url,\n            headers=self.headers,\n            json=payload,\n            timeout=self.timeout\n        )\n    except requests.Timeout:\n        logger.error('Timeout occurred when trying to send message to Slack.')\n    except requests.RequestException as e:\n        logger.error(f'Error occurred when communicating with Slack: {e}.')\n    else:\n        success = True\n        logger.info('Successfully sent message to Slack.')\n\n    return success\n```\n\nAnd we can test our notification with a new subject line.\n\n```python\nhtml_string = '''\n    \u003cp\u003e\n        Here \u003ci\u003eis\u003c/i\u003e a \u003cstrike\u003eparagraph\u003c/strike\u003e with a \u003cb\u003elot\u003c/b\u003e of formatting.\n    \u003c/p\u003e\n    \u003cbr\u003e\n    \u003ccode\u003eCode sample\u003c/code\u003e \u0026 testing escape.\n    \u003cul\u003e\n        \u003cli\u003e\n            \u003ca href=\"https://www.google.com\"\u003eGoogle\u003c/a\u003e\n        \u003c/li\u003e\n        \u003cli\u003e\n            \u003ca href=\"https://www.amazon.com\"\u003eAmazon\u003c/a\u003e\n        \u003c/li\u003e\n    \u003c/ul\u003e\n'''\nwebhook_url = os.environ.get('SLACK_WEBHOOK_URL')\nparser = SlackHTMLParser()\nslack_message = parser.parse(html_string)\nslack = SlackWebhookBot(webhook_url)\nslack.send(slack_message, subject='You\\'ve completed the tutorial!')\n```\n\nYou should see a notification appear with the following preview\n\n![Slack notification {453x101}](/images/slack-webhook/slack-popup.jpg)\n\n\nand the following message in your channel.\n\n![Last message in Slack {680x159}](/images/slack-webhook/slack-last-message.jpg)\n\n\nWe have a custom Slack notification app!  You can place the `send` message calls all across your applications with related messages and now you can have a better pulse on user activity that developers and any other employees/stakeholders can easily access.\n\n---\n\nFor those wanting additional challenges or to continue developing their custom app, Slack has added a lot of really cool tools to the Block Kit.  There are a ton of really cool possibilities that can be added on by updating the `format_message` method in our `SlackWebhookBot` class.\n\nExplore the Slack's [Block Kit Builder](https://app.slack.com/block-kit-builder/) and see what you can make!\n\n---\n","title":"Setting up a Slack webhook for simple notifications","date":"2021-07-11","tags":["python","slack","webhook","api"],"description":"Setting up a Slack webhook to send plain text or simple HTML notifications to a Slack channel."}],"networkx":[{"id":"visualizing-your-linkedin-connections","contentHtml":"\u003ch2\u003etl;dr\u003c/h2\u003e\n\u003ch3\u003eGoal\u003c/h3\u003e\n\u003cp\u003e\u003cem\u003eTo understand and visualize the companies within my directly connected network on LinkedIn\u003c/em\u003e\u003c/p\u003e\n\u003ch3\u003eProcess overview\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eLinkedIn data sources\u003c/strong\u003e - retrieving LinkedIn Network data from a \"Get a copy of your data\" CSV export\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eDiving into the data\u003c/strong\u003e - exploring, cleaning, and aggregating the data with \u003ca href=\"https://pandas.pydata.org/\"\u003e\u003ccode\u003ePandas\u003c/code\u003e\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eCreating the network\u003c/strong\u003e - creating a network graph using \u003ca href=\"https://networkx.org/\"\u003e\u003ccode\u003eNetworkX\u003c/code\u003e\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eVisualization\u003c/strong\u003e - visualizing the network with \u003ca href=\"https://pyvis.readthedocs.io/en/latest/\"\u003e\u003ccode\u003epyvis\u003c/code\u003e\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eImproving the output\u003c/strong\u003e - cleaning up the network graph with additional filtering\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3\u003eResults\u003c/h3\u003e\n\u003cp\u003e\u003cem\u003eHover over the nodes for more details\u003c/em\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"/network/first-nx-graph.html\"\u003eThe first network graph\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/network/second-nx-graph.html\"\u003eThe second (more specific) network graph\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003ePython dependencies\u003c/h3\u003e\n\u003cpre\u003e\u003ccode\u003e# Python standard library\nfrom difflib import get_close_matches\n\n# 3rd party\nimport networkx as nx\nimport pandas as pd\nfrom pyvis.network import Network\n\u003c/code\u003e\u003c/pre\u003e\n\u003chr\u003e\n\u003cp\u003eRecently, I was exploring \u003ca href=\"https://www.linkedin.com/in/bradley-schoeneweis/\"\u003emy LinkedIn\u003c/a\u003e network to see what some of my colleagues from high school and undergrad are currently up to.\u003c/p\u003e\n\u003cp\u003eAs I was scrolling through the connections page, I noticed LinkedIn gives you options to filter and searching with ease, but it doesn't really provide tools to learn about your network as a whole.\u003c/p\u003e\n\u003cp\u003eSo I decided to see if there was an easy way to export my network data to see what I could do with a few hours of exploring the data.\u003c/p\u003e\n\u003ch2\u003eLinkedIn data sources\u003c/h2\u003e\n\u003cp\u003eMy first thought was to checkout out the \u003ca href=\"https://www.linkedin.com/developers/\"\u003eLinkedIn's Developer API\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eSomething I do fairly frequently at my current job is integrating various 3rd-party REST APIs into our platform, so I wanted to see all the functionality and possibilities that this API would provide.\u003c/p\u003e\n\u003cp\u003eAfter reading through some documentation, I decided this wasn't a direction I wanted to pursue. Most of their developer products require approval, so I decided to look into other options.\u003c/p\u003e\n\u003cp\u003eAnother thought I had was to write a quick scraping script to pull down the HTML of my connections page and parse out names and companies, but I assumed there had to be a more simple way to get this data.\u003c/p\u003e\n\u003cp\u003eFinally, after a bit of research, I found that there are various \"Get a copy of your data\" reports that you can run within LinkedIn.  In order to get to these reports, you can do the following:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eOn the homepage toolbar, click the \u003cstrong\u003eMe\u003c/strong\u003e dropdown\u003c/li\u003e\n\u003cli\u003eUnder the \u003cem\u003eAccount\u003c/em\u003e section, click \u003cstrong\u003eSettings \u0026#x26; Privacy\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003eClick on \u003cstrong\u003eGet a copy of your data\u003c/strong\u003e, and you can view the various reports\u003c/li\u003e\n\u003cli\u003eSelect the reports you're interested in, for this, I just checked \u003cstrong\u003eConnections\u003c/strong\u003e\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eAfter requesting the report, it should only take a few minutes before you get an email saying your report is ready for export.\u003c/p\u003e\n\u003ch2\u003eDiving into the data\u003c/h2\u003e\n\u003cp\u003eTo reiterate our goal, we want to get a broad understanding of the companies within the first layer of our network (direct connections). Now, let's load up Python and learn more about this data in this CSV.\u003c/p\u003e\n\u003ch3\u003eReading in the data\u003c/h3\u003e\n\u003cp\u003eOnce the CSV is downloaded, we can open it up with Pandas and take a look (\u003cem\u003eoutput will be commented below\u003c/em\u003e).\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eimport pandas as pd\n\n# We want to skip the first three rows because of Notes at the top\ndf = pd.read_csv('Connections.csv', skiprows=3)\n\ndf.columns\n# ['First Name', 'Last Name', 'Email Address', 'Company', 'Position', 'Connected On',]\n\ndf.info()\n\"\"\"\n\u0026#x3C;class 'pandas.core.frame.DataFrame'\u003e\nRangeIndex: 376 entries, 0 to 375\nData columns (total 6 columns):\n #   Column         Non-Null Count  Dtype \n---  ------         --------------  ----- \n 0   First Name     375 non-null    object\n 1   Last Name      375 non-null    object\n 2   Email Address  1 non-null      object\n 3   Company        371 non-null    object\n 4   Position       371 non-null    object\n 5   Connected On   376 non-null    object\ndtypes: object(6)\nmemory usage: 17.8+ KB\n\"\"\"\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eI won't post the name's of any individuals or full rows to respect the privacy of my connections, but when I searched through the my Connections CSV, I noticed a few initial patterns that would help clean up the data.\u003c/p\u003e\n\u003ch3\u003eCleaning up the data\u003c/h3\u003e\n\u003cp\u003eAt first glance, the first thing I notice is connections who don't list a current company, so let's get rid of those.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003edf = df[df['Company'].notna()].sort_values(by='Company')\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eAfter sorting, another thing I noticed was that some of these company names belong to the same company, but the individuals wrote them differently.\u003c/p\u003e\n\u003cp\u003eAn example of this is \u003ccode\u003e'IBM Global Solution Center'\u003c/code\u003e and \u003ccode\u003e'IBM'\u003c/code\u003e; for our purposes, these should both be classified as \u003ccode\u003eIBM\u003c/code\u003e.\u003c/p\u003e\n\u003cp\u003eLet's run through a fuzzy match run using \u003ca href=\"https://docs.python.org/3/library/difflib.html#difflib.get_close_matches\"\u003edifflib's \u003ccode\u003eget_close_matches\u003c/code\u003e\u003c/a\u003e to try and bucket some of these similar company names.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003efrom difflib import get_close_matches\n\ncompanies = df['Company'].drop_duplicates()\n\n# cutoff=0.7 is a similarity ranking, and n=10 just takes the top 10 values\nsimilar_companies = {x: get_close_matches(x, companies, n=10, cutoff=0.7)\n                     for x in companies}\n\n# We are only interested in the entries that had another match\nsimilar_companies = {x: [name for name in y if name != x]\n                     for x, y in similar_companies.items() if len(y) \u003e 1}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eNow, this solution is not perfect, but it will help draw out some similar companies. You should still run a manual inspection of the data (the IBM example I gave above is one that doesn't show up in the fuzzy match results).\u003c/p\u003e\n\u003cp\u003eBased upon the results, let's group together some of the companies that had matches.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003edf['Company'] = df['Company'].replace({\n    'KPMG US': similar_companies['KPMG US'],\n    'Self-employed': similar_companies['Self-employed'],\n    'IBM Global Solution Center': 'IBM',\n})\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe next thing you may have noticed is that in our \u003ccode\u003esimilar_companies\u003c/code\u003e dictionary, we cleaned up a \u003ccode\u003eSelf-employed\u003c/code\u003e entry.\u003c/p\u003e\n\u003cp\u003eTo stay aligned with our goal, let's drop these entries, as well as your current company.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ecompanies_to_drop = ['self employed', 'your current company']\ndf = df[~df['Company'].str.lower().isin(companies_to_drop)]\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003eAggregating the data\u003c/h3\u003e\n\u003cp\u003eNow that our data is cleaned up a bit, let's aggregate and sum the number of connections for each of the companies.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003edf_company_counts = df['Company'].value_counts().reset_index()\ndf_company_counts.columns = ['Company', 'Count']  # For ease of understanding\ndf_company_counts = df_company_counts.sort_values(by='Count', ascending=False)\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2\u003eCreating the network\u003c/h2\u003e\n\u003cp\u003eWe have the numbers we want for each company, now let's jump into using \u003ccode\u003eNetworkX\u003c/code\u003e to recreate a network.\u003c/p\u003e\n\u003cp\u003eThe first step will be to initialize our graph, and add yourself as the central node, as it is your network.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eimport networkx as nx\n\nG = nx.Graph()\nG.add_node('Me')\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThen, we'll loop through our \u003ccode\u003edf_company_counts\u003c/code\u003e DataFrame and add each company as a node.\u003c/p\u003e\n\u003cp\u003e\u003cem\u003eYou'll notice some HTML tags in the title below, this is just to make it more readable for later\u003c/em\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003efor _, row in df_company_counts.iterrows():\n\t# The title will be for more information later on\n    title = '\u0026#x3C;b\u003e{0}\u0026#x3C;/b\u003e ({1})\u0026#x3C;br\u003e\u0026#x3C;hr\u003ePositions:\u0026#x3C;br\u003e'.format(row['Company'],\n    \t\t\t\t\t\t\t\t\t\t\t\t\t\trow['Count'])\n\n    # In addition to the full company name, let's add each position in a\n    # list to see the roles our connections have at these companies\n    position_list = ''.join('\u0026#x3C;li\u003e{}\u0026#x3C;/li\u003e'.format(x)\n    \t\t\t\t\t\tfor x in df[df['Company'] == row['Company']]['Position'])\n    title += '\u0026#x3C;ul\u003e{0}\u0026#x3C;/ul\u003e'.format(position_list)\n\n    # For ease of viewing, limit company names to 15 letters\n    node_name = row['Company']\n    if len(node_name) \u003e 15:\n        node_name = node_name[:15] + '...'\n\n    # Add the node and an edge connection ourself to the new node\n    G.add_node(node_name, weight=row['Count'], size=row['Count'] * 2, title=title)\n    G.add_edge('Me', node_name)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eAnd just like that, we've created our network of connections.\u003c/p\u003e\n\u003ch2\u003eVisualization\u003c/h2\u003e\n\u003cp\u003eOur network graph is created, so let's get into visualizing the network.\u003c/p\u003e\n\u003cp\u003eThere are a few options for visualizing networks including \u003ccode\u003ematplotlib.pyplot\u003c/code\u003e, but I found that \u003ccode\u003epyvis\u003c/code\u003e was the easiest to use for several reasons:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003epyvis\u003c/code\u003e generates an HTML file\u003c/li\u003e\n\u003cli\u003eCustomization is made very easy\u003c/li\u003e\n\u003cli\u003eThe graph is interactive by default\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eLet's look into generating this HTML file.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003efrom pyvis.network import Network\n\nnt = Network('100%', '100%', bgcolor='#222222', font_color='white')\nnt.from_nx(G)\nnt.repulsion()  # Spaces out the nodes\nnt.show('nx.html')\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eAnd it's that simple! We specify a width and height, optional styling attributes, and then we can generate the network graph visual straight from what we created with NetworkX.\u003c/p\u003e\n\u003cp\u003eNow we can see \u003ca href=\"/network/first-nx-graph.html\"\u003ethe network we generated\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eYou can hover over each node to see the total number of connections that work at the respective company, and below is a list of the positions held by your connections.\u003c/p\u003e\n\u003cp\u003eAs you can see, this is a bit hard to read into since there are a lot of nodes. Try and imagine reading this with +1,000 connections.\u003c/p\u003e\n\u003ch2\u003eImproving the output\u003c/h2\u003e\n\u003cp\u003eThere are a few ways that our network could be narrowed down.\u003c/p\u003e\n\u003cp\u003eBeing a \u003cem\u003eSoftware Developer\u003c/em\u003e, the thought that first occurred to me was to try and dial in on tech-related companies through known positions titles.\u003c/p\u003e\n\u003cp\u003eTo do this, I thought of a list of buzzwords/common job titles that I've seen across LinkedIn, and filtered down the initial DataFrame.\u003c/p\u003e\n\u003cp\u003eThen, we go through the same process we did in previous sections of generating and displaying the graph.\u003c/p\u003e\n\u003cp\u003e\u003cem\u003eAgain, this is not perfect, but it's a good starting point.\u003c/em\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e# Filter down from a list of popular tech positions\npositions = [\n    'developer', 'engineer', 'ai', 'analytics', 'software', 'cloud', 'cto',\n    'sde', 'sre', 'saas', 'product', 'engineering', 'scientist', 'data',\n]\ndf = df[df['Position'].str.contains('|'.join(positions), case=False)]\ndf_company_counts = df['Company'].value_counts().reset_index()\ndf_company_counts.columns = ['Company', 'Count']\ndf_company_counts = df_company_counts.sort_values(by='Count', ascending=False)\n\n# Re-initialize the graph and add the nodes/edges again\nG = nx.Graph()\nG.add_node('Me')\n\nfor _, row in df_company_counts.iterrows():\n    title = '\u0026#x3C;b\u003e{0}\u0026#x3C;/b\u003e ({1})\u0026#x3C;br\u003e\u0026#x3C;hr\u003ePositions:\u0026#x3C;br\u003e'.format(row['Company'], row['Count'])\n    position_list = ''.join('\u0026#x3C;li\u003e{}\u0026#x3C;/li\u003e'.format(x)\n    \t\t\t\t\t\tfor x in df[df['Company'] == row['Company']]['Position'])\n    title += '\u0026#x3C;ul\u003e{0}\u0026#x3C;/ul\u003e'.format(position_list)\n    node_name = row['Company']\n    if len(node_name) \u003e 15:\n        node_name = node_name[:15] + '...'\n\n    # Since there are less nodes, let's increase the sizes\n    G.add_node(node_name, weight=row['Count'], size=row['Count'] * 5, title=title)\n    G.add_edge('Me', node_name)\n\n# Generate the visualization\nnt = Network('100%', '100%', bgcolor='#222222', font_color='white')\nnt.from_nx(G)\nnt.repulsion()\nnt.show('nx.html')\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eNow, let's look at the \u003ca href=\"/network/second-nx-graph.html\"\u003eupdated results\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eMuch better! This is more readable and easier to interact with.\u003c/p\u003e\n\u003cp\u003eAnd just like that, we achieved our goal of gaining a broader understanding of the companies in our LinkedIn network.\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003e\u003cstrong\u003e\u003cem\u003ePossible improvements for those interested\u003c/em\u003e\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eScraping the profile location of each of your connections to segment by location\u003c/li\u003e\n\u003cli\u003eCompiling a list of companies you'd like to work for/are interested in and creating a filtering system\u003c/li\u003e\n\u003cli\u003eResearching salary data for positions and gathering average pay by company\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n","markdown":"\n## tl;dr\n\n### Goal\n_To understand and visualize the companies within my directly connected network on LinkedIn_\n\n### Process overview\n1. **LinkedIn data sources** - retrieving LinkedIn Network data from a \"Get a copy of your data\" CSV export\n2. **Diving into the data** - exploring, cleaning, and aggregating the data with [`Pandas`](https://pandas.pydata.org/)\n3. **Creating the network** - creating a network graph using [`NetworkX`](https://networkx.org/)\n4. **Visualization** - visualizing the network with [`pyvis`](https://pyvis.readthedocs.io/en/latest/)\n5. **Improving the output** - cleaning up the network graph with additional filtering\n\n### Results\n_Hover over the nodes for more details_\n- [The first network graph](/network/first-nx-graph.html)\n- [The second (more specific) network graph](/network/second-nx-graph.html)\n\n### Python dependencies\n```python\n# Python standard library\nfrom difflib import get_close_matches\n\n# 3rd party\nimport networkx as nx\nimport pandas as pd\nfrom pyvis.network import Network\n```\n\n---\n\nRecently, I was exploring [my LinkedIn](https://www.linkedin.com/in/bradley-schoeneweis/) network to see what some of my colleagues from high school and undergrad are currently up to.\n\nAs I was scrolling through the connections page, I noticed LinkedIn gives you options to filter and searching with ease, but it doesn't really provide tools to learn about your network as a whole.\n\nSo I decided to see if there was an easy way to export my network data to see what I could do with a few hours of exploring the data.\n\n\n## LinkedIn data sources\n\nMy first thought was to checkout out the [LinkedIn's Developer API](https://www.linkedin.com/developers/).\n\nSomething I do fairly frequently at my current job is integrating various 3rd-party REST APIs into our platform, so I wanted to see all the functionality and possibilities that this API would provide.\n\nAfter reading through some documentation, I decided this wasn't a direction I wanted to pursue. Most of their developer products require approval, so I decided to look into other options.\n\nAnother thought I had was to write a quick scraping script to pull down the HTML of my connections page and parse out names and companies, but I assumed there had to be a more simple way to get this data.\n\nFinally, after a bit of research, I found that there are various \"Get a copy of your data\" reports that you can run within LinkedIn.  In order to get to these reports, you can do the following:\n1. On the homepage toolbar, click the **Me** dropdown\n2. Under the _Account_ section, click **Settings \u0026 Privacy**\n3. Click on **Get a copy of your data**, and you can view the various reports\n4. Select the reports you're interested in, for this, I just checked **Connections**\n\nAfter requesting the report, it should only take a few minutes before you get an email saying your report is ready for export.\n\n\n## Diving into the data\n\nTo reiterate our goal, we want to get a broad understanding of the companies within the first layer of our network (direct connections). Now, let's load up Python and learn more about this data in this CSV.\n\n### Reading in the data\nOnce the CSV is downloaded, we can open it up with Pandas and take a look (_output will be commented below_).\n\n```python\nimport pandas as pd\n\n# We want to skip the first three rows because of Notes at the top\ndf = pd.read_csv('Connections.csv', skiprows=3)\n\ndf.columns\n# ['First Name', 'Last Name', 'Email Address', 'Company', 'Position', 'Connected On',]\n\ndf.info()\n\"\"\"\n\u003cclass 'pandas.core.frame.DataFrame'\u003e\nRangeIndex: 376 entries, 0 to 375\nData columns (total 6 columns):\n #   Column         Non-Null Count  Dtype \n---  ------         --------------  ----- \n 0   First Name     375 non-null    object\n 1   Last Name      375 non-null    object\n 2   Email Address  1 non-null      object\n 3   Company        371 non-null    object\n 4   Position       371 non-null    object\n 5   Connected On   376 non-null    object\ndtypes: object(6)\nmemory usage: 17.8+ KB\n\"\"\"\n```\n\nI won't post the name's of any individuals or full rows to respect the privacy of my connections, but when I searched through the my Connections CSV, I noticed a few initial patterns that would help clean up the data.\n\n### Cleaning up the data\n\nAt first glance, the first thing I notice is connections who don't list a current company, so let's get rid of those.\n\n```python\ndf = df[df['Company'].notna()].sort_values(by='Company')\n```\n\nAfter sorting, another thing I noticed was that some of these company names belong to the same company, but the individuals wrote them differently.\n\nAn example of this is `'IBM Global Solution Center'` and `'IBM'`; for our purposes, these should both be classified as `IBM`.\n\nLet's run through a fuzzy match run using [difflib's `get_close_matches`](https://docs.python.org/3/library/difflib.html#difflib.get_close_matches) to try and bucket some of these similar company names.\n```python\nfrom difflib import get_close_matches\n\ncompanies = df['Company'].drop_duplicates()\n\n# cutoff=0.7 is a similarity ranking, and n=10 just takes the top 10 values\nsimilar_companies = {x: get_close_matches(x, companies, n=10, cutoff=0.7)\n                     for x in companies}\n\n# We are only interested in the entries that had another match\nsimilar_companies = {x: [name for name in y if name != x]\n                     for x, y in similar_companies.items() if len(y) \u003e 1}\n```\n\nNow, this solution is not perfect, but it will help draw out some similar companies. You should still run a manual inspection of the data (the IBM example I gave above is one that doesn't show up in the fuzzy match results).\n\nBased upon the results, let's group together some of the companies that had matches.\n```python\ndf['Company'] = df['Company'].replace({\n    'KPMG US': similar_companies['KPMG US'],\n    'Self-employed': similar_companies['Self-employed'],\n    'IBM Global Solution Center': 'IBM',\n})\n```\n\nThe next thing you may have noticed is that in our `similar_companies` dictionary, we cleaned up a `Self-employed` entry.\n\nTo stay aligned with our goal, let's drop these entries, as well as your current company.\n```python\ncompanies_to_drop = ['self employed', 'your current company']\ndf = df[~df['Company'].str.lower().isin(companies_to_drop)]\n```\n\n### Aggregating the data\nNow that our data is cleaned up a bit, let's aggregate and sum the number of connections for each of the companies.\n\n```python\ndf_company_counts = df['Company'].value_counts().reset_index()\ndf_company_counts.columns = ['Company', 'Count']  # For ease of understanding\ndf_company_counts = df_company_counts.sort_values(by='Count', ascending=False)\n```\n\n## Creating the network\n\nWe have the numbers we want for each company, now let's jump into using `NetworkX` to recreate a network.\n\nThe first step will be to initialize our graph, and add yourself as the central node, as it is your network.\n\n```python\nimport networkx as nx\n\nG = nx.Graph()\nG.add_node('Me')\n```\n\nThen, we'll loop through our `df_company_counts` DataFrame and add each company as a node.\n\n_You'll notice some HTML tags in the title below, this is just to make it more readable for later_\n```python\nfor _, row in df_company_counts.iterrows():\n\t# The title will be for more information later on\n    title = '\u003cb\u003e{0}\u003c/b\u003e ({1})\u003cbr\u003e\u003chr\u003ePositions:\u003cbr\u003e'.format(row['Company'],\n    \t\t\t\t\t\t\t\t\t\t\t\t\t\trow['Count'])\n\n    # In addition to the full company name, let's add each position in a\n    # list to see the roles our connections have at these companies\n    position_list = ''.join('\u003cli\u003e{}\u003c/li\u003e'.format(x)\n    \t\t\t\t\t\tfor x in df[df['Company'] == row['Company']]['Position'])\n    title += '\u003cul\u003e{0}\u003c/ul\u003e'.format(position_list)\n\n    # For ease of viewing, limit company names to 15 letters\n    node_name = row['Company']\n    if len(node_name) \u003e 15:\n        node_name = node_name[:15] + '...'\n\n    # Add the node and an edge connection ourself to the new node\n    G.add_node(node_name, weight=row['Count'], size=row['Count'] * 2, title=title)\n    G.add_edge('Me', node_name)\n```\n\nAnd just like that, we've created our network of connections.\n\n\n## Visualization\n\nOur network graph is created, so let's get into visualizing the network.\n\nThere are a few options for visualizing networks including `matplotlib.pyplot`, but I found that `pyvis` was the easiest to use for several reasons:\n- `pyvis` generates an HTML file\n- Customization is made very easy\n- The graph is interactive by default\n\nLet's look into generating this HTML file.\n```python\nfrom pyvis.network import Network\n\nnt = Network('100%', '100%', bgcolor='#222222', font_color='white')\nnt.from_nx(G)\nnt.repulsion()  # Spaces out the nodes\nnt.show('nx.html')\n```\n\nAnd it's that simple! We specify a width and height, optional styling attributes, and then we can generate the network graph visual straight from what we created with NetworkX.\n\nNow we can see [the network we generated](/network/first-nx-graph.html).\n\nYou can hover over each node to see the total number of connections that work at the respective company, and below is a list of the positions held by your connections.\n\nAs you can see, this is a bit hard to read into since there are a lot of nodes. Try and imagine reading this with +1,000 connections.\n\n## Improving the output\n\nThere are a few ways that our network could be narrowed down.\n\nBeing a _Software Developer_, the thought that first occurred to me was to try and dial in on tech-related companies through known positions titles.\n\nTo do this, I thought of a list of buzzwords/common job titles that I've seen across LinkedIn, and filtered down the initial DataFrame.\n\nThen, we go through the same process we did in previous sections of generating and displaying the graph.\n\n_Again, this is not perfect, but it's a good starting point._\n```python\n# Filter down from a list of popular tech positions\npositions = [\n    'developer', 'engineer', 'ai', 'analytics', 'software', 'cloud', 'cto',\n    'sde', 'sre', 'saas', 'product', 'engineering', 'scientist', 'data',\n]\ndf = df[df['Position'].str.contains('|'.join(positions), case=False)]\ndf_company_counts = df['Company'].value_counts().reset_index()\ndf_company_counts.columns = ['Company', 'Count']\ndf_company_counts = df_company_counts.sort_values(by='Count', ascending=False)\n\n# Re-initialize the graph and add the nodes/edges again\nG = nx.Graph()\nG.add_node('Me')\n\nfor _, row in df_company_counts.iterrows():\n    title = '\u003cb\u003e{0}\u003c/b\u003e ({1})\u003cbr\u003e\u003chr\u003ePositions:\u003cbr\u003e'.format(row['Company'], row['Count'])\n    position_list = ''.join('\u003cli\u003e{}\u003c/li\u003e'.format(x)\n    \t\t\t\t\t\tfor x in df[df['Company'] == row['Company']]['Position'])\n    title += '\u003cul\u003e{0}\u003c/ul\u003e'.format(position_list)\n    node_name = row['Company']\n    if len(node_name) \u003e 15:\n        node_name = node_name[:15] + '...'\n\n    # Since there are less nodes, let's increase the sizes\n    G.add_node(node_name, weight=row['Count'], size=row['Count'] * 5, title=title)\n    G.add_edge('Me', node_name)\n\n# Generate the visualization\nnt = Network('100%', '100%', bgcolor='#222222', font_color='white')\nnt.from_nx(G)\nnt.repulsion()\nnt.show('nx.html')\n```\n\nNow, let's look at the [updated results](/network/second-nx-graph.html).\n\nMuch better! This is more readable and easier to interact with.\n\nAnd just like that, we achieved our goal of gaining a broader understanding of the companies in our LinkedIn network.\n\n---\n\n**_Possible improvements for those interested_**\n- Scraping the profile location of each of your connections to segment by location\n- Compiling a list of companies you'd like to work for/are interested in and creating a filtering system\n- Researching salary data for positions and gathering average pay by company\n\n---\n","title":"Visualizing your LinkedIn connections using Python","date":"2021-04-08","tags":["python","pandas","networkx","data-analysis"],"description":"Using Python's Pandas, NetworkX, and pyvis to understand and visualize companies within a directly connected LinkedIn network."}]}},"__N_SSG":true},"page":"/tags","query":{},"buildId":"Llfq-lYryHX2DkunnEbsb","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>